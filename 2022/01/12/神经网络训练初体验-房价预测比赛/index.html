<!DOCTYPE html><html lang="zh-Hans"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta name="description" content="神经网络训练初体验: 房价预测比赛"><meta name="keywords" content="深度学习"><meta name="author" content="Met Guo"><meta name="copyright" content="Met Guo"><title>神经网络训练初体验: 房价预测比赛 | Gmet's Blog</title><link rel="shortcut icon" href="/melody-favicon.ico"><link rel="stylesheet" href="/css/index.css?version=1.8.2"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/font-awesome@latest/css/font-awesome.min.css?version=1.8.2"><meta name="format-detection" content="telephone=no"><meta http-equiv="x-dns-prefetch-control" content="on"><link rel="dns-prefetch" href="https://cdn.jsdelivr.net"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/instantsearch.js@2.1.1/dist/instantsearch.min.css"><script src="https://cdn.jsdelivr.net/npm/instantsearch.js@2.1.1/dist/instantsearch.min.js" defer></script><meta http-equiv="Cache-Control" content="no-transform"><meta http-equiv="Cache-Control" content="no-siteapp"><script src="https://v1.hitokoto.cn/?encode=js&amp;charset=utf-8&amp;select=.footer_custom_text" defer></script><script>var GLOBAL_CONFIG = { 
  root: '/',
  algolia: {"appId":"LEZCUKXOU8","apiKey":"43c226e390cd280e256d1d7cc0e6cce4","indexName":"blogs","hits":{"per_page":10,"input_placeholder":"Search for Posts","hits_empty":"û���ҵ�����Ҫ�Ľ��: ${query}","hits_stats":"�ҵ�${hits}���������ʱ${time}���룩"},"languages":{"input_placeholder":"搜索文章","hits_empty":"找不到您查询的内容:${query}","hits_stats":"找到 ${hits} 条结果，用时 ${time} 毫秒"}},
  localSearch: undefined,
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  hexoVersion: '5.4.2'
} </script><meta name="generator" content="Hexo 5.4.2"><link rel="alternate" href="/atom.xml" title="Gmet's Blog" type="application/atom+xml">
</head><body><canvas class="fireworks"></canvas><i class="fa fa-arrow-right" id="toggle-sidebar" aria-hidden="true"></i><div id="sidebar" data-display="true"><div class="toggle-sidebar-info text-center"><span data-toggle="切换文章详情">切换站点概览</span><hr></div><div class="sidebar-toc"><div class="sidebar-toc__title">目录</div><div class="sidebar-toc__progress"><span class="progress-notice">你已经读了</span><span class="progress-num">0</span><span class="progress-percentage">%</span><div class="sidebar-toc__progress-bar"></div></div><div class="sidebar-toc__content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#%E5%B7%A5%E4%BD%9C%E7%8E%AF%E5%A2%83"><span class="toc-number">1.</span> <span class="toc-text">工作环境</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E5%88%9B%E5%BB%BA%E9%A1%B9%E7%9B%AE"><span class="toc-number">2.</span> <span class="toc-text">创建项目</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E4%B8%8B%E8%BD%BD%E6%95%B0%E6%8D%AE%E9%9B%86"><span class="toc-number">3.</span> <span class="toc-text">下载数据集</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E8%AF%BB%E5%8F%96%E6%95%B0%E6%8D%AE%E9%9B%86"><span class="toc-number">4.</span> <span class="toc-text">读取数据集</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%95%B0%E6%8D%AE%E9%A2%84%E5%A4%84%E7%90%86"><span class="toc-number">4.1.</span> <span class="toc-text">数据预处理</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E8%AE%AD%E7%BB%83"><span class="toc-number">5.</span> <span class="toc-text">训练</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#K-%E6%8A%98%E4%BA%A4%E5%8F%89%E9%AA%8C%E8%AF%81"><span class="toc-number">6.</span> <span class="toc-text">K-折交叉验证</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E6%A8%A1%E5%9E%8B%E9%80%89%E6%8B%A9"><span class="toc-number">7.</span> <span class="toc-text">模型选择</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E6%8F%90%E4%BA%A4Kaggle%E9%A2%84%E6%B5%8B"><span class="toc-number">8.</span> <span class="toc-text">提交Kaggle预测</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E5%B0%8F%E7%BB%93"><span class="toc-number">9.</span> <span class="toc-text">小结</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E6%9B%B4%E8%BF%9B%E4%B8%80%E6%AD%A5"><span class="toc-number">10.</span> <span class="toc-text">更进一步</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E5%90%8E%E8%AE%B0"><span class="toc-number">11.</span> <span class="toc-text">后记</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E5%8F%82%E8%80%83%E8%B5%84%E6%96%99"><span class="toc-number">12.</span> <span class="toc-text">参考资料</span></a></li></ol></div></div><div class="author-info hide"><div class="author-info__avatar text-center"><img src="/img/avatar.png"></div><div class="author-info__name text-center">Met Guo</div><div class="author-info__description text-center"></div><hr><div class="author-info-articles"><a class="author-info-articles__archives article-meta" href="/archives"><span class="pull-left">文章</span><span class="pull-right">71</span></a><a class="author-info-articles__tags article-meta" href="/tags"><span class="pull-left">标签</span><span class="pull-right">55</span></a><a class="author-info-articles__categories article-meta" href="/categories"><span class="pull-left">分类</span><span class="pull-right">43</span></a></div></div></div><div id="content-outer"><div id="top-container" style="background-image: url(https://images7.alphacoders.com/550/thumb-1920-550739.jpg)"><div id="page-header"><span class="pull-left"> <a id="site-name" href="/">Gmet's Blog</a></span><i class="fa fa-bars toggle-menu pull-right" aria-hidden="true"></i><span class="pull-right menus">   <a class="site-page" href="/">Home</a><a class="site-page" href="/archives">Archives</a><a class="site-page" href="/tags">Tags</a><a class="site-page" href="/categories">Categories</a><a class="site-page" href="/slides">Slides</a></span><span class="pull-right"><a class="site-page social-icon search"><i class="fa fa-search"></i><span> 搜索</span></a></span></div><div id="post-info"><div id="post-title">神经网络训练初体验: 房价预测比赛</div><div id="post-meta"><time class="post-meta__date"><i class="fa fa-calendar" aria-hidden="true"></i> 2022-01-12</time><span class="post-meta__separator">|</span><i class="fa fa-inbox post-meta__icon" aria-hidden="true"></i><a class="post-meta__categories" href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">深度学习</a><i class="fa fa-angle-right" aria-hidden="true"></i><i class="fa fa-inbox post-meta__icon" aria-hidden="true"></i><a class="post-meta__categories" href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E5%8A%A8%E6%89%8B%E5%AD%A6%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">动手学深度学习</a><div class="post-meta-wordcount"><span>字数总计: </span><span class="word-count">3.7k</span><span class="post-meta__separator">|</span><span>阅读时长: 14 分钟</span></div></div></div></div><div class="layout" id="content-inner"><article id="post"><div class="article-container" id="post-content"><blockquote>
<p>本文FROM《动手学深度学习》第四章第十节，链接详见<em>参考资料1</em></p>
</blockquote>
<h1 id="工作环境"><a href="#工作环境" class="headerlink" title="工作环境"></a>工作环境</h1><div class="table-container">
<table>
<thead>
<tr>
<th>软件名称</th>
<th>说明</th>
<th>备注</th>
</tr>
</thead>
<tbody>
<tr>
<td>anaconda</td>
<td>Python环境和开源模块管理工具</td>
<td>默认</td>
</tr>
<tr>
<td>Python</td>
<td>开发语言</td>
<td>3.8</td>
</tr>
<tr>
<td>torch、torchvision</td>
<td>深度学习框架</td>
<td>默认</td>
</tr>
<tr>
<td>d2l</td>
<td>动手学深度学习官方模块</td>
<td>默认</td>
</tr>
<tr>
<td>VS Code</td>
<td>开发IDE</td>
<td>默认</td>
</tr>
</tbody>
</table>
</div>
<h1 id="创建项目"><a href="#创建项目" class="headerlink" title="创建项目"></a>创建项目</h1><p>创建项目文件夹<code>kaggle-house-prices</code>（自定义命名）以及<code>code</code>子文件夹，<code>code/</code>下创建Jupyter notebook，所有代码写在这里面。</p>
<p>生成的项目结构如下：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">kaggle-house-prices/</span><br><span class="line">	code/</span><br><span class="line">		kaggle-house-prices.ipynb</span><br></pre></td></tr></table></figure>
<h1 id="下载数据集"><a href="#下载数据集" class="headerlink" title="下载数据集"></a>下载数据集</h1><p>数据集来自于Kaggle上的一个竞赛。网址：<a target="_blank" rel="noopener" href="https://www.kaggle.com/c/house-prices-advanced-regression-techniques/data">https://www.kaggle.com/c/house-prices-advanced-regression-techniques/data</a></p>
<p>你可以直接从上面下载数据集；（包含训练集、测试集、数据描述和提交样例）</p>
<p>或者你可以使用书中的方式下载代码，这里我把完整的代码贴一下。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> hashlib</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> tarfile</span><br><span class="line"><span class="keyword">import</span> zipfile</span><br><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"></span><br><span class="line"><span class="comment"># 这个二元组包含数据集的url和验证文件完整性的sha-1密钥</span></span><br><span class="line">DATA_HUB = <span class="built_in">dict</span>()</span><br><span class="line">DATA_URL = <span class="string">&#x27;http://d2l-data.s3-accelerate.amazonaws.com/&#x27;</span></span><br><span class="line">DATA_HUB[<span class="string">&#x27;kaggle_house_train&#x27;</span>] = (</span><br><span class="line">    DATA_URL + <span class="string">&#x27;kaggle_house_pred_train.csv&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;585e9cc93e70b39160e7921475f9bcd7d31219ce&#x27;</span>)</span><br><span class="line"></span><br><span class="line">DATA_HUB[<span class="string">&#x27;kaggle_house_test&#x27;</span>] = (</span><br><span class="line">    DATA_URL + <span class="string">&#x27;kaggle_house_pred_test.csv&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;fa19780a7b011d9b009e8bff8e99922a8ee2eb90&#x27;</span>)</span><br><span class="line"></span><br><span class="line">DATA_URL = <span class="string">&#x27;http://d2l-data.s3-accelerate.amazonaws.com/&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">定义了一堆下载、解压的函数</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">download</span>(<span class="params">name, cache_dir=os.path.join(<span class="params"><span class="string">&#x27;..&#x27;</span>, <span class="string">&#x27;data&#x27;</span></span>)</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;下载一个DATA_HUB中的文件，返回本地文件名&quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">assert</span> name <span class="keyword">in</span> DATA_HUB, <span class="string">f&quot;<span class="subst">&#123;name&#125;</span> 不存在于 <span class="subst">&#123;DATA_HUB&#125;</span>&quot;</span></span><br><span class="line">    url, sha1_hash = DATA_HUB[name]</span><br><span class="line">    os.makedirs(cache_dir, exist_ok=<span class="literal">True</span>)</span><br><span class="line">    fname = os.path.join(cache_dir, url.split(<span class="string">&#x27;/&#x27;</span>)[-<span class="number">1</span>])</span><br><span class="line">    <span class="keyword">if</span> os.path.exists(fname):</span><br><span class="line">        sha1 = hashlib.sha1()</span><br><span class="line">        <span class="keyword">with</span> <span class="built_in">open</span>(fname, <span class="string">&#x27;rb&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">            <span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">                data = f.read(<span class="number">1048576</span>)</span><br><span class="line">                <span class="keyword">if</span> <span class="keyword">not</span> data:</span><br><span class="line">                    <span class="keyword">break</span></span><br><span class="line">                sha1.update(data)</span><br><span class="line">        <span class="keyword">if</span> sha1.hexdigest() == sha1_hash:</span><br><span class="line">            <span class="keyword">return</span> fname  <span class="comment"># 命中缓存</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&#x27;正在从<span class="subst">&#123;url&#125;</span>下载<span class="subst">&#123;fname&#125;</span>...&#x27;</span>)</span><br><span class="line">    r = requests.get(url, stream=<span class="literal">True</span>, verify=<span class="literal">True</span>)</span><br><span class="line">    <span class="keyword">with</span> <span class="built_in">open</span>(fname, <span class="string">&#x27;wb&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">        f.write(r.content)</span><br><span class="line">    <span class="keyword">return</span> fname</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">download_extract</span>(<span class="params">name, folder=<span class="literal">None</span></span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;下载并解压zip/tar文件&quot;&quot;&quot;</span></span><br><span class="line">    fname = download(name)</span><br><span class="line">    base_dir = os.path.dirname(fname)</span><br><span class="line">    data_dir, ext = os.path.splitext(fname)</span><br><span class="line">    <span class="keyword">if</span> ext == <span class="string">&#x27;.zip&#x27;</span>:</span><br><span class="line">        fp = zipfile.ZipFile(fname, <span class="string">&#x27;r&#x27;</span>)</span><br><span class="line">    <span class="keyword">elif</span> ext <span class="keyword">in</span> (<span class="string">&#x27;.tar&#x27;</span>, <span class="string">&#x27;.gz&#x27;</span>):</span><br><span class="line">        fp = tarfile.<span class="built_in">open</span>(fname, <span class="string">&#x27;r&#x27;</span>)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">assert</span> <span class="literal">False</span>, <span class="string">&#x27;只有zip/tar文件可以被解压缩&#x27;</span></span><br><span class="line">    fp.extractall(base_dir)</span><br><span class="line">    <span class="keyword">return</span> os.path.join(base_dir, folder) <span class="keyword">if</span> folder <span class="keyword">else</span> data_dir</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">download_all</span>():</span><br><span class="line">    <span class="string">&quot;&quot;&quot;下载DATA_HUB中的所有文件&quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">for</span> name <span class="keyword">in</span> DATA_HUB:</span><br><span class="line">        download(name)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 下载训练集和测试集</span></span><br><span class="line">download_all()</span><br></pre></td></tr></table></figure>
<pre><code>正在从http://d2l-data.s3-accelerate.amazonaws.com/kaggle_house_pred_train.csv下载..\data\kaggle_house_pred_train.csv...
正在从http://d2l-data.s3-accelerate.amazonaws.com/kaggle_house_pred_test.csv下载..\data\kaggle_house_pred_test.csv...
</code></pre><p>使用书中的代码下载的数据集存放在<code>../data/</code>中。结构目录如下：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">kaggle-house-prices/</span><br><span class="line">	code/</span><br><span class="line">		kaggle-house-prices.ipynb</span><br><span class="line">    data/</span><br><span class="line">    	kaggle_house_pred_train.csv</span><br><span class="line">    	kaggle_house_pred_test.csv</span><br></pre></td></tr></table></figure>
<p>下面进行数据读取和预处理。</p>
<h1 id="读取数据集"><a href="#读取数据集" class="headerlink" title="读取数据集"></a>读取数据集</h1><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 如果pandas没有被安装，请取消下一句的注释。</span></span><br><span class="line"><span class="comment"># !pip install pandas</span></span><br><span class="line"></span><br><span class="line">%matplotlib inline</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> nn</span><br><span class="line"><span class="keyword">from</span> d2l <span class="keyword">import</span> torch <span class="keyword">as</span> d2l</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">train_data = pd.read_csv(<span class="string">&quot;../data/kaggle_house_pred_train.csv&quot;</span>)</span><br><span class="line">test_data = pd.read_csv(<span class="string">&quot;../data/kaggle_house_pred_train.csv&quot;</span>)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 打印他们的行列数，这里test_data的列比train_data少1，少的是标签一列</span></span><br><span class="line"><span class="built_in">print</span>(train_data.shape)</span><br><span class="line"><span class="built_in">print</span>(test_data.shape)</span><br></pre></td></tr></table></figure>
<pre><code>(1460, 81)
(1460, 81)
</code></pre><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># print train_data 两个参数分别指出打印的行（样本）和列（特征）</span></span><br><span class="line"><span class="built_in">print</span>(train_data.iloc[<span class="number">0</span>:<span class="number">4</span>, [<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, -<span class="number">3</span>, -<span class="number">2</span>, -<span class="number">1</span>]])</span><br></pre></td></tr></table></figure>
<pre><code>   Id  MSSubClass MSZoning  LotFrontage SaleType SaleCondition  SalePrice
0   1          60       RL         65.0       WD        Normal     208500
1   2          20       RL         80.0       WD        Normal     181500
2   3          60       RL         68.0       WD        Normal     223500
3   4          70       RL         60.0       WD       Abnorml     140000
</code></pre><p>将train_data和test_data去掉第一个特征（第一个特征是ID，对训练无意义）的所有特征都放到all_features中：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">all_features = pd.concat((train_data.iloc[:, <span class="number">1</span>:-<span class="number">1</span>], test_data.iloc[:, <span class="number">1</span>:]))</span><br></pre></td></tr></table></figure>
<h2 id="数据预处理"><a href="#数据预处理" class="headerlink" title="数据预处理"></a>数据预处理</h2><p>在开始建模之前，我们需要对数据进行预处理。</p>
<p>对于数字特征，首先，<strong>将所有缺失的值替换为相应特征的平均值；</strong></p>
<p>然后，为了将所有特征放在一个共同的尺度上，我们<strong>通过将特征重新缩放到零均值和单位方差来标准化数据</strong>：</p>
<script type="math/tex; mode=display">
x \leftarrow \frac{x - \mu}{\sigma}.</script><p>此时，特征即具有零均值和单位方差，即 $E[\frac{x-\mu}{\sigma}] = \frac{\mu - \mu}{\sigma} = 0$和$E[(x-\mu)^2] = (\sigma^2 + \mu^2) - 2\mu^2+\mu^2 = \sigma^2$。</p>
<p>标准化数据有两个原因：</p>
<ul>
<li>方便优化；</li>
<li>我们不知道哪些特征是相关的，所以我们不想让惩罚分配给一个特征的系数比分配给其他任何特征的系数更大；</li>
<li>取消由于量纲不同、自身变异或者数值相差较大所引起的误差。</li>
</ul>
<p>更多关于标准化的知识请见<em>参考资料2</em></p>
<p>这里可以看到，书中提到的是先处理缺失值，再标准化；而实际代码是先标准化，再处理缺失值。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 若无法获得测试数据，则可根据训练数据计算均值和标准差</span></span><br><span class="line"><span class="comment"># 取出数字类型的特征索引</span></span><br><span class="line">numeric_features = all_features.dtypes[all_features.dtypes != <span class="string">&#x27;object&#x27;</span>].index</span><br><span class="line"><span class="comment"># 将数字类型的特征标准化</span></span><br><span class="line">all_features[numeric_features] = all_features[numeric_features].apply(</span><br><span class="line">    <span class="keyword">lambda</span> x: (x - x.mean()) / (x.std()))</span><br><span class="line"><span class="comment"># 在标准化数据之后，所有均值消失，因此我们可以将缺失值设置为0</span></span><br><span class="line">all_features[numeric_features] = all_features[numeric_features].fillna(<span class="number">0</span>)</span><br></pre></td></tr></table></figure>
<p>对于离散值，我们使用one-hot编码，就是特征的离散值转换为向量。例如，特征“type”的值包括cat，dog，rat，那么经过one-hot编码后会生成三个特征“type_cat”，“type_dog”，“type_rat”。如果原来“type”=cat，则“type_cat”=1，“type_dog”=0，“type_rat”=0。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># “Dummy_na=True”将“na”（缺失值）视为有效的特征值，并为其创建指示符特征</span></span><br><span class="line">all_features = pd.get_dummies(all_features, dummy_na=<span class="literal">True</span>)</span><br><span class="line">all_features.shape</span><br></pre></td></tr></table></figure>
<pre><code>(2920, 332)
</code></pre><p>可以看到，此转换会将特征的总数量从79个增加到331个。 最后，通过values属性，我们可以 从pandas格式中提取NumPy格式，并将其转换为张量表示用于训练。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">n_train = train_data.shape[<span class="number">0</span>]  <span class="comment"># 取得train_data的行数</span></span><br><span class="line"><span class="comment"># 取出all_features的train_data转换成tensor</span></span><br><span class="line">train_features = torch.tensor(all_features[:n_train].values, dtype=torch.float32)</span><br><span class="line"><span class="comment"># 取出all_features的test_data转换成tensor</span></span><br><span class="line">test_features = torch.tensor(all_features[n_train:].values, dtype=torch.float32)</span><br><span class="line"><span class="comment"># train_labels.shape[0] == n_train</span></span><br><span class="line"><span class="comment"># reshape(-1, 1)相当于把labels一行转为一列和train_features一一对应</span></span><br><span class="line">train_labels = torch.tensor(</span><br><span class="line">    train_data.SalePrice.values.reshape(-<span class="number">1</span>, <span class="number">1</span>), dtype=torch.float32)</span><br></pre></td></tr></table></figure>
<h1 id="训练"><a href="#训练" class="headerlink" title="训练"></a>训练</h1><p>首先，我们训练一个带有损失平方的线性模型。如果一切顺利，线性模型将作为基线（baseline）模型， 让我们直观地知道最好的模型有超出简单的模型多少。</p>
<p>损失函数：MSE Loss</p>
<p>基线模型：（个人理解）最先想到的、最简单的、结果比较差、一般在此基础上进行优化的模型。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">loss = nn.MSELoss()</span><br><span class="line">in_features = train_features.shape[<span class="number">1</span>]</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">get_net</span>():</span><br><span class="line">    net = nn.Sequential(nn.Linear(in_features,<span class="number">1</span>))</span><br><span class="line">    <span class="keyword">return</span> net</span><br></pre></td></tr></table></figure>
<p>对于房价，就像股票价格一样，我们关心的是相对数量，而不是绝对数量。因此，[<strong>我们更关心相对误差$\frac{y - \hat{y}}{y}$，</strong>]而不是绝对误差$y - \hat{y}$。例如，如果我们在俄亥俄州农村地区估计一栋房子的价格时，我们的预测偏差了10万美元，在那里一栋典型的房子的价值是12.5万美元，那么我们可能做得很糟糕。另一方面，如果我们在加州豪宅区的预测出现了这个数字的偏差，这可能是一个惊人的准确预测（在那里，房价均值超过400万美元）。</p>
<p>(<strong>解决这个问题的一种方法是用价格预测的对数来衡量差异</strong>)。事实上，这也是比赛中官方用来评价提交质量的误差指标。即将 $\delta$ for $|\log y - \log \hat{y}| \leq \delta$转换为$e^{-\delta} \leq \frac{\hat{y}}{y} \leq e^\delta$。这使得预测价格的对数与真实标签价格的对数之间出现以下均方根误差：</p>
<script type="math/tex; mode=display">
\sqrt{\frac{1}{n}\sum_{i=1}^n\left(\log y_i -\log \hat{y}_i\right)^2}.</script><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">log_rmse</span>(<span class="params">net, features, labels</span>):</span><br><span class="line">    <span class="comment"># 为了在取对数时进一步稳定该值，将小于1的值设置为1</span></span><br><span class="line">    <span class="comment"># clamp方法说明详见 参考资料5</span></span><br><span class="line">    clipped_preds = torch.clamp(net(features), <span class="number">1</span>, <span class="built_in">float</span>(<span class="string">&#x27;inf&#x27;</span>))</span><br><span class="line">    rmse = torch.sqrt(loss(torch.log(clipped_preds),</span><br><span class="line">                           torch.log(labels)))</span><br><span class="line">    <span class="keyword">return</span> rmse.item()</span><br></pre></td></tr></table></figure>
<blockquote>
<p>在这里，我一开始对损失函数（loss）和评价指标（metrics）没有理解，所以我对loss和log_rmse纠结了很久。</p>
<p>这里我的理解是，</p>
<p>loss是需要丢到网络里的，是网络优化的目标函数；因为需要通过梯度下降来反向传播，所以必须是可导的；</p>
<p>metrics是评价网络的一种指标，不参与优化；不需要可导。</p>
<p>更多关于损失函数和评价指标请参见<em>参考资料3</em>，<em>参考资料4</em></p>
</blockquote>
<hr>
<p>我们的训练函数将借助Adam优化器。</p>
<p>Adam优化器的主要吸引力在于它对初始学习率不那么敏感。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">train</span>(<span class="params">net, train_features, train_labels, test_features, test_labels,</span></span><br><span class="line"><span class="params">          num_epochs, learning_rate, weight_decay, batch_size</span>):</span><br><span class="line">    train_ls, test_ls = [], []</span><br><span class="line">    train_iter = d2l.load_array((train_features, train_labels), batch_size)</span><br><span class="line">    <span class="comment"># 这里使用的是Adam优化算法</span></span><br><span class="line">    optimizer = torch.optim.Adam(net.parameters(),</span><br><span class="line">                                 lr = learning_rate,</span><br><span class="line">                                 weight_decay = weight_decay)</span><br><span class="line">    <span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(num_epochs):</span><br><span class="line">        <span class="keyword">for</span> X, y <span class="keyword">in</span> train_iter:</span><br><span class="line">            optimizer.zero_grad()</span><br><span class="line">            l = loss(net(X), y)</span><br><span class="line">            l.backward()</span><br><span class="line">            optimizer.step()</span><br><span class="line">        train_ls.append(log_rmse(net, train_features, train_labels))</span><br><span class="line">        <span class="keyword">if</span> test_labels <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">            test_ls.append(log_rmse(net, test_features, test_labels))</span><br><span class="line">    <span class="keyword">return</span> train_ls, test_ls</span><br></pre></td></tr></table></figure>
<h1 id="K-折交叉验证"><a href="#K-折交叉验证" class="headerlink" title="K-折交叉验证"></a>K-折交叉验证</h1><p>所谓K-折交叉验证就是把train data分为K份，每次1/K份作为验证集，把另外的1 - 1/K份作为训练集。事实上，<code>get_k_fold_data</code>就是在做这件事。</p>
<p>K-折交叉验证有助于模型选择和超参数调整。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">get_k_fold_data</span>(<span class="params">k, i, X, y</span>):</span><br><span class="line">    <span class="keyword">assert</span> k &gt; <span class="number">1</span></span><br><span class="line">    fold_size = X.shape[<span class="number">0</span>] // k</span><br><span class="line">    X_train, y_train = <span class="literal">None</span>, <span class="literal">None</span></span><br><span class="line">    <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(k):</span><br><span class="line">        <span class="comment"># slice方法说明详见参考资料6</span></span><br><span class="line">        idx = <span class="built_in">slice</span>(j * fold_size, (j + <span class="number">1</span>) * fold_size)</span><br><span class="line">        X_part, y_part = X[idx, :], y[idx]</span><br><span class="line">        <span class="keyword">if</span> j == i:</span><br><span class="line">            X_valid, y_valid = X_part, y_part</span><br><span class="line">        <span class="keyword">elif</span> X_train <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">            X_train, y_train = X_part, y_part</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            X_train = torch.cat([X_train, X_part], <span class="number">0</span>) <span class="comment"># 将已有的X_train和X_part连接起来</span></span><br><span class="line">            y_train = torch.cat([y_train, y_part], <span class="number">0</span>)</span><br><span class="line">    <span class="keyword">return</span> X_train, y_train, X_valid, y_valid</span><br></pre></td></tr></table></figure>
<p><code>k_fold</code>中先求每一折得到的trian-loss, valid-loss，注意train_ls和valid_ls是一个list，存放了每次迭代后loss值，我们取train_ls[-1]，也就是最终的那个loss</p>
<p>最后把所有K-折得到的train-loss的平均和valid-loss的平均</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">k_fold</span>(<span class="params">k, X_train, y_train, num_epochs, learning_rate, weight_decay,</span></span><br><span class="line"><span class="params">           batch_size</span>):</span><br><span class="line">    train_l_sum, valid_l_sum = <span class="number">0</span>, <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(k):</span><br><span class="line">        <span class="comment"># 这里data实际是一个元组(X_train, y_train, X_valid, y_valid)</span></span><br><span class="line">        data = get_k_fold_data(k, i, X_train, y_train)</span><br><span class="line">        net = get_net()</span><br><span class="line">        <span class="comment"># 把data这个元组传入，对应train中的train_features, train_labels, test_features, test_labels四个参数</span></span><br><span class="line">        train_ls, valid_ls = train(net, *data, num_epochs, learning_rate,</span><br><span class="line">                                   weight_decay, batch_size)</span><br><span class="line">        train_l_sum += train_ls[-<span class="number">1</span>]</span><br><span class="line">        valid_l_sum += valid_ls[-<span class="number">1</span>]</span><br><span class="line">        <span class="keyword">if</span> i == <span class="number">0</span>:</span><br><span class="line">            d2l.plot(<span class="built_in">list</span>(<span class="built_in">range</span>(<span class="number">1</span>, num_epochs + <span class="number">1</span>)), [train_ls, valid_ls],</span><br><span class="line">                     xlabel=<span class="string">&#x27;epoch&#x27;</span>, ylabel=<span class="string">&#x27;rmse&#x27;</span>, xlim=[<span class="number">1</span>, num_epochs],</span><br><span class="line">                     legend=[<span class="string">&#x27;train&#x27;</span>, <span class="string">&#x27;valid&#x27;</span>], yscale=<span class="string">&#x27;log&#x27;</span>)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&#x27;折<span class="subst">&#123;i + <span class="number">1</span>&#125;</span>，训练log rmse<span class="subst">&#123;<span class="built_in">float</span>(train_ls[-<span class="number">1</span>]):f&#125;</span>, &#x27;</span></span><br><span class="line">              <span class="string">f&#x27;验证log rmse<span class="subst">&#123;<span class="built_in">float</span>(valid_ls[-<span class="number">1</span>]):f&#125;</span>&#x27;</span>)</span><br><span class="line">    <span class="keyword">return</span> train_l_sum / k, valid_l_sum / k</span><br></pre></td></tr></table></figure>
<h1 id="模型选择"><a href="#模型选择" class="headerlink" title="模型选择"></a>模型选择</h1><p>下面是一组超参数，后面我们可以对此进行调优（改改数， run run code）</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">k, num_epochs, lr, weight_decay, batch_size = <span class="number">5</span>, <span class="number">100</span>, <span class="number">5</span>, <span class="number">0</span>, <span class="number">64</span></span><br><span class="line">train_l, valid_l = k_fold(k, train_features, train_labels, num_epochs, lr,</span><br><span class="line">                          weight_decay, batch_size)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&#x27;<span class="subst">&#123;k&#125;</span>-折验证: 平均训练log rmse: <span class="subst">&#123;<span class="built_in">float</span>(train_l):f&#125;</span>, &#x27;</span></span><br><span class="line">      <span class="string">f&#x27;平均验证log rmse: <span class="subst">&#123;<span class="built_in">float</span>(valid_l):f&#125;</span>&#x27;</span>)</span><br></pre></td></tr></table></figure>
<pre><code>折1，训练log rmse0.168934, 验证log rmse0.158768
折2，训练log rmse0.162051, 验证log rmse0.186553
折3，训练log rmse0.163633, 验证log rmse0.167966
折4，训练log rmse0.167716, 验证log rmse0.154111
折5，训练log rmse0.161381, 验证log rmse0.184188
5-折验证: 平均训练log rmse: 0.164743, 平均验证log rmse: 0.170317
</code></pre><p><img src="kaggle-house-prices_31_1.svg" alt="svg"></p>
<p>请注意，有时一组超参数的训练误差可能非常低，但 K 折交叉验证的误差要高得多， 这表明模型过拟合了。 在整个训练过程中，你将希望监控训练误差和验证误差这两个数字。 较少的过拟合可能表明现有数据可以支撑一个更强大的模型， 较大的过拟合可能意味着我们可以通过正则化技术来获益。</p>
<h1 id="提交Kaggle预测"><a href="#提交Kaggle预测" class="headerlink" title="提交Kaggle预测"></a>提交Kaggle预测</h1><p>当我们用上面的K-折交叉验证确定参数后，我们将超参数固定住，把所有的train data拿来train。</p>
<p>如果测试集上的预测与 K 倍交叉验证过程中的预测相似， 那就是时候把它们上传到Kaggle了。 下面的代码将生成一个名为submission.csv的文件。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">train_and_pred</span>(<span class="params">train_features, test_feature, train_labels, test_data,</span></span><br><span class="line"><span class="params">                   num_epochs, lr, weight_decay, batch_size</span>):</span><br><span class="line">    net = get_net()</span><br><span class="line">    train_ls, _ = train(net, train_features, train_labels, <span class="literal">None</span>, <span class="literal">None</span>,</span><br><span class="line">                        num_epochs, lr, weight_decay, batch_size)</span><br><span class="line">    d2l.plot(np.arange(<span class="number">1</span>, num_epochs + <span class="number">1</span>), [train_ls], xlabel=<span class="string">&#x27;epoch&#x27;</span>,</span><br><span class="line">             ylabel=<span class="string">&#x27;log rmse&#x27;</span>, xlim=[<span class="number">1</span>, num_epochs], yscale=<span class="string">&#x27;log&#x27;</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&#x27;训练log rmse：<span class="subst">&#123;<span class="built_in">float</span>(train_ls[-<span class="number">1</span>]):f&#125;</span>&#x27;</span>)</span><br><span class="line">    <span class="comment"># 将网络应用于测试集。</span></span><br><span class="line">    preds = net(test_features).detach().numpy()</span><br><span class="line">    <span class="comment"># 将其重新格式化以导出到Kaggle</span></span><br><span class="line">    test_data[<span class="string">&#x27;SalePrice&#x27;</span>] = pd.Series(preds.reshape(<span class="number">1</span>, -<span class="number">1</span>)[<span class="number">0</span>])</span><br><span class="line">    submission = pd.concat([test_data[<span class="string">&#x27;Id&#x27;</span>], test_data[<span class="string">&#x27;SalePrice&#x27;</span>]], axis=<span class="number">1</span>)</span><br><span class="line">    submission.to_csv(<span class="string">&#x27;submission.csv&#x27;</span>, index=<span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line">train_and_pred(train_features, test_features, train_labels, test_data,</span><br><span class="line">               num_epochs, lr, weight_decay, batch_size)</span><br></pre></td></tr></table></figure>
<pre><code>训练log rmse：0.162150
</code></pre><p><img src="kaggle-house-prices_34_1.svg" alt="svg"></p>
<p>接下来我们将生成的<code>submission.csv</code>文件提交到Kaggle：</p>
<ul>
<li>访问<a target="_blank" rel="noopener" href="https://www.kaggle.com/c/house-prices-advanced-regression-techniques/data">https://www.kaggle.com/c/house-prices-advanced-regression-techniques/data</a></li>
<li>点击“Submit Predictions”</li>
<li>选择你要上传的预测文件<code>submission.csv</code></li>
<li>点击页面底部的“Make Submission”按钮，即可查看结果。</li>
</ul>
<h1 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h1><ul>
<li>真实数据通常混合了不同的数据类型，需要进行预处理。</li>
<li>常用的预处理方法：将实值数据重新缩放为零均值和单位方法；用均值替换缺失值。</li>
<li>将类别特征转化为指标特征，可以使我们把这个特征当作一个独热向量来对待。</li>
<li>我们可以使用 K 折交叉验证来选择模型并调整超参数。</li>
<li>对数对于相对误差很有用。</li>
</ul>
<h1 id="更进一步"><a href="#更进一步" class="headerlink" title="更进一步"></a>更进一步</h1><p>这里是书中给出的一些思考问题，我没做，但是依然列出来供参考：</p>
<ol>
<li>将试图预测价格改为试图预测价格的对数，会发生什么？</li>
<li>用平均值替换缺失值总是好主意吗？提示：你能构造一个不随机丢失值的情况吗？</li>
<li>通过 K 折交叉验证调整超参数，从而提高Kaggle的得分。</li>
<li>通过改进模型（例如，层、权重衰减和dropout）来提高分数。</li>
<li>如果我们没有像本节所做的那样标准化连续的数值特征，会发生什么？</li>
</ol>
<h1 id="后记"><a href="#后记" class="headerlink" title="后记"></a>后记</h1><p>我仔细阅读原文，捋了一边代码。</p>
<p>基础比较差，有些地方认识不太清晰，全凭自己理解，如有错误，请多包涵，或直接邮箱联系我。</p>
<p>我原以为会有训练模型错误率不断降低的成就感。。但实际上全是复制粘贴run code。</p>
<p>好像学到了又好像没学到。🤦‍</p>
<h1 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h1><ol>
<li><a target="_blank" rel="noopener" href="http://zh-v2.d2l.ai/chapter_multilayer-perceptrons/kaggle-house-price.html#id6">《动手学深度学习》 4.10. 实战Kaggle比赛：预测房价</a></li>
<li><a target="_blank" rel="noopener" href="https://www.cnblogs.com/wangqiang9/p/9285594.html">数据预处理之中心化（零均值化）与标准化（归一化）</a></li>
<li><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/373032887">机器学习——损失函数(loss)与评价指标(metric)的区别？</a></li>
<li><a target="_blank" rel="noopener" href="https://codeantenna.com/a/7p6uOqnNhx">keras中compile方法的 loss 和 metrics 区别</a></li>
<li><a target="_blank" rel="noopener" href="https://pytorch.org/docs/stable/generated/torch.clamp.html">torch.clamp方法说明</a></li>
<li><a target="_blank" rel="noopener" href="https://www.runoob.com/python/python-func-slice.html">Python slice方法说明</a></li>
<li><a target="_blank" rel="noopener" href="https://blog.csdn.net/m0_37871195/article/details/79829488">深度学习中iteration、epoch、batchsize的定义</a></li>
<li><a target="_blank" rel="noopener" href="https://pytorch.org/docs/1.9.1/generated/torch.Tensor.detach.html">torch.detach方法说明</a></li>
<li><a target="_blank" rel="noopener" href="https://pytorch.org/docs/stable/generated/torch.cat.html#torch.cat">torch.cat方法说明</a></li>
<li><a target="_blank" rel="noopener" href="https://csbwang.github.io/dl_ch2">机器学习基础</a></li>
</ol>
</div></article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">文章作者: </span><span class="post-copyright-info"><a href="mailto:undefined">Met Guo</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">文章链接: </span><span class="post-copyright-info"><a href="https://guoyujian.github.io/2022/01/12/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E8%AE%AD%E7%BB%83%E5%88%9D%E4%BD%93%E9%AA%8C-%E6%88%BF%E4%BB%B7%E9%A2%84%E6%B5%8B%E6%AF%94%E8%B5%9B/">https://guoyujian.github.io/2022/01/12/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E8%AE%AD%E7%BB%83%E5%88%9D%E4%BD%93%E9%AA%8C-%E6%88%BF%E4%BB%B7%E9%A2%84%E6%B5%8B%E6%AF%94%E8%B5%9B/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a target="_blank" rel="noopener" href="https://creativecommons.org/licenses/by-nc-sa/4.0/">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="https://guoyujian.github.io">Gmet's Blog</a>！</span></div></div><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">深度学习</a></div><nav id="pagination"><div class="prev-post pull-left"><a href="/2022/01/15/HTTP%E5%8D%8F%E8%AE%AE%E7%9A%84%E5%B9%82%E7%AD%89%E6%80%A7/"><i class="fa fa-chevron-left">  </i><span>HTTP协议的幂等性</span></a></div><div class="next-post pull-right"><a href="/2022/01/10/%E3%80%8A%E5%8A%A8%E6%89%8B%E5%AD%A6%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E3%80%8B%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0%EF%BC%88%E4%B8%80%EF%BC%89-%E5%89%8D%E8%A8%80/"><span>《动手学深度学习》读书笔记（一） 前言</span><i class="fa fa-chevron-right"></i></a></div></nav></div></div><footer class="footer-bg" style="background-image: url(https://images7.alphacoders.com/550/thumb-1920-550739.jpg)"><div class="layout" id="footer"><div class="copyright">&copy;2021 - 2023 By Met Guo</div><div class="framework-info"><span>驱动 - </span><a target="_blank" rel="noopener" href="http://hexo.io"><span>Hexo</span></a><span class="footer-separator">|</span><span>主题 - </span><a target="_blank" rel="noopener" href="https://github.com/Molunerfinn/hexo-theme-melody"><span>Melody</span></a></div><div class="footer_custom_text">hitokoto</div><div class="busuanzi"><script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><span id="busuanzi_container_page_pv"><i class="fa fa-file"></i><span id="busuanzi_value_page_pv"></span><span></span></span></div></div></footer><i class="fa fa-arrow-up" id="go-up" aria-hidden="true"></i><script src="https://cdn.jsdelivr.net/npm/animejs@latest/anime.min.js"></script><script src="https://cdn.jsdelivr.net/npm/jquery@latest/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.js"></script><script src="https://cdn.jsdelivr.net/npm/velocity-animate@latest/velocity.min.js"></script><script src="https://cdn.jsdelivr.net/npm/velocity-ui-pack@latest/velocity.ui.min.js"></script><script src="/js/utils.js?version=1.8.2"></script><script src="/js/fancybox.js?version=1.8.2"></script><script src="/js/sidebar.js?version=1.8.2"></script><script src="/js/copy.js?version=1.8.2"></script><script src="/js/fireworks.js?version=1.8.2"></script><script src="/js/transition.js?version=1.8.2"></script><script src="/js/scroll.js?version=1.8.2"></script><script src="/js/head.js?version=1.8.2"></script><script src="/js/search/algolia.js"></script><script type="text/x-mathjax-config">MathJax.Hub.Config({
  tex2jax: {
    inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
    processEscapes: true,
    skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
  },
  CommonHTML: {
    linebreaks: { automatic: true, width: "90% container" }
  },
  "HTML-CSS": { 
    linebreaks: { automatic: true, width: "90% container" }
  },
  "SVG": { 
    linebreaks: { automatic: true, width: "90% container" }
  }
});
</script><script type="text/x-mathjax-config">MathJax.Hub.Queue(function() {
  var all = MathJax.Hub.getAllJax(), i;
  for (i=0; i < all.length; i += 1) {
    all[i].SourceElement().parentNode.className += ' has-jax';
  }
});
</script><script src="https://cdn.jsdelivr.net/npm/mathjax/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script><script>if(/Android|webOS|iPhone|iPod|iPad|BlackBerry/i.test(navigator.userAgent)) {
  $('#nav').addClass('is-mobile')
  $('footer').addClass('is-mobile')
  $('#top-container').addClass('is-mobile')
}</script><div class="search-dialog" id="algolia-search"><div class="search-dialog__title" id="algolia-search-title">Algolia</div><div id="algolia-input-panel"><div id="algolia-search-input"></div></div><hr><div id="algolia-search-results"><div id="algolia-hits"></div><div id="algolia-pagination"></div><div id="algolia-stats"></div></div><span class="search-close-button"><i class="fa fa-times"></i></span></div><div class="search-mask"></div></body></html>