<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Gmet&#39;s Blog</title>
  
  <subtitle>Eureka!</subtitle>
  <link href="https://guoyujian.github.io/atom.xml" rel="self"/>
  
  <link href="https://guoyujian.github.io/"/>
  <updated>2022-11-07T14:33:39.446Z</updated>
  <id>https://guoyujian.github.io/</id>
  
  <author>
    <name>Met Guo</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>SSH三步解决免密登录</title>
    <link href="https://guoyujian.github.io/2022/11/07/SSH%E4%B8%89%E6%AD%A5%E8%A7%A3%E5%86%B3%E5%85%8D%E5%AF%86%E7%99%BB%E5%BD%95/"/>
    <id>https://guoyujian.github.io/2022/11/07/SSH%E4%B8%89%E6%AD%A5%E8%A7%A3%E5%86%B3%E5%85%8D%E5%AF%86%E7%99%BB%E5%BD%95/</id>
    <published>2022-11-07T14:29:07.000Z</published>
    <updated>2022-11-07T14:33:39.446Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Refs"><a href="#Refs" class="headerlink" title="Refs"></a>Refs</h1><ol><li><a href="https://blog.csdn.net/jeikerxiao/article/details/84105529">SSH 三步解决免密登录</a></li></ol>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;Refs&quot;&gt;&lt;a href=&quot;#Refs&quot; class=&quot;headerlink&quot; title=&quot;Refs&quot;&gt;&lt;/a&gt;Refs&lt;/h1&gt;&lt;ol&gt;
&lt;li&gt;&lt;a href=&quot;https://blog.csdn.net/jeikerxiao/article/detail</summary>
      
    
    
    
    <category term="Linux" scheme="https://guoyujian.github.io/categories/Linux/"/>
    
    <category term="开发工具" scheme="https://guoyujian.github.io/categories/Linux/%E5%BC%80%E5%8F%91%E5%B7%A5%E5%85%B7/"/>
    
    
    <category term="开发工具" scheme="https://guoyujian.github.io/tags/%E5%BC%80%E5%8F%91%E5%B7%A5%E5%85%B7/"/>
    
  </entry>
  
  <entry>
    <title>FATE使用遇到的问题汇总</title>
    <link href="https://guoyujian.github.io/2022/11/04/FATE%E4%BD%BF%E7%94%A8%E9%81%87%E5%88%B0%E7%9A%84%E9%97%AE%E9%A2%98%E6%B1%87%E6%80%BB/"/>
    <id>https://guoyujian.github.io/2022/11/04/FATE%E4%BD%BF%E7%94%A8%E9%81%87%E5%88%B0%E7%9A%84%E9%97%AE%E9%A2%98%E6%B1%87%E6%80%BB/</id>
    <published>2022-11-03T16:11:41.000Z</published>
    <updated>2022-11-03T16:13:55.018Z</updated>
    
    <content type="html"><![CDATA[<p>本文汇总在使用和开发FATE时遇到的各类问题，以及给出可能的解决方案。</p><h1 id="flow-init"><a href="#flow-init" class="headerlink" title="flow init"></a>flow init</h1><h2 id="问题状态"><a href="#问题状态" class="headerlink" title="问题状态"></a>问题状态</h2><p>已解决</p><h2 id="问题描述"><a href="#问题描述" class="headerlink" title="问题描述"></a>问题描述</h2><p>首次进入fate-client时，提示需要执行flow init，否则有关flow的命令都执行不了。</p><h2 id="解决方案"><a href="#解决方案" class="headerlink" title="解决方案"></a>解决方案</h2><p><code>flow init --ip &lt;docker容器宿主机ip&gt; --port 9380</code></p><p>‍</p><h1 id="ModuleNotFoundError-No-module-named-‘-lzma’"><a href="#ModuleNotFoundError-No-module-named-‘-lzma’" class="headerlink" title="ModuleNotFoundError: No module named ‘_lzma’"></a>ModuleNotFoundError: No module named ‘_lzma’</h1><h2 id="问题描述-1"><a href="#问题描述-1" class="headerlink" title="问题描述"></a>问题描述</h2><p>执行任务时，nn模块报错：ModuleNotFoundError: No module named ‘_lzma’</p><p><img src="image-20220927210914-c8pbaiz.png" alt="image.png"></p><h2 id="解决方案-1"><a href="#解决方案-1" class="headerlink" title="解决方案"></a>解决方案</h2><p>在fate-flow container安装相关的包即可（guest、host和arbiter都要安装）。安装教程：<a href="https://github.com/ultralytics/yolov5/issues/1298">https://github.com/ultralytics/yolov5/issues/1298</a></p><p>这里需要修改路径</p><p><img src="image-20220928115429-n9l4hgw.png" alt="image.png"></p><h1 id="找不到文件：No-such-file-or-directory-‘-data-projects-fate-work-mnist-fed-mnist-train-part2-config-yaml’"><a href="#找不到文件：No-such-file-or-directory-‘-data-projects-fate-work-mnist-fed-mnist-train-part2-config-yaml’" class="headerlink" title="找不到文件：No such file or directory: ‘/data/projects/fate/work/mnist_fed/mnist_train_part2/config.yaml’"></a>找不到文件：<strong>No such file or directory: ‘/data/projects/fate/work/mnist_fed/mnist_train_part2/config.yaml’</strong></h1><h2 id="问题状态-1"><a href="#问题状态-1" class="headerlink" title="问题状态"></a>问题状态</h2><p>已解决</p><h2 id="问题描述-2"><a href="#问题描述-2" class="headerlink" title="问题描述"></a>问题描述</h2><p>在执行任务时，reader组件报错：</p><p><img src="image-20220927205925-34fvaot.png" alt="image.png"></p><p>这是由于我把数据保存在了fate-client，而fate读取数据是在fate-flow container导致的。</p><h2 id="解决方案-2"><a href="#解决方案-2" class="headerlink" title="解决方案"></a>解决方案</h2><p>由于fate-client和fate-flow两个容器中的examples文件夹挂载到docker底层同一处存储。所以把数据放到examples下，把配置修改为新的文件路径即可。</p><h1 id="开发新的FATE-FLOW-API"><a href="#开发新的FATE-FLOW-API" class="headerlink" title="开发新的FATE-FLOW API"></a>开发新的FATE-FLOW API</h1><p>这里是已有的API：<a href="https://federatedai.github.io/FATE-Flow/latest/zh/swagger/">https://federatedai.github.io/FATE-Flow/latest/zh/swagger/</a></p><p>FATE的HTTP接口都是基于flask框架编写的。</p><p>开发步骤如下：</p><ol><li>进入FATE-FLOW容器</li><li>cd /data/projects/fate/fateflow/python/fate_flow/apps</li><li>新建python文件，命名为xxx_app.py，编写新的接口。</li><li>重启FLOW容器</li></ol><h1 id="修改代码导致docker-container没起来"><a href="#修改代码导致docker-container没起来" class="headerlink" title="修改代码导致docker container没起来"></a>修改代码导致docker container没起来</h1><p>修改FATE-FLOW的代码后，由于代码有bug，导致容器起不来，又导致不能进入容器修改代码的死循环，怎么办？</p><p>查看docker容器的启动日志，确定出错的代码，docker cp拷贝出来需要修改的代码，再拷贝回去。</p><p>‍</p><h1 id="实际训练的epoch小于配置的max-iter"><a href="#实际训练的epoch小于配置的max-iter" class="headerlink" title="实际训练的epoch小于配置的max_iter"></a>实际训练的epoch小于配置的max_iter</h1><p>查看自己是否在配置文件中配置了：</p><figure class="highlight json"><table><tr><td class="code"><pre><span class="line"><span class="attr">&quot;early_stop&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">    <span class="attr">&quot;early_stop&quot;</span><span class="punctuation">:</span> <span class="string">&quot;diff&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;eps&quot;</span><span class="punctuation">:</span> <span class="number">0.0001</span></span><br><span class="line"><span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br></pre></td></tr></table></figure><p>这里的意思是，如果两个epoch得到的loss之差小于0.0001时则停止训练。</p><h1 id="memory-error"><a href="#memory-error" class="headerlink" title="memory error"></a>memory error</h1><p>根据实践经验，memory error 还有dataloader worker pid之类的错误，均是由于内存不够引起的。调小batch size，或者增加硬件配置</p><p>‍</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;本文汇总在使用和开发FATE时遇到的各类问题，以及给出可能的解决方案。&lt;/p&gt;
&lt;h1 id=&quot;flow-init&quot;&gt;&lt;a href=&quot;#flow-init&quot; class=&quot;headerlink&quot; title=&quot;flow init&quot;&gt;&lt;/a&gt;flow init&lt;/h1&gt;&lt;h</summary>
      
    
    
    
    <category term="联邦学习" scheme="https://guoyujian.github.io/categories/%E8%81%94%E9%82%A6%E5%AD%A6%E4%B9%A0/"/>
    
    
    <category term="联邦学习" scheme="https://guoyujian.github.io/tags/%E8%81%94%E9%82%A6%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>FATE横向联邦学习：肺炎的多模态任务的联邦学习</title>
    <link href="https://guoyujian.github.io/2022/11/04/FATE%E6%A8%AA%E5%90%91%E8%81%94%E9%82%A6%E5%AD%A6%E4%B9%A0%EF%BC%9A%E8%82%BA%E7%82%8E%E7%9A%84%E5%A4%9A%E6%A8%A1%E6%80%81%E4%BB%BB%E5%8A%A1%E7%9A%84%E8%81%94%E9%82%A6%E5%AD%A6%E4%B9%A0/"/>
    <id>https://guoyujian.github.io/2022/11/04/FATE%E6%A8%AA%E5%90%91%E8%81%94%E9%82%A6%E5%AD%A6%E4%B9%A0%EF%BC%9A%E8%82%BA%E7%82%8E%E7%9A%84%E5%A4%9A%E6%A8%A1%E6%80%81%E4%BB%BB%E5%8A%A1%E7%9A%84%E8%81%94%E9%82%A6%E5%AD%A6%E4%B9%A0/</id>
    <published>2022-11-03T16:10:23.000Z</published>
    <updated>2022-11-03T16:11:17.397Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>多模态最近比较火</p><p>多模态任务的input和算法FATE不支持，因此需要开发新的dataloader和算法组件。</p><p>本篇就以肺炎多模态任务为例，介绍如何开发新的FATE机器学习组件</p><p>官方文档在这里：<a href="https://fate.readthedocs.io/en/latest/develop/develop_guide/#develop-an-algorithm-component-of-fate">https://fate.readthedocs.io/en/latest/develop/develop_guide/#develop-an-algorithm-component-of-fate</a></p></blockquote><h1 id="baseline"><a href="#baseline" class="headerlink" title="baseline"></a>baseline</h1><p>本任务将开发基于肺部X光图像和描述文字正确判断是否患有肺炎的二分类算法。</p><p>数据集输入由两部分组成。一部分为肺部X光扫描图像，另一部分为对图像的描述文字。数据标签分为0和1，分别对应正常和患有肺炎两类标签。</p><h2 id="本地代码复现"><a href="#本地代码复现" class="headerlink" title="本地代码复现"></a>本地代码复现</h2><ol><li>baseline 代码在这里：<a href="https://github.com/AxelAllen/Multimodal-BERT-in-Medical-Image-and-Text-Classification">https://github.com/AxelAllen/Multimodal-BERT-in-Medical-Image-and-Text-Classification</a></li><li>将其clone到本地，按照README.md的提示，将NLMCXR_png_frontal图像文件夹放到data目录下。执行data/preparations.ipynb生成元数据。</li><li>执行run_mmbt.ipynb</li><li>执行完毕后，会在根目录下生成mmbt_output_findings_10epochs_n文件夹，里面保存有模型拟合后的梯度和评估结果。</li></ol><h2 id="阅读代码"><a href="#阅读代码" class="headerlink" title="阅读代码"></a>阅读代码</h2><p>这里要弄清楚代码的整套流程，主要是超参、使用的算法、训练、数据处理和加载，模型如何评估这几步。这里只展示核心代码</p><h3 id="超参"><a href="#超参" class="headerlink" title="超参"></a>超参</h3><div class="table-container"><table><thead><tr><th>参数</th><th>值</th></tr></thead><tbody><tr><td>Epoch</td><td>10</td></tr><tr><td>Bacth_size</td><td>16/32</td></tr><tr><td>Optimizer</td><td>AdamW</td></tr><tr><td>LR</td><td>5e-5</td></tr><tr><td>Loss</td><td>CrossEntropyLoss</td></tr><tr><td>Metrics</td><td>Accuracy</td></tr></tbody></table></div><blockquote><p>有趣的是，如果batch size = 4，模型无法训练处任何结果。</p></blockquote><h3 id="算法"><a href="#算法" class="headerlink" title="算法"></a>算法</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 部分code</span></span><br><span class="line"></span><br><span class="line">transformer_config = AutoConfig.from_pretrained(args.config_name <span class="keyword">if</span> args.config_name <span class="keyword">else</span> args.model_name, num_labels=num_labels)</span><br><span class="line">tokenizer = AutoTokenizer.from_pretrained(</span><br><span class="line">        args.tokenizer_name <span class="keyword">if</span> args.tokenizer_name <span class="keyword">else</span> args.model_name,</span><br><span class="line">        do_lower_case=<span class="literal">True</span>,</span><br><span class="line">        cache_dir=<span class="literal">None</span>,</span><br><span class="line">    )</span><br><span class="line">transformer = AutoModel.from_pretrained(args.model_name, config=transformer_config, cache_dir=<span class="literal">None</span>)</span><br><span class="line">img_encoder = ImageEncoderDenseNet(num_image_embeds=args.num_image_embeds)</span><br><span class="line">multimodal_config = MMBTConfig(transformer, img_encoder, num_labels=num_labels, modal_hidden_size=<span class="number">1024</span>)</span><br><span class="line">model = MMBTForClassification(transformer_config, multimodal_config)</span><br></pre></td></tr></table></figure><p>使用MMBT模型: 用于图像和文本分类的有监督多模态双向Transformer。</p><ul><li>图像编码器使用的ChexNet，这是一个针对X光胸片肺炎检测的模型；</li><li>文本编码器使用的预训练的BERT模型：bert-base-uncased。</li></ul><p>整体网络结构如图</p><p><img src="image-20221102150400-2suo5cw.png" alt="image">​</p><p>‍</p><h3 id="data-loader"><a href="#data-loader" class="headerlink" title="data loader"></a>data loader</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 部分code</span></span><br><span class="line">dataset = JsonlDataset(path, img_dir, tokenizer, img_transforms, labels, wandb_config.max_seq_length -</span><br><span class="line">                       wandb_config.num_image_embeds - <span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">...</span><br><span class="line">train_dataloader = DataLoader(</span><br><span class="line">    train_dataset,</span><br><span class="line">    sampler=train_sampler,</span><br><span class="line">    batch_size=args.train_batch_size,</span><br><span class="line">    collate_fn=collate_fn</span><br><span class="line">)</span><br></pre></td></tr></table></figure><h3 id="train"><a href="#train" class="headerlink" title="train"></a>train</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 部分code</span></span><br><span class="line"><span class="keyword">for</span> _ <span class="keyword">in</span> train_iterator:</span><br><span class="line">    epoch_iterator = tqdm(train_dataloader, desc=<span class="string">&quot;Training Batch Iteration&quot;</span>)</span><br><span class="line">    <span class="keyword">for</span> step, batch <span class="keyword">in</span> <span class="built_in">enumerate</span>(epoch_iterator):</span><br><span class="line"></span><br><span class="line">        batch = <span class="built_in">tuple</span>(t.to(args.device) <span class="keyword">for</span> t <span class="keyword">in</span> batch)</span><br><span class="line">        labels = batch[<span class="number">5</span>]</span><br><span class="line">        input_ids = batch[<span class="number">0</span>]</span><br><span class="line">        input_modal = batch[<span class="number">2</span>]</span><br><span class="line">        attention_mask = batch[<span class="number">1</span>]</span><br><span class="line">        modal_start_tokens = batch[<span class="number">3</span>]</span><br><span class="line">        modal_end_tokens = batch[<span class="number">4</span>]</span><br><span class="line"></span><br><span class="line">        outputs = model(</span><br><span class="line">            input_modal,</span><br><span class="line">            input_ids=input_ids,</span><br><span class="line">            modal_start_tokens=modal_start_tokens,</span><br><span class="line">            modal_end_tokens=modal_end_tokens,</span><br><span class="line">            attention_mask=attention_mask,</span><br><span class="line">            token_type_ids=<span class="literal">None</span>,</span><br><span class="line">            modal_token_type_ids=<span class="literal">None</span>,</span><br><span class="line">            position_ids=<span class="literal">None</span>,</span><br><span class="line">            modal_position_ids=<span class="literal">None</span>,</span><br><span class="line">            head_mask=<span class="literal">None</span>,</span><br><span class="line">            inputs_embeds=<span class="literal">None</span>,</span><br><span class="line">            labels=labels,</span><br><span class="line">            return_dict=<span class="literal">True</span></span><br><span class="line">        )</span><br><span class="line">        logits = outputs.logits</span><br><span class="line">        loss = outputs.loss</span><br><span class="line">        loss.backward()</span><br></pre></td></tr></table></figure><h3 id="评估"><a href="#评估" class="headerlink" title="评估"></a>评估</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 部分代码</span></span><br><span class="line">result = evaluate(args, model, tokenizer, evaluate=<span class="literal">True</span>, test=<span class="literal">True</span>, prefix=prefix)</span><br></pre></td></tr></table></figure><h1 id="开发新组件"><a href="#开发新组件" class="headerlink" title="开发新组件"></a>开发新组件</h1><p>当我们已经在本地跑通代码，并明确算法之后，就可以开发新的组件，将算法联邦化。</p><p>这里官方文档写的很清楚，我大概复述一下</p><h3 id="Step-1-Define-the-python-parameter-object-to-be-used-by-this-component"><a href="#Step-1-Define-the-python-parameter-object-to-be-used-by-this-component" class="headerlink" title="Step 1. Define the python parameter object to be used by this component"></a>Step 1. Define the python parameter object to be used by this component</h3><ol><li>Open a new python file called <code>xxx_param.py</code>​, where xxx stands for your component’s name. Place this file in the folder <code>python/federatedm/param/</code>​. The class object defined in <code>xxx_param.py</code>​ should inherit the <code>BaseParam</code>​ class declared in <code>python/federatedml/param/base_param.py</code>​</li><li>The <code>__init__</code>​ method of your parameter class should specify all parameters that the component uses.</li><li>Override and implement the <code>check</code>​ interface method of BaseParam. The <code>check</code>​ method is used to validate the parameter variables.</li><li><code>python/federatedml/param/__init__.py</code>​列表<code>__all__</code>​增加你的组件名称，并导入。</li></ol><p>我这里组件名称叫homo_mm，所以创建的python文件名为homo_mm_param.py。由于和homo_nn很像，所以直接讲homo_nn_param.py复制过来，将里面的“nn”改成“mm”。</p><p>第四步增加了</p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> federatedml.param.homo_mm_param <span class="keyword">import</span> HomoMMParam</span><br><span class="line">...</span><br><span class="line">__all__ = [... <span class="string">&quot;HomoMMParam&quot;</span>, ...]</span><br></pre></td></tr></table></figure><p>python/federatedml/param/<strong>init</strong>.py</p><h3 id="Step-2-Define-the-meta-file-of-the-new-component"><a href="#Step-2-Define-the-meta-file-of-the-new-component" class="headerlink" title="Step 2. Define the meta file of the new component"></a>Step 2. Define the meta file of the new component</h3><ol><li>Define component meta python file under <code>python/federatedml/components/</code>​, name it as <code>xxx.py</code>​, where xxx stands for the algorithm component being developed.</li><li>Implement the meta file.</li></ol><p>我这里组件名称叫homo_mm，所以创建的python文件名为homo_mm.py。由于和homo_nn很像，所以直接讲homo_nn.py复制过来，将里面的“nn”改成“mm”。</p><h3 id="Step-3-Define-the-transfer-variable-object-of-this-module-Optional"><a href="#Step-3-Define-the-transfer-variable-object-of-this-module-Optional" class="headerlink" title="Step 3. Define the transfer variable object of this module. (Optional)"></a>Step 3. Define the transfer variable object of this module. (Optional)</h3><p>这里不需要</p><h3 id="Step-4-Create-the-component-which-inherits-the-class-model-base​"><a href="#Step-4-Create-the-component-which-inherits-the-class-model-base​" class="headerlink" title="Step 4. Create the component which inherits the class model_base​"></a>Step 4. Create the component which inherits the class <code>model_base</code>​</h3><p>现在就可以将<code>python/federatedml/nn/homo_nn</code>​复制一份，修改为homo_mm，修改_torch.py文件</p><p>详略。</p><h3 id="additional"><a href="#additional" class="headerlink" title="additional"></a>additional</h3><p>需要注意在<code>python/federatedml/nn/backend/pytorch/data.py</code>​新建新的dataset。并在_torch中的make_dataset创建，这里可以参照VisionDataSet</p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">MMDataSet</span>(<span class="title class_ inherited__">DatasetMixIn</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">get_num_labels</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">None</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">get_num_features</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">None</span></span><br><span class="line">  </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">get_keys</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">return</span> self._keys</span><br><span class="line">  </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">as_data_instance</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">from</span> federatedml.feature.instance <span class="keyword">import</span> Instance</span><br><span class="line"></span><br><span class="line">        <span class="keyword">def</span> <span class="title function_">_as_instance</span>(<span class="params">x</span>):</span><br><span class="line">            <span class="keyword">if</span> <span class="built_in">isinstance</span>(x, np.number):</span><br><span class="line">                <span class="keyword">return</span> Instance(label=x.tolist())</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                <span class="keyword">return</span> Instance(label=x)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> computing_session.parallelize(</span><br><span class="line">            data=<span class="built_in">zip</span>(self._keys, <span class="built_in">map</span>(_as_instance, self.targets)),</span><br><span class="line">            include_key=<span class="literal">True</span>,</span><br><span class="line">            partition=<span class="number">1</span>,</span><br><span class="line">        )</span><br><span class="line">  </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self,train_data_path, is_train=<span class="literal">True</span>, expected_label_type=np.float32,**kwargs</span>):</span><br><span class="line"><span class="comment"># 这里必须加上，否则会卡在标签对齐且不报错</span></span><br><span class="line">        <span class="keyword">if</span> is_train:</span><br><span class="line">            HomoLabelEncoderClient().label_alignment([<span class="string">&quot;fake&quot;</span>])</span><br><span class="line"></span><br><span class="line">        tokenizer = AutoTokenizer.from_pretrained(</span><br><span class="line">            <span class="string">&quot;bert-base-uncased&quot;</span>,</span><br><span class="line">            do_lower_case=<span class="literal">True</span>,</span><br><span class="line">            cache_dir=<span class="literal">None</span>,</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">        labels = [<span class="number">0</span>,<span class="number">1</span>]</span><br><span class="line">        labels2id = &#123;<span class="string">&#x27;0&#x27;</span>: <span class="number">0</span>, <span class="string">&#x27;1&#x27;</span>: <span class="number">1</span>&#125;</span><br><span class="line">        self.labels2id = labels2id</span><br><span class="line">        self.data = [json.loads(line) <span class="keyword">for</span> line <span class="keyword">in</span> <span class="built_in">open</span>(os.path.join(train_data_path, <span class="string">&quot;meta.jsonl&quot;</span>))]</span><br><span class="line"></span><br><span class="line">        self.targets = [ item[<span class="string">&#x27;label&#x27;</span>] <span class="keyword">for</span> item <span class="keyword">in</span> self.data]</span><br><span class="line">        self.img_data_dir = os.path.join(train_data_path, <span class="string">&#x27;images&#x27;</span>)</span><br><span class="line">        self.tokenizer = tokenizer</span><br><span class="line">        self.labels = labels</span><br><span class="line">        self.n_classes = <span class="built_in">len</span>(labels)</span><br><span class="line">        self.max_seq_length = <span class="number">300</span> - <span class="number">3</span> - <span class="number">2</span></span><br><span class="line">        self.transforms = torchvision.transforms.Compose(</span><br><span class="line">            [</span><br><span class="line">                torchvision.transforms.Resize(<span class="number">256</span>),</span><br><span class="line">                torchvision.transforms.CenterCrop(<span class="number">224</span>),</span><br><span class="line">                torchvision.transforms.ToTensor(),</span><br><span class="line">                torchvision.transforms.Normalize(</span><br><span class="line">                    mean=[<span class="number">0.485</span>, <span class="number">0.456</span>, <span class="number">0.406</span>],</span><br><span class="line">                    std=[<span class="number">0.229</span>, <span class="number">0.224</span>, <span class="number">0.225</span>]</span><br><span class="line">                )</span><br><span class="line">            ]</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">        key_dic = []</span><br><span class="line">        <span class="keyword">for</span> <span class="built_in">id</span> <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(self.data)):</span><br><span class="line">            key_dic.append(<span class="built_in">id</span>)</span><br><span class="line">        self._keys = key_dic</span><br><span class="line">        <span class="keyword">pass</span></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__getitem__</span>(<span class="params">self, index</span>):</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        sentence = torch.LongTensor(self.tokenizer.encode(self.data[index][<span class="string">&quot;text&quot;</span>], add_special_tokens=<span class="literal">True</span>))</span><br><span class="line">        start_token, sentence, end_token = sentence[<span class="number">0</span>], sentence[<span class="number">1</span>:-<span class="number">1</span>], sentence[-<span class="number">1</span>]</span><br><span class="line">        sentence = sentence[:self.max_seq_length]</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> self.n_classes &gt; <span class="number">2</span>:</span><br><span class="line">            <span class="comment"># multiclass</span></span><br><span class="line">            label = torch.zeros(self.n_classes)</span><br><span class="line">            label[self.labels.index(self.data[index][<span class="string">&quot;label&quot;</span>])] = <span class="number">1</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            label = torch.LongTensor([self.labels.index(self.data[index][<span class="string">&quot;label&quot;</span>])])</span><br><span class="line"></span><br><span class="line">        image = Image.<span class="built_in">open</span>(os.path.join(self.img_data_dir, self.data[index][<span class="string">&quot;img&quot;</span>])).convert(<span class="string">&quot;RGB&quot;</span>)</span><br><span class="line">        image = self.transforms(image)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> &#123;</span><br><span class="line">            <span class="string">&quot;image_start_token&quot;</span>: start_token,</span><br><span class="line">            <span class="string">&quot;image_end_token&quot;</span>: end_token,</span><br><span class="line">            <span class="string">&quot;sentence&quot;</span>: sentence,</span><br><span class="line">            <span class="string">&quot;image&quot;</span>: image,</span><br><span class="line">            <span class="string">&quot;label&quot;</span>: label,</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__len__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">len</span>(self.data)</span><br><span class="line">    <span class="comment"># 标签名称和标签index的对应，例如&#123;&quot;阴性&quot;:0, &quot;阳性&quot;:1&#125;</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">get_label_align_mapping</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">return</span> self.labels2id</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>如果Job仍然跑不起来，可以通过FATE-BOARD日志排错。</p><p>‍</p>]]></content>
    
    
      
      
    <summary type="html">&lt;blockquote&gt;
&lt;p&gt;多模态最近比较火&lt;/p&gt;
&lt;p&gt;多模态任务的input和算法FATE不支持，因此需要开发新的dataloader和算法组件。&lt;/p&gt;
&lt;p&gt;本篇就以肺炎多模态任务为例，介绍如何开发新的FATE机器学习组件&lt;/p&gt;
&lt;p&gt;官方文档在这里：&lt;a hre</summary>
      
    
    
    
    <category term="联邦学习" scheme="https://guoyujian.github.io/categories/%E8%81%94%E9%82%A6%E5%AD%A6%E4%B9%A0/"/>
    
    
    <category term="联邦学习" scheme="https://guoyujian.github.io/tags/%E8%81%94%E9%82%A6%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>FATE横向联邦学习：肠癌图像分类任务（下）——联邦化</title>
    <link href="https://guoyujian.github.io/2022/11/04/FATE%E6%A8%AA%E5%90%91%E8%81%94%E9%82%A6%E5%AD%A6%E4%B9%A0%EF%BC%9A%E8%82%A0%E7%99%8C%E5%9B%BE%E5%83%8F%E5%88%86%E7%B1%BB%E4%BB%BB%E5%8A%A1%EF%BC%88%E4%B8%8B%EF%BC%89%E2%80%94%E2%80%94%E8%81%94%E9%82%A6%E5%8C%96/"/>
    <id>https://guoyujian.github.io/2022/11/04/FATE%E6%A8%AA%E5%90%91%E8%81%94%E9%82%A6%E5%AD%A6%E4%B9%A0%EF%BC%9A%E8%82%A0%E7%99%8C%E5%9B%BE%E5%83%8F%E5%88%86%E7%B1%BB%E4%BB%BB%E5%8A%A1%EF%BC%88%E4%B8%8B%EF%BC%89%E2%80%94%E2%80%94%E8%81%94%E9%82%A6%E5%8C%96/</id>
    <published>2022-11-03T16:08:29.000Z</published>
    <updated>2022-11-03T16:10:04.862Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>在上一篇已经在本地跑通了肠癌图像分类的整个流程，现在我们将它移植到FATE上，实现联邦学习。</p></blockquote><h1 id="数据预处理"><a href="#数据预处理" class="headerlink" title="数据预处理"></a>数据预处理</h1><p>仿照“手写数字识别”任务，将三份训练数据进行预处理。并新建配置文件，处理后的格式如图。</p><p><img src="image-20221101234910-nivm8sx.png" alt="image.png"></p><ul><li>code/： bind开头的文件是用于数据绑定；colon_conf是conf文件，colon_dsl是dsl文件</li><li>test/：500张测试数据</li><li>val/：500张验证集</li><li><p>train_pX/：第X份训练数据，每一份3000张</p><ul><li>images/：图片文件夹，存放所有图像</li><li>config.yaml：图片文件夹配置：通道数，格式等。</li><li>filenames：images目录下的所有文件名（去掉后缀），每个文件名占一行</li><li>targets：images目录下的所有文件名（去掉后缀）和label，逗号区分，每个文件名和类别占一行。</li></ul></li></ul><h1 id="修改源代码"><a href="#修改源代码" class="headerlink" title="修改源代码"></a>修改源代码</h1><p>之前在分析源码时，可以看到homo_nn的模型配置比较定制化，不够灵活，因此我们修改源码实现：</p><ol><li>修改数据加载</li><li>使用预训练的vgg16算法模型；</li><li>使用GPU</li><li>实现模型评估</li></ol><h2 id="修改数据加载"><a href="#修改数据加载" class="headerlink" title="修改数据加载"></a>修改数据加载</h2><p>我们知道vgg16传入的图像尺寸为$224<em>224</em>3$，而肠癌数据集的图像格式大小为$768<em>768</em>3$，所以需要先对数据加载进行修改：</p><p>修改FATE/python/federatedml/nn/backend/pytorch/data.py的<code>VisionDataSet</code>类的<strong>get_item</strong>方法：</p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">__getitem__</span>(<span class="params">self, index</span>):</span><br><span class="line"></span><br><span class="line">    img = Image.<span class="built_in">open</span>(self.images[index]).convert(self._PIL_mode)</span><br><span class="line">    <span class="keyword">if</span> img.size[<span class="number">0</span>] &gt; <span class="number">224</span>:</span><br><span class="line">        resize_transform = torchvision.transforms.Compose(</span><br><span class="line">            [</span><br><span class="line">                torchvision.transforms.Resize(<span class="number">256</span>),</span><br><span class="line">                torchvision.transforms.CenterCrop(<span class="number">224</span>),</span><br><span class="line">            ]</span><br><span class="line">        )</span><br><span class="line">        img = resize_transform(img)</span><br><span class="line">    <span class="keyword">if</span> self.targets_is_image:</span><br><span class="line">        target = Image.<span class="built_in">open</span>(self.targets[index])</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        target = self.targets[index]</span><br><span class="line">    <span class="keyword">return</span> self.transforms(img, target)</span><br></pre></td></tr></table></figure><h2 id="修改算法模型"><a href="#修改算法模型" class="headerlink" title="修改算法模型"></a>修改算法模型</h2><p>我们需要修改homo<em>nn组件下的<em>torch.py文件，<code>FedLightModule</code>类的__init</em></em>方法</p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># --------- 修改前 ----------</span></span><br><span class="line"><span class="comment"># self.model = nn.Sequential(*layers)</span></span><br><span class="line"><span class="comment"># --------- 修改后 ----------</span></span><br><span class="line"><span class="comment"># 这里非常定制化，out_features=2是针对本二分类任务，如果需要更灵活的传参，可以读取配置文件的配置</span></span><br><span class="line">LOGGER.info(<span class="string">&quot;define vgg16&quot;</span>)</span><br><span class="line">self.model = models.vgg16(pretrained=<span class="literal">True</span>)</span><br><span class="line">self.model.classifier[<span class="number">6</span>] = nn.Linear(in_features=<span class="number">4096</span>, out_features=<span class="number">2</span>, bias=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure><h2 id="使用GPU"><a href="#使用GPU" class="headerlink" title="使用GPU"></a>使用GPU</h2><p>需要修改homo_nn组件下的_torch.py文件，<code>FedLightModule</code>类的training_step、validation_step以及do_convergence_check和encrypt方法。改动如下。</p><blockquote><p>do_convergence_check和encrypt要改动的原因并不清楚，大致来看，应该是在model聚合和加密的时候需要将其从GPU中取出。。不过可以肯定，如此改动就会生效。</p></blockquote><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">validation_step</span>(<span class="params">self, batch, batch_idx</span>):</span><br><span class="line">    x, y = batch</span><br><span class="line">    <span class="comment"># -------------- add start ------------------</span></span><br><span class="line">    device = torch.device(<span class="string">&#x27;cuda&#x27;</span> <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> <span class="string">&#x27;cpu&#x27;</span>)</span><br><span class="line">    <span class="comment"># LOGGER.info(f&#x27;device:&#123;device&#125;&#x27;)</span></span><br><span class="line">    x, y = x.to(device), y.to(device)</span><br><span class="line">    <span class="comment"># -------------- add end ------------------</span></span><br><span class="line">    y_hat = self.forward(x)</span><br><span class="line">    loss = self.loss_fn(y_hat, y)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> y_hat.shape[<span class="number">1</span>] &gt; <span class="number">1</span>:</span><br><span class="line">        accuracy = (y_hat.argmax(dim=<span class="number">1</span>) == y).<span class="built_in">sum</span>().<span class="built_in">float</span>() / <span class="built_in">float</span>(y.size(<span class="number">0</span>))</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        y_prob = y_hat[:, <span class="number">0</span>] &gt; <span class="number">0.5</span></span><br><span class="line">        accuracy = (y == y_prob).<span class="built_in">sum</span>().<span class="built_in">float</span>() / y.size(<span class="number">0</span>)</span><br><span class="line">    <span class="keyword">return</span> &#123;<span class="string">&quot;val_loss&quot;</span>: loss, <span class="string">&quot;val_accuracy&quot;</span>: accuracy&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">training_step</span>(<span class="params">self, batch, batch_idx</span>):</span><br><span class="line">    x, y = batch</span><br><span class="line">    <span class="comment"># -------------- add start ------------------</span></span><br><span class="line">    device = torch.device(<span class="string">&#x27;cuda&#x27;</span> <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> <span class="string">&#x27;cpu&#x27;</span>)</span><br><span class="line">    x, y = x.to(device), y.to(device)</span><br><span class="line">    self.model = self.model.to(device)</span><br><span class="line">    <span class="comment"># -------------- add end ------------------</span></span><br><span class="line">    y_hat = self.model(x)</span><br><span class="line">    <span class="comment"># LOGGER.info(&#x27;y_hat: &#123;&#125;&#x27;.format(y_hat.detach().numpy()))</span></span><br><span class="line">    loss = self.loss_fn(y_hat, y)</span><br><span class="line">    self.log(<span class="string">&quot;train_loss&quot;</span>, loss)</span><br><span class="line">    <span class="keyword">return</span> loss</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">do_convergence_check</span>(<span class="params">self, weight, loss</span>):</span><br><span class="line">    <span class="comment"># loss_value = loss.detach().numpy().tolist()</span></span><br><span class="line">    loss_value = loss.detach().cpu().numpy().tolist()</span><br><span class="line"></span><br><span class="line">    self.loss_summary.append(loss_value)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># send loss to server</span></span><br><span class="line">    self.send_loss(loss_value, weight)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># recv convergence status</span></span><br><span class="line">    status = self.recv_loss()</span><br><span class="line">    <span class="keyword">return</span> status</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">encrypt</span>(<span class="params">self, tensor: torch.Tensor, weight</span>):</span><br><span class="line">    <span class="keyword">return</span> self.random_padding_cipher.encrypt(</span><br><span class="line"><span class="comment"># torch.clone(tensor).detach().mul_(weight)</span></span><br><span class="line">        torch.clone(tensor).detach().mul_(weight).cpu()</span><br><span class="line">    ).numpy()</span><br></pre></td></tr></table></figure><h2 id="模型评估"><a href="#模型评估" class="headerlink" title="模型评估"></a>模型评估</h2><p>以下是一个简单的模型评估代码，在homo_nn文件夹下新建evaluation.py，代码及注释如下</p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 导入必要的库，注意这里需要导入homo_nn下的FedLightModule类</span></span><br><span class="line"><span class="comment"># 如果库不存在，需要在fate-flow容器下pip安装</span></span><br><span class="line"><span class="keyword">from</span> federatedml.nn.homo_nn._torch <span class="keyword">import</span> FedLightModule</span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> DataLoader, Dataset, random_split</span><br><span class="line"><span class="keyword">from</span> torchvision <span class="keyword">import</span> datasets, models, transforms</span><br><span class="line"><span class="keyword">from</span> tqdm <span class="keyword">import</span> tqdm</span><br><span class="line"><span class="keyword">import</span> os </span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> nn</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> base64</span><br><span class="line"><span class="comment"># import cv2</span></span><br><span class="line"><span class="keyword">from</span> io <span class="keyword">import</span> BytesIO</span><br><span class="line"></span><br><span class="line"><span class="comment"># dataset</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">My_Dataset</span>(<span class="title class_ inherited__">Dataset</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, image_path, target</span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        self.image_path = image_path</span><br><span class="line">        self.target = target</span><br><span class="line">  </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__len__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">len</span>(self.image_path)</span><br><span class="line">  </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__getitem__</span>(<span class="params">self, index</span>):</span><br><span class="line">        path = self.image_path[index]</span><br><span class="line">        img = Image.<span class="built_in">open</span>(path).convert(<span class="string">&#x27;RGB&#x27;</span>)</span><br><span class="line">        resize_transform = transforms.Compose([</span><br><span class="line">            transforms.Resize(<span class="number">256</span>),</span><br><span class="line">            transforms.CenterCrop(<span class="number">224</span>),</span><br><span class="line">        ])</span><br><span class="line"></span><br><span class="line">        toTensor_transform = transforms.Compose([</span><br><span class="line">            transforms.ToTensor()</span><br><span class="line">        ])</span><br><span class="line">        label = self.target[index]</span><br><span class="line">        <span class="keyword">if</span> img.size[<span class="number">0</span>] &gt; <span class="number">224</span>:</span><br><span class="line">            img = resize_transform(img)</span><br><span class="line">        img = toTensor_transform(img)</span><br><span class="line">        <span class="keyword">return</span> img, label</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># test</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">test_model</span>(<span class="params">test_loader, model, criterion, device</span>):</span><br><span class="line">    model.<span class="built_in">eval</span>()</span><br><span class="line">  </span><br><span class="line">    true_labels = []</span><br><span class="line">    pred_labels = []</span><br><span class="line">    scores = []</span><br><span class="line"></span><br><span class="line">    size = <span class="built_in">len</span>(test_loader.dataset)</span><br><span class="line">    num_batches = <span class="built_in">len</span>(test_loader)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&#x27;size:<span class="subst">&#123;size&#125;</span>; num_batches:<span class="subst">&#123;num_batches&#125;</span>&#x27;</span>)</span><br><span class="line">    losses, correct = <span class="number">0</span>, <span class="number">0</span></span><br><span class="line">    <span class="comment"># log_loss = 0</span></span><br><span class="line">    <span class="comment">################################# validation #################################</span></span><br><span class="line">    <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">        <span class="keyword">for</span> batch, (x, y) <span class="keyword">in</span> <span class="built_in">enumerate</span>(tqdm(test_loader)):</span><br><span class="line">            device = torch.device(device)</span><br><span class="line">            x, y = x.to(device), y.to(device)</span><br><span class="line">            pred = model(x)</span><br><span class="line">            loss = criterion(pred, y.long().squeeze()) </span><br><span class="line">            current = batch * <span class="built_in">len</span>(x)</span><br><span class="line">            scores += pred.tolist()</span><br><span class="line">            y_pred, y_true = torch.argmax(pred, axis=<span class="number">1</span>), y.long().squeeze()</span><br><span class="line">            correct += (y_pred == y_true).<span class="built_in">type</span>(torch.<span class="built_in">float</span>).<span class="built_in">sum</span>().item()</span><br><span class="line">            loss, current = np.<span class="built_in">round</span>(loss.item(), <span class="number">5</span>), batch * <span class="built_in">len</span>(x)</span><br><span class="line">            true_labels += y_true.detach().cpu().tolist()</span><br><span class="line">            pred_labels += y_pred.detach().cpu().tolist()</span><br><span class="line">            losses += loss</span><br><span class="line">    correct /= size</span><br><span class="line">    losses /= num_batches</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&#x27;losses:<span class="subst">&#123;losses&#125;</span>\n&#x27;</span>)</span><br><span class="line">    metrics = <span class="string">f&quot;Test: Accuracy: <span class="subst">&#123;(<span class="number">100</span>*correct):&gt;<span class="number">0.2</span>f&#125;</span>%, Avg loss: <span class="subst">&#123;losses:&gt;5f&#125;</span> \n&quot;</span></span><br><span class="line">    <span class="keyword">return</span> np.array(true_labels), np.array(pred_labels), np.array(scores), metrics</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">model_path: model path</span></span><br><span class="line"><span class="string">res_path: save csv path，保存预测的数据结果</span></span><br><span class="line"><span class="string">metric_path: mertic path，保存模型评估结果</span></span><br><span class="line"><span class="string">typ : predict or test，test是评估模型，需要输出模型的评估指标，predict是单纯的对未知label数据进行预测</span></span><br><span class="line"><span class="string">test_path: test data path，测试数据集path，默认和train是相同的组织形式</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">evaluation</span>(<span class="params">model_path, res_path, metric_path,  typ, test_path</span>):</span><br><span class="line">    model = FedLightModule.load_from_checkpoint(model_path)</span><br><span class="line">    test_images_over = []</span><br><span class="line">    test_labels_over = []</span><br><span class="line">    <span class="keyword">if</span> typ == <span class="string">&#x27;test&#x27;</span>:</span><br><span class="line">        <span class="keyword">with</span> <span class="built_in">open</span>(os.path.join(test_path, <span class="string">&#x27;targets&#x27;</span>), <span class="string">&#x27;r&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">            line = f.readline()</span><br><span class="line">            <span class="keyword">while</span> line:</span><br><span class="line">                filename = line.split(<span class="string">&#x27;,&#x27;</span>)[<span class="number">0</span>] + <span class="string">&#x27;.jpg&#x27;</span></span><br><span class="line">                target = <span class="built_in">int</span>(line.split(<span class="string">&#x27;,&#x27;</span>)[-<span class="number">1</span>].replace(<span class="string">&#x27;\n&#x27;</span>,<span class="string">&#x27;&#x27;</span>))</span><br><span class="line">                test_images_over.append(os.path.join(test_path, <span class="string">&#x27;images&#x27;</span>, filename))</span><br><span class="line">                test_labels_over.append(target)</span><br><span class="line">                line = f.readline()</span><br><span class="line">    <span class="keyword">elif</span> typ == <span class="string">&#x27;predict&#x27;</span>:</span><br><span class="line">        <span class="keyword">with</span> <span class="built_in">open</span>(os.path.join(test_path, <span class="string">&#x27;filenames&#x27;</span>), <span class="string">&#x27;r&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">            line = f.readline()</span><br><span class="line">            <span class="keyword">while</span> line:</span><br><span class="line">                filename = line.replace(<span class="string">&#x27;\n&#x27;</span>, <span class="string">&#x27;&#x27;</span>) + <span class="string">&#x27;.jpg&#x27;</span></span><br><span class="line">                target = <span class="number">0</span></span><br><span class="line">                test_images_over.append(os.path.join(test_path, <span class="string">&#x27;images&#x27;</span>, filename))</span><br><span class="line">                test_labels_over.append(target)</span><br><span class="line">                line = f.readline()</span><br><span class="line">    test_dataset = My_Dataset(test_images_over, test_labels_over)</span><br><span class="line">    test_loader = DataLoader(test_dataset, batch_size=<span class="number">32</span>)</span><br><span class="line">    loss_fn = nn.CrossEntropyLoss()</span><br><span class="line">    <span class="comment"># device = torch.device(&#x27;cuda&#x27; if torch.cuda.is_available() else &#x27;cpu&#x27;)</span></span><br><span class="line">    device = <span class="string">&#x27;cpu&#x27;</span></span><br><span class="line">    true_labels, pred_labels, scores, metrics = test_model(test_loader, model, loss_fn, device)</span><br><span class="line"></span><br><span class="line">    l = <span class="built_in">len</span>(true_labels)</span><br><span class="line">    <span class="keyword">if</span> typ == <span class="string">&#x27;test&#x27;</span>:</span><br><span class="line">        <span class="keyword">with</span> <span class="built_in">open</span>(metric_path, <span class="string">&#x27;w&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">            f.write(<span class="string">f&#x27;<span class="subst">&#123;metrics&#125;</span>\n&#x27;</span>)</span><br><span class="line">        <span class="keyword">with</span> <span class="built_in">open</span>(res_path, <span class="string">&#x27;w&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">            f.write(<span class="string">&#x27;true_label,pred_label,score\n&#x27;</span>)</span><br><span class="line">            <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(l):</span><br><span class="line">                true_label, pred_label, score = true_labels[i], pred_labels[i], scores[i]</span><br><span class="line">                f.write(<span class="string">f&#x27;<span class="subst">&#123;true_label&#125;</span>,<span class="subst">&#123;pred_label&#125;</span>,<span class="subst">&#123;score&#125;</span>\n&#x27;</span>)</span><br><span class="line">    <span class="keyword">elif</span> typ == <span class="string">&#x27;predict&#x27;</span>:</span><br><span class="line">        <span class="keyword">with</span> <span class="built_in">open</span>(res_path, <span class="string">&#x27;w&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">            f.write(<span class="string">&#x27;pred_label,score\n&#x27;</span>)</span><br><span class="line">            <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(l):</span><br><span class="line">                true_label, pred_label, score = true_labels[i], pred_labels[i], scores[i]</span><br><span class="line">                f.write(<span class="string">f&#x27;<span class="subst">&#123;pred_label&#125;</span>,<span class="subst">&#123;score&#125;</span>\n&#x27;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    res_path = <span class="string">&quot;./123.csv&quot;</span></span><br><span class="line">    metric_path = <span class="string">&quot;./123.txt&quot;</span></span><br><span class="line">    typ = <span class="string">&quot;test&quot;</span></span><br><span class="line">    path = <span class="string">&quot;/data/projects/fate/examples/gwork/colon/test&quot;</span></span><br><span class="line">    model_path = <span class="string">&#x27;&#x27;</span></span><br><span class="line">    evaluation(model_path, res_path, metric_path,  typ, path)</span><br></pre></td></tr></table></figure><p>代码修改完毕。下面进行训练。</p><h1 id="联邦学习"><a href="#联邦学习" class="headerlink" title="联邦学习"></a>联邦学习</h1><p>分别修改CONF和DSL配置</p><h2 id="colon-conf-json"><a href="#colon-conf-json" class="headerlink" title="colon_conf.json"></a>colon_conf.json</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">&#123;</span><br><span class="line">    <span class="string">&quot;dsl_version&quot;</span>: <span class="number">2</span>,</span><br><span class="line">    <span class="string">&quot;initiator&quot;</span>: &#123;</span><br><span class="line">        <span class="string">&quot;role&quot;</span>: <span class="string">&quot;guest&quot;</span>,</span><br><span class="line">        <span class="string">&quot;party_id&quot;</span>: <span class="number">9999</span></span><br><span class="line">    &#125;,</span><br><span class="line">    <span class="string">&quot;role&quot;</span>: &#123;</span><br><span class="line">        <span class="string">&quot;arbiter&quot;</span>: [</span><br><span class="line">            <span class="number">10000</span></span><br><span class="line">        ],</span><br><span class="line">        <span class="string">&quot;host&quot;</span>: [</span><br><span class="line">            <span class="number">9998</span>,<span class="number">9997</span></span><br><span class="line">        ],</span><br><span class="line">        <span class="string">&quot;guest&quot;</span>: [</span><br><span class="line">            <span class="number">9999</span></span><br><span class="line">        ]</span><br><span class="line">    &#125;,</span><br><span class="line">    <span class="string">&quot;component_parameters&quot;</span>: &#123;</span><br><span class="line">        <span class="string">&quot;common&quot;</span>: &#123;</span><br><span class="line">            <span class="string">&quot;homo_nn_0&quot;</span>: &#123;</span><br><span class="line">                <span class="string">&quot;api_version&quot;</span>: <span class="number">2</span>,</span><br><span class="line">                <span class="string">&quot;encode_label&quot;</span>: true,</span><br><span class="line">                <span class="string">&quot;max_iter&quot;</span>: <span class="number">2</span>,</span><br><span class="line">                <span class="string">&quot;batch_size&quot;</span>: <span class="number">32</span>,</span><br><span class="line">                <span class="string">&quot;optimizer&quot;</span>: &#123;</span><br><span class="line">                    <span class="string">&quot;lr&quot;</span>: <span class="number">0.000001</span>,</span><br><span class="line">                    <span class="string">&quot;optimizer&quot;</span>: <span class="string">&quot;Adam&quot;</span></span><br><span class="line">                &#125;,</span><br><span class="line">                <span class="string">&quot;loss&quot;</span>: <span class="string">&quot;CrossEntropyLoss&quot;</span>,</span><br><span class="line">                <span class="string">&quot;metrics&quot;</span>: [</span><br><span class="line">                    <span class="string">&quot;accuracy&quot;</span></span><br><span class="line">                ],</span><br><span class="line">                <span class="string">&quot;nn_define&quot;</span>: [</span><br><span class="line">                ],</span><br><span class="line">                <span class="string">&quot;config_type&quot;</span>: <span class="string">&quot;pytorch&quot;</span></span><br><span class="line">            &#125;</span><br><span class="line">        &#125;,</span><br><span class="line">        <span class="string">&quot;role&quot;</span>: &#123;</span><br><span class="line">            <span class="string">&quot;host&quot;</span>: &#123;</span><br><span class="line">                <span class="string">&quot;0&quot;</span>: &#123;</span><br><span class="line">                    <span class="string">&quot;reader_0&quot;</span>: &#123;</span><br><span class="line">                        <span class="string">&quot;table&quot;</span>: &#123;</span><br><span class="line">                            <span class="string">&quot;name&quot;</span>: <span class="string">&quot;colon_images_0&quot;</span>,</span><br><span class="line">                            <span class="string">&quot;namespace&quot;</span>: <span class="string">&quot;experiment&quot;</span></span><br><span class="line">                        &#125;</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;,</span><br><span class="line">      <span class="string">&quot;1&quot;</span>: &#123;</span><br><span class="line">                    <span class="string">&quot;reader_0&quot;</span>: &#123;</span><br><span class="line">                        <span class="string">&quot;table&quot;</span>: &#123;</span><br><span class="line">                            <span class="string">&quot;name&quot;</span>: <span class="string">&quot;colon_images_1&quot;</span>,</span><br><span class="line">                            <span class="string">&quot;namespace&quot;</span>: <span class="string">&quot;experiment&quot;</span></span><br><span class="line">                        &#125;</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;,</span><br><span class="line">            <span class="string">&quot;guest&quot;</span>: &#123;</span><br><span class="line">                <span class="string">&quot;0&quot;</span>: &#123;</span><br><span class="line">                    <span class="string">&quot;reader_0&quot;</span>: &#123;</span><br><span class="line">                        <span class="string">&quot;table&quot;</span>: &#123;</span><br><span class="line">                            <span class="string">&quot;name&quot;</span>: <span class="string">&quot;colon_images_2&quot;</span>,</span><br><span class="line">                            <span class="string">&quot;namespace&quot;</span>: <span class="string">&quot;experiment&quot;</span></span><br><span class="line">                        &#125;</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure><h2 id="colon-dsl-json"><a href="#colon-dsl-json" class="headerlink" title="colon_dsl.json"></a>colon_dsl.json</h2><p>略</p><p>首先数据已经处理成FATE可以读取的格式。</p><p>然后将三份数据分发到集群的三台不同的机器上，分别是fate9999，fate9998，以及fate9997</p><p>进入三台机器的fate-client container，使用flow table bind -c 命令将文件夹绑定到table。</p><p>在发起方FATE9999的client容器中，进入code文件夹，执行<code>flow job submit -c colon_conf.json -d colon_dsl.json</code>启动任务</p><p>查看FATE-BOARD Job</p><p>他的homo_nn组件输出的日志如下：</p><p><img src="image-20221014121445-6gzta7m.png" alt="image.png"></p><h1 id="模型评估-1"><a href="#模型评估-1" class="headerlink" title="模型评估"></a>模型评估</h1><p>在job结束后，会保存check point，保存的容器为fate-flow container。</p><p>以fate9999为例，保存路径为：</p><p>/data/projects/fate/fateflow/jobs/202210131350059277200/guest/9999/homo_cv_0/202210131350059277200_homo_cv_0/0/task_executor/7f86f6064aff11edbd540242c0a70064/model.ckpt</p><blockquote><p>不同角色（guset、host）、不同party_id的机器上路径可能有所差异。</p></blockquote><p>将该路径复制到刚才的evaluation.py的model_path中，执行<code>python evaluation.py</code>，查看输出结果：</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">Accuracy: 99.20%, Avg loss: 0.022641</span><br></pre></td></tr></table></figure><h1 id="实验结果"><a href="#实验结果" class="headerlink" title="实验结果"></a>实验结果</h1><p>结合baseline的实验结果，可以得到下表。</p><div class="table-container"><table><thead><tr><th>使用的数据</th><th>训练类型</th><th>模型评估</th></tr></thead><tbody><tr><td>全部训练数据（Train_1+Train_2+Train_3）</td><td>本地（GPU）</td><td>Accuracy: 99.60%, Avg loss: 0.011775</td></tr><tr><td>Train_1</td><td>本地（GPU）</td><td>Accuracy: 73.20%, Avg loss: 0.641481</td></tr><tr><td>Train_2</td><td>本地（GPU）</td><td>Accuracy: 71.40%, Avg loss: 0.649055</td></tr><tr><td>Train_3</td><td>本地（GPU）</td><td>Accuracy: 56.80%, Avg loss: 0.654335</td></tr><tr><td>全部训练数据（Train_1+Train_2+Train_3）</td><td>联邦（GPU）</td><td>Accuracy: 99.20%, Avg loss: 0.022641</td></tr></tbody></table></div><p>在增加了部分读写日志，并加以分析可以得到训练的时间分布：</p><p><img src="image-20221102004157-5zhbj13.png" alt="image.png"></p><h1 id="实验分析"><a href="#实验分析" class="headerlink" title="实验分析"></a>实验分析</h1><ol><li><p>使用联邦学习的效果要优于分开训练的模型效果，证明了联邦学习的有效性。</p></li><li><p>做实验发现，使用CPU进行训练，每个epoch需要大约15分钟，而使用GPU之后，每个epoch仅需要29s左右。使用GPU的计算效率要远远大于使用CPU。</p></li><li><p>对日志进行分析发现，计算时间约为60s，模型参数加密、解密以及传输的时间约为比例约为600s，二者比例约为1:10。因此可以得出结论：结肠癌联邦学习的时间瓶颈不在于本地模型的训练时间，而是在于模型参数加密、解密以及传输时间。</p></li></ol><h1 id="补充"><a href="#补充" class="headerlink" title="补充"></a>补充</h1><p>修改了homo_nn的源码，导致原有的homo_nn的功能失效，所以这里不推荐这样改，更推荐开发新的组件来完成。</p><p>‍</p>]]></content>
    
    
      
      
    <summary type="html">&lt;blockquote&gt;
&lt;p&gt;在上一篇已经在本地跑通了肠癌图像分类的整个流程，现在我们将它移植到FATE上，实现联邦学习。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h1 id=&quot;数据预处理&quot;&gt;&lt;a href=&quot;#数据预处理&quot; class=&quot;headerlink&quot; title=&quot;数</summary>
      
    
    
    
    <category term="联邦学习" scheme="https://guoyujian.github.io/categories/%E8%81%94%E9%82%A6%E5%AD%A6%E4%B9%A0/"/>
    
    
    <category term="联邦学习" scheme="https://guoyujian.github.io/tags/%E8%81%94%E9%82%A6%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>FATE横向联邦学习：肠癌图像分类任务（上）——baseline</title>
    <link href="https://guoyujian.github.io/2022/11/04/FATE%E6%A8%AA%E5%90%91%E8%81%94%E9%82%A6%E5%AD%A6%E4%B9%A0%EF%BC%9A%E8%82%A0%E7%99%8C%E5%9B%BE%E5%83%8F%E5%88%86%E7%B1%BB%E4%BB%BB%E5%8A%A1%EF%BC%88%E4%B8%8A%EF%BC%89%E2%80%94%E2%80%94baseline/"/>
    <id>https://guoyujian.github.io/2022/11/04/FATE%E6%A8%AA%E5%90%91%E8%81%94%E9%82%A6%E5%AD%A6%E4%B9%A0%EF%BC%9A%E8%82%A0%E7%99%8C%E5%9B%BE%E5%83%8F%E5%88%86%E7%B1%BB%E4%BB%BB%E5%8A%A1%EF%BC%88%E4%B8%8A%EF%BC%89%E2%80%94%E2%80%94baseline/</id>
    <published>2022-11-03T16:07:00.000Z</published>
    <updated>2022-11-03T16:08:08.651Z</updated>
    
    <content type="html"><![CDATA[<p>本案例分上下两篇，上篇介绍肠癌图像分类任务的本地baseline，下篇介绍将肠癌图像分类任务移植到FATE上，实现联邦学习。</p><h1 id="任务目标"><a href="#任务目标" class="headerlink" title="任务目标"></a>任务目标</h1><ol><li>使用FATE开发新的组件，实现图像横向联邦学习</li><li>证明联邦学习有效</li></ol><h1 id="任务介绍"><a href="#任务介绍" class="headerlink" title="任务介绍"></a>任务介绍</h1><p>该任务将开发基于结肠的组织病理学图像正确判断是良性组织或者结肠癌的二分类算法。</p><h2 id="数据集"><a href="#数据集" class="headerlink" title="数据集"></a>数据集</h2><p>数据集来自于<a href="https://www.kaggle.com/datasets/andrewmvd/lung-and-colon-cancer-histopathological-images的colon_image_sets">https://www.kaggle.com/datasets/andrewmvd/lung-and-colon-cancer-histopathological-images的colon_image_sets</a></p><p>本任务数据集由2个类别组成的10000张符合HIPAA标准的结肠组织病理学图像。所有图像的尺寸为$768 <em> 768 </em> 3$，为jpeg文件格式。</p><p>为了进行实验，需要对数据进行划分：步骤如下：</p><ol><li><p>数据shuffle。</p></li><li><p>分为五个子集，包含三份训练集子集，命名为Train_1, Train_2, Train_3，训练集子集各三千张图像，一份验证集和一份测试集各500张，分别命名为val和test。（这里我没有对图像本身进行改动，而是生成了一个excel，每个sheet包含image_path和type两列，分别对应图像的位置和label，一共有input1，input2，input3，val和test五个sheet页）</p></li></ol><p>三份训练数据和一份测试数据对应的三种类型的图像数量如下：</p><div class="table-container"><table><thead><tr><th>Data</th><th>结肠癌组织</th><th>良性组织</th><th>总计</th></tr></thead><tbody><tr><td>Train_1</td><td>1505</td><td>1495</td><td>3000</td></tr><tr><td>Train_2</td><td>1467</td><td>1533</td><td>3000</td></tr><tr><td>Train_3</td><td>1515</td><td>1485</td><td>3000</td></tr><tr><td>Test</td><td>253</td><td>247</td><td>500</td></tr><tr><td>总计（不算Test）</td><td>4487</td><td>4513</td><td>/</td></tr></tbody></table></div><h2 id="算法"><a href="#算法" class="headerlink" title="算法"></a>算法</h2><p>为了保证单一变量影响，在本地训练和联邦训练的模型参数相同，具体参数如下表</p><div class="table-container"><table><thead><tr><th>key</th><th>val</th></tr></thead><tbody><tr><td>平台</td><td>kaggle</td></tr><tr><td>算法</td><td>基于ImageNet1K预训练的vgg16模型</td></tr><tr><td>Epoch</td><td>2</td></tr><tr><td>Batch Size</td><td>16 or 32</td></tr><tr><td>Optimizer</td><td>Adam</td></tr><tr><td>Learning Rate</td><td>1e-5</td></tr><tr><td>Loss</td><td>CrossEntropyLoss</td></tr><tr><td>Metrics</td><td>Accuracy</td></tr></tbody></table></div><h1 id="实验步骤"><a href="#实验步骤" class="headerlink" title="实验步骤"></a>实验步骤</h1><ol><li><p>使用全部训练集在本地进行训练，在测试集进行模型评估。</p></li><li><p>分别使用三份训练集子集在本地进行训练，在测试集进行模型评估。</p></li><li><p>使用FATE对三份训练集子集进行联邦训练，在测试集上进行模型评估。</p></li></ol><h1 id="Code"><a href="#Code" class="headerlink" title="Code"></a>Code</h1><blockquote><p>这里只列出重要的code，详细code可以参见：<a href="https://www.kaggle.com/code/guoyujian/colon-cancer101">https://www.kaggle.com/code/guoyujian/colon-cancer101</a></p></blockquote><h2 id="define-params"><a href="#define-params" class="headerlink" title="define params"></a>define params</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">EPOCHS = <span class="number">2</span></span><br><span class="line">BATCH_SIZE = <span class="number">32</span></span><br><span class="line">lr = <span class="number">1e-5</span></span><br><span class="line"></span><br><span class="line">device = torch.device(<span class="string">&#x27;cuda&#x27;</span> <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> <span class="string">&#x27;cpu&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(device)</span><br></pre></td></tr></table></figure><h2 id="加载数据"><a href="#加载数据" class="headerlink" title="加载数据"></a>加载数据</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 从元数据中读取图像的path和label</span></span><br><span class="line">metadata_path = <span class="string">&#x27;../input/input-colon/colon_inputs.xls&#x27;</span></span><br><span class="line"><span class="comment"># metadata_path = &#x27;../input/input-colon-cuts/colon_inputs_cuts.xls&#x27;</span></span><br><span class="line">df1 = pd.read_excel(metadata_path, sheet_name = <span class="string">&#x27;input1&#x27;</span>)</span><br><span class="line">df2 = pd.read_excel(metadata_path, sheet_name = <span class="string">&#x27;input2&#x27;</span>)</span><br><span class="line">df3 = pd.read_excel(metadata_path, sheet_name = <span class="string">&#x27;input3&#x27;</span>)</span><br><span class="line">df4 = pd.read_excel(metadata_path, sheet_name = <span class="string">&#x27;val&#x27;</span>)</span><br><span class="line">df5 = pd.read_excel(metadata_path, sheet_name = <span class="string">&#x27;test&#x27;</span>)</span><br><span class="line">df = pd.concat([df1, df2, df3])</span><br><span class="line"></span><br><span class="line">df.head()</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 全部的图片路径和标签</span></span><br><span class="line"><span class="comment"># images_all_over = df[&#x27;image_path&#x27;].to_list()</span></span><br><span class="line">images_all_over = []</span><br><span class="line"><span class="keyword">for</span> item <span class="keyword">in</span> df[<span class="string">&#x27;image_path&#x27;</span>]:</span><br><span class="line">    item = images_all_over.append(<span class="string">&#x27;../input/lung-and-colon-cancer-histopathological-images/lung_colon_image_set/colon_image_sets/&#x27;</span> + item)</span><br><span class="line">labels_all_over = df[<span class="string">&#x27;type&#x27;</span>].to_list()</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&#x27;len images_all_over: <span class="subst">&#123;<span class="built_in">len</span>(images_all_over)&#125;</span>; len labels_all_over: <span class="subst">&#123;<span class="built_in">len</span>(labels_all_over)&#125;</span>; &#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># part1,2,3 &amp; val</span></span><br><span class="line">images_1_over = []</span><br><span class="line"><span class="keyword">for</span> item <span class="keyword">in</span> df1[<span class="string">&#x27;image_path&#x27;</span>]:</span><br><span class="line">    item = images_1_over.append(<span class="string">&#x27;../input/lung-and-colon-cancer-histopathological-images/lung_colon_image_set/colon_image_sets/&#x27;</span> + item)</span><br><span class="line">labels_1_over = df1[<span class="string">&#x27;type&#x27;</span>].to_list()</span><br><span class="line"></span><br><span class="line">images_2_over = []</span><br><span class="line"><span class="keyword">for</span> item <span class="keyword">in</span> df2[<span class="string">&#x27;image_path&#x27;</span>]:</span><br><span class="line">    item = images_2_over.append(<span class="string">&#x27;../input/lung-and-colon-cancer-histopathological-images/lung_colon_image_set/colon_image_sets/&#x27;</span> + item)</span><br><span class="line">labels_2_over = df2[<span class="string">&#x27;type&#x27;</span>].to_list()</span><br><span class="line"></span><br><span class="line">images_3_over = []</span><br><span class="line"><span class="keyword">for</span> item <span class="keyword">in</span> df3[<span class="string">&#x27;image_path&#x27;</span>]:</span><br><span class="line">    item = images_3_over.append(<span class="string">&#x27;../input/lung-and-colon-cancer-histopathological-images/lung_colon_image_set/colon_image_sets/&#x27;</span> + item)</span><br><span class="line">labels_3_over = df3[<span class="string">&#x27;type&#x27;</span>].to_list()</span><br><span class="line"></span><br><span class="line">images_val_over = []</span><br><span class="line"><span class="keyword">for</span> item <span class="keyword">in</span> df4[<span class="string">&#x27;image_path&#x27;</span>]:</span><br><span class="line">    item = images_val_over.append(<span class="string">&#x27;../input/lung-and-colon-cancer-histopathological-images/lung_colon_image_set/colon_image_sets/&#x27;</span> + item)</span><br><span class="line">labels_val_over = df4[<span class="string">&#x27;type&#x27;</span>].to_list()</span><br><span class="line"></span><br><span class="line">images_test_over = []</span><br><span class="line"><span class="keyword">for</span> item <span class="keyword">in</span> df5[<span class="string">&#x27;image_path&#x27;</span>]:</span><br><span class="line">    item = images_test_over.append(<span class="string">&#x27;../input/lung-and-colon-cancer-histopathological-images/lung_colon_image_set/colon_image_sets/&#x27;</span> + item)</span><br><span class="line">labels_test_over = df5[<span class="string">&#x27;type&#x27;</span>].to_list()</span><br><span class="line"></span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 对全部数据shuffle</span></span><br><span class="line"></span><br><span class="line">shuffle_dataset = np.hstack((np.array(images_all_over).reshape(-<span class="number">1</span>, <span class="number">1</span>), np.array(labels_all_over).reshape(-<span class="number">1</span>, <span class="number">1</span>)))</span><br><span class="line">np.random.shuffle(shuffle_dataset)</span><br><span class="line">images_all_over = shuffle_dataset[:, <span class="number">0</span>].tolist()</span><br><span class="line">labels_all_over = shuffle_dataset[:, <span class="number">1</span>].astype(<span class="built_in">int</span>).tolist()</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#定义dataset类</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Colon_Dataset</span>(<span class="title class_ inherited__">Dataset</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, image_path, target, train_transform = <span class="literal">None</span>, test_transform = <span class="literal">None</span></span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        self.image_path = image_path</span><br><span class="line">        self.target = target</span><br><span class="line">        self.train_transform = train_transform</span><br><span class="line">        self.test_transform = test_transform</span><br><span class="line">        self.transform = <span class="literal">None</span></span><br><span class="line">  </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__len__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">len</span>(self.image_path)</span><br><span class="line">  </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__getitem__</span>(<span class="params">self, index</span>):</span><br><span class="line">        path = self.image_path[index]</span><br><span class="line">        image = cv2.imread(path)</span><br><span class="line">        label = self.target[index]</span><br><span class="line">        <span class="keyword">if</span> self.transform:</span><br><span class="line">            image = self.transform(image)</span><br><span class="line">        <span class="keyword">return</span> image, label</span><br><span class="line">  </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">train_mode</span>(<span class="params">self</span>):</span><br><span class="line">        self.transform = self.train_transform</span><br><span class="line">  </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">test_mode</span>(<span class="params">self</span>):</span><br><span class="line">        self.transform = self.test_transform</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># define data transform</span></span><br><span class="line">train_transform = transforms.Compose([</span><br><span class="line">    transforms.ToPILImage(),</span><br><span class="line">    transforms.Resize(<span class="number">256</span>),</span><br><span class="line">    transforms.CenterCrop(<span class="number">224</span>),</span><br><span class="line">    transforms.RandomHorizontalFlip(),</span><br><span class="line">    transforms.RandomRotation(<span class="number">10</span>),</span><br><span class="line">    transforms.ColorJitter(),</span><br><span class="line">    transforms.ToTensor(),</span><br><span class="line">])</span><br><span class="line"></span><br><span class="line">test_transform = transforms.Compose([</span><br><span class="line">    transforms.ToPILImage(),</span><br><span class="line">    transforms.Resize(<span class="number">256</span>),</span><br><span class="line">    transforms.CenterCrop(<span class="number">224</span>),</span><br><span class="line">    transforms.ToTensor()</span><br><span class="line">])</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 全部训练数据</span></span><br><span class="line">colon_all_dataset = Colon_Dataset(images_all_over, labels_all_over, train_transform, test_transform)</span><br><span class="line">train_loader = DataLoader(colon_all_dataset, batch_size=BATCH_SIZE)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 三份训练数据、验证数据和测试数据</span></span><br><span class="line">colon_1_dataset = Colon_Dataset(images_1_over, labels_1_over, train_transform, test_transform)</span><br><span class="line">colon_2_dataset = Colon_Dataset(images_2_over, labels_2_over, train_transform, test_transform)</span><br><span class="line">colon_3_dataset = Colon_Dataset(images_3_over, labels_3_over, train_transform, test_transform)</span><br><span class="line">colon_val_dataset = Colon_Dataset(images_val_over, labels_val_over, train_transform, test_transform)</span><br><span class="line">colon_test_dataset = Colon_Dataset(images_test_over, labels_test_over, train_transform, test_transform)</span><br><span class="line"></span><br><span class="line">train_1_loader = DataLoader(colon_1_dataset, batch_size=BATCH_SIZE)</span><br><span class="line">train_2_loader = DataLoader(colon_2_dataset, batch_size=BATCH_SIZE)</span><br><span class="line">train_3_loader = DataLoader(colon_3_dataset, batch_size=BATCH_SIZE)</span><br><span class="line">val_loader = DataLoader(colon_val_dataset, batch_size=BATCH_SIZE)</span><br><span class="line">test_loader = DataLoader(colon_test_dataset, batch_size=BATCH_SIZE)</span><br></pre></td></tr></table></figure><h2 id="define-a-model"><a href="#define-a-model" class="headerlink" title="define a model"></a>define a model</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">Model = models.vgg16(pretrained=<span class="literal">True</span>)</span><br><span class="line">Model.classifier[<span class="number">6</span>] = nn.Linear(in_features=<span class="number">4096</span>, out_features=<span class="number">2</span>, bias=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">Model = Model.to(device)</span><br><span class="line"></span><br><span class="line">optimizer = torch.optim.Adam(Model.parameters() , lr = lr)</span><br><span class="line"></span><br><span class="line">scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[<span class="number">10</span>, <span class="number">25</span>, <span class="number">50</span>, <span class="number">75</span>, <span class="number">120</span>], gamma=<span class="number">0.5</span>)</span><br><span class="line"></span><br><span class="line">loss_fn = nn.CrossEntropyLoss()</span><br></pre></td></tr></table></figure><h2 id="train-amp-val"><a href="#train-amp-val" class="headerlink" title="train&amp;val"></a>train&amp;val</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 训练一轮</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">train_one_epoch</span>(<span class="params">train_loader, model, criterion, optimizer, device</span>):</span><br><span class="line">    model.train()</span><br><span class="line">  </span><br><span class="line">    colon_all_dataset.train_mode()</span><br><span class="line">    colon_1_dataset.train_mode()</span><br><span class="line">    colon_2_dataset.train_mode()</span><br><span class="line">    colon_3_dataset.train_mode()</span><br><span class="line">    colon_val_dataset.train_mode()</span><br><span class="line">  </span><br><span class="line">    size = <span class="built_in">len</span>(train_loader.dataset)</span><br><span class="line">    num_batches = <span class="built_in">len</span>(train_loader)</span><br><span class="line">    losses, correct = <span class="number">0</span>, <span class="number">0</span></span><br><span class="line">    <span class="comment">################################# train #################################</span></span><br><span class="line">    <span class="keyword">for</span> batch, (x, y) <span class="keyword">in</span> <span class="built_in">enumerate</span>(tqdm(train_loader)):</span><br><span class="line">        device = torch.device(device)</span><br><span class="line">        x, y = x.to(device), y.to(device)  </span><br><span class="line">        optimizer.zero_grad()</span><br><span class="line">        pred = model(x)</span><br><span class="line"></span><br><span class="line">        loss = criterion(pred, y.long().squeeze())</span><br><span class="line"></span><br><span class="line">        current = batch * <span class="built_in">len</span>(x)</span><br><span class="line">        loss.backward()</span><br><span class="line">        optimizer.step()</span><br><span class="line">        y_pred, y_true = torch.argmax(pred, axis=<span class="number">1</span>), y.long().squeeze()</span><br><span class="line">        correct += (y_pred == y_true).<span class="built_in">type</span>(torch.<span class="built_in">float</span>).<span class="built_in">sum</span>().item()</span><br><span class="line">        losses += loss.item()</span><br><span class="line">    correct /= size</span><br><span class="line">    losses /= num_batches</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;Train: Accuracy: <span class="subst">&#123;(<span class="number">100</span>*correct):&gt;<span class="number">0.2</span>f&#125;</span>%, Avg loss: <span class="subst">&#123;losses:&gt;5f&#125;</span>&quot;</span>)</span><br><span class="line">    <span class="keyword">return</span> losses, correct</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 验证一轮， 验证集数据加载，模型，损失函数，device</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">valid_one_epoch</span>(<span class="params">valid_loader, model, criterion, device</span>):</span><br><span class="line">    model.<span class="built_in">eval</span>()</span><br><span class="line"></span><br><span class="line">    colon_all_dataset.train_mode()</span><br><span class="line">    colon_1_dataset.train_mode()</span><br><span class="line">    colon_2_dataset.train_mode()</span><br><span class="line">    colon_3_dataset.train_mode()</span><br><span class="line">    colon_val_dataset.train_mode()</span><br><span class="line">  </span><br><span class="line">    size = <span class="built_in">len</span>(valid_loader.dataset)</span><br><span class="line">    num_batches = <span class="built_in">len</span>(valid_loader)</span><br><span class="line">    losses, correct = <span class="number">0</span>, <span class="number">0</span></span><br><span class="line">    <span class="comment">################################# validation #################################</span></span><br><span class="line">    <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">        <span class="keyword">for</span> batch, (x, y) <span class="keyword">in</span> <span class="built_in">enumerate</span>(tqdm(valid_loader)):</span><br><span class="line">            device = torch.device(device)</span><br><span class="line">            x, y = x.to(device), y.to(device)</span><br><span class="line">            pred = model(x)</span><br><span class="line">            loss = criterion(pred, y.long().squeeze())</span><br><span class="line"></span><br><span class="line">            current = batch * <span class="built_in">len</span>(x)</span><br><span class="line">            y_pred, y_true = torch.argmax(pred, axis=<span class="number">1</span>), y.long().squeeze()</span><br><span class="line">            correct += (y_pred == y_true).<span class="built_in">type</span>(torch.<span class="built_in">float</span>).<span class="built_in">sum</span>().item()</span><br><span class="line">            losses += loss.item()</span><br><span class="line">    correct /= size</span><br><span class="line">    losses /= num_batches</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;Valid: Accuracy: <span class="subst">&#123;(<span class="number">100</span>*correct):&gt;<span class="number">0.2</span>f&#125;</span>%, Avg loss: <span class="subst">&#123;losses:&gt;5f&#125;</span> \n&quot;</span>)</span><br><span class="line">    <span class="keyword">return</span> losses, correct</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">train_valid</span>(<span class="params">train_loader,valid_loader, model, criterion, optimizer, scheduler, device, part = <span class="literal">None</span></span>):</span><br><span class="line">    liveloss = PlotLosses()</span><br><span class="line">  </span><br><span class="line">    tolerance = <span class="number">0</span></span><br><span class="line">    best_loss = np.inf</span><br><span class="line">    best_epoch = <span class="number">0</span></span><br><span class="line">    best_acc = <span class="number">0</span></span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;Starting Training...\n&#x27;</span>)</span><br><span class="line">    <span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>, EPOCHS):</span><br><span class="line">        logs = &#123;&#125;</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;-------------------------------   Epoch <span class="subst">&#123;epoch + <span class="number">1</span>&#125;</span>   -------------------------------&quot;</span>)</span><br><span class="line"></span><br><span class="line">        train_loss, train_acc = train_one_epoch(train_loader, model, criterion, optimizer, device)</span><br><span class="line">        valid_loss, valid_acc = valid_one_epoch(valid_loader, model, criterion, device)</span><br><span class="line">        scheduler.step()</span><br><span class="line">      </span><br><span class="line">        <span class="comment"># save validation loss if it was improved (reduced) &amp; validation accuracy if it was improved (increased)</span></span><br><span class="line">        <span class="keyword">if</span> valid_loss &lt; best_loss <span class="keyword">and</span> valid_acc &gt; best_acc:</span><br><span class="line">            best_epoch = epoch + <span class="number">1</span></span><br><span class="line">            best_loss = valid_loss</span><br><span class="line">            best_acc = valid_acc</span><br><span class="line">            <span class="comment"># save the model&#x27;s weights and biases</span></span><br><span class="line">            <span class="keyword">if</span> part:</span><br><span class="line">                torch.save(model, <span class="string">f&quot;vgg_ep<span class="subst">&#123;best_epoch&#125;</span>_part<span class="subst">&#123;part&#125;</span>.pth&quot;</span>)</span><br><span class="line">            <span class="keyword">else</span>: </span><br><span class="line">                torch.save(model, <span class="string">f&quot;vgg_ep<span class="subst">&#123;best_epoch&#125;</span>.pth&quot;</span>)</span><br><span class="line"></span><br><span class="line">      </span><br><span class="line">        <span class="keyword">if</span> valid_acc &lt; best_acc:</span><br><span class="line">            tolerance += <span class="number">1</span></span><br><span class="line">      </span><br><span class="line">        logs[<span class="string">&#x27;log loss&#x27;</span>] = train_loss</span><br><span class="line">        logs[<span class="string">&#x27;accuracy&#x27;</span>] = train_acc*<span class="number">100</span></span><br><span class="line">        logs[<span class="string">&#x27;val_log loss&#x27;</span>] = valid_loss</span><br><span class="line">        logs[<span class="string">&#x27;val_accuracy&#x27;</span>] = valid_acc*<span class="number">100</span></span><br><span class="line">      </span><br><span class="line">        liveloss.update(logs)</span><br><span class="line">        liveloss.send()</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;Done!&quot;</span>)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># train all</span></span><br><span class="line">train_valid(train_loader,val_loader, Model, loss_fn, optimizer, scheduler, device)</span><br></pre></td></tr></table></figure><p>可以看到模型拟合的很快</p><p><img src="image-20221101180725-qad0jfu.png" alt="image.png"></p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 3 parts train </span></span><br><span class="line">train_valid(train_1_loader,val_loader, Model, loss_fn, optimizer, scheduler, device, part = <span class="number">1</span>)</span><br><span class="line">train_valid(train_2_loader,val_loader, Model, loss_fn, optimizer, scheduler, device, part = <span class="number">2</span>)</span><br><span class="line">train_valid(train_3_loader,val_loader, Model, loss_fn, optimizer, scheduler, device, part = <span class="number">3</span>)</span><br></pre></td></tr></table></figure><h2 id="模型评估"><a href="#模型评估" class="headerlink" title="模型评估"></a>模型评估</h2><p>这里注意的是不需要先对pred进行softmax，在计算loss，而是直接计算loss：</p><p>Ref:<a href="https://blog.csdn.net/DragonGirI/article/details/105743487">pytorch 计算 CrossEntropyLoss 和 softmax 激活层</a></p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># test</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">test_model</span>(<span class="params">test_loader, model, criterion, device</span>):</span><br><span class="line">    model.<span class="built_in">eval</span>()</span><br><span class="line">    cervical_test_dataset.test_mode()</span><br><span class="line">  </span><br><span class="line">    true_labels = []</span><br><span class="line">    pred_labels = []</span><br><span class="line">    scores = []</span><br><span class="line"></span><br><span class="line">    size = <span class="built_in">len</span>(test_loader.dataset)</span><br><span class="line"></span><br><span class="line">    num_batches = <span class="built_in">len</span>(test_loader)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&#x27;size:<span class="subst">&#123;size&#125;</span>; num_batches:<span class="subst">&#123;num_batches&#125;</span>&#x27;</span>)</span><br><span class="line">    losses, correct = <span class="number">0</span>, <span class="number">0</span></span><br><span class="line">    <span class="comment">################################# validation #################################</span></span><br><span class="line">    <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">        <span class="keyword">for</span> batch, (x, y) <span class="keyword">in</span> <span class="built_in">enumerate</span>(tqdm(test_loader)):</span><br><span class="line">            device = torch.device(device)</span><br><span class="line">            x, y = x.to(device), y.to(device)</span><br><span class="line">            pred = model(x)</span><br><span class="line"><span class="comment">#             pred = nn.Softmax()(pred)</span></span><br><span class="line"></span><br><span class="line">            loss = criterion(pred, y.long().squeeze()) </span><br><span class="line">            current = batch * <span class="built_in">len</span>(x)</span><br><span class="line">            scores += pred.tolist()</span><br><span class="line">            y_pred, y_true = torch.argmax(pred, axis=<span class="number">1</span>), y.long().squeeze()</span><br><span class="line">            correct += (y_pred == y_true).<span class="built_in">type</span>(torch.<span class="built_in">float</span>).<span class="built_in">sum</span>().item()</span><br><span class="line">            loss, current = np.<span class="built_in">round</span>(loss.item(), <span class="number">5</span>), batch * <span class="built_in">len</span>(x)</span><br><span class="line">            true_labels += y_true.detach().cpu().tolist()</span><br><span class="line">            pred_labels += y_pred.detach().cpu().tolist()</span><br><span class="line">            losses += loss.item()</span><br><span class="line">    correct /= size</span><br><span class="line">    losses /= num_batches</span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;Test: Accuracy: <span class="subst">&#123;(<span class="number">100</span>*correct):&gt;<span class="number">0.2</span>f&#125;</span>%, Avg loss: <span class="subst">&#123;losses:&gt;5f&#125;</span> \n&quot;</span>)</span><br><span class="line">    <span class="keyword">return</span> np.array(true_labels), np.array(pred_labels), np.array(scores)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">test_model_obj = torch.load(<span class="string">&#x27;模型文件path&#x27;</span>)</span><br><span class="line">test_model_obj = test_model_obj.to(device)</span><br><span class="line">test_model(test_loader, test_model_obj, loss_fn, device)</span><br></pre></td></tr></table></figure><h1 id="实验结果"><a href="#实验结果" class="headerlink" title="实验结果"></a>实验结果</h1><div class="table-container"><table><thead><tr><th>使用的数据</th><th>评估结果</th></tr></thead><tbody><tr><td>全部训练数据（Train_1+Train_2+Train_3）</td><td>Accuracy: 99.60%, Avg loss: 0.011775</td></tr><tr><td>Train_1</td><td>Accuracy: 73.20%, Avg loss: 0.641481</td></tr><tr><td>Train_2</td><td>Accuracy: 71.40%, Avg loss: 0.649055</td></tr><tr><td>Train_3</td><td>Accuracy: 56.80%, Avg loss: 0.654335</td></tr></tbody></table></div><h1 id="实验分析"><a href="#实验分析" class="headerlink" title="实验分析"></a>实验分析</h1><p>见下篇</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;本案例分上下两篇，上篇介绍肠癌图像分类任务的本地baseline，下篇介绍将肠癌图像分类任务移植到FATE上，实现联邦学习。&lt;/p&gt;
&lt;h1 id=&quot;任务目标&quot;&gt;&lt;a href=&quot;#任务目标&quot; class=&quot;headerlink&quot; title=&quot;任务目标&quot;&gt;&lt;/a&gt;任务目标</summary>
      
    
    
    
    <category term="联邦学习" scheme="https://guoyujian.github.io/categories/%E8%81%94%E9%82%A6%E5%AD%A6%E4%B9%A0/"/>
    
    
    <category term="联邦学习" scheme="https://guoyujian.github.io/tags/%E8%81%94%E9%82%A6%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>FATE横向联邦学习：手写数字识别</title>
    <link href="https://guoyujian.github.io/2022/11/04/FATE%E6%A8%AA%E5%90%91%E8%81%94%E9%82%A6%E5%AD%A6%E4%B9%A0%EF%BC%9A%E6%89%8B%E5%86%99%E6%95%B0%E5%AD%97%E8%AF%86%E5%88%AB/"/>
    <id>https://guoyujian.github.io/2022/11/04/FATE%E6%A8%AA%E5%90%91%E8%81%94%E9%82%A6%E5%AD%A6%E4%B9%A0%EF%BC%9A%E6%89%8B%E5%86%99%E6%95%B0%E5%AD%97%E8%AF%86%E5%88%AB/</id>
    <published>2022-11-03T16:04:59.000Z</published>
    <updated>2022-11-03T16:06:33.144Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>上上一篇介绍了如何使用FATE发起一个横向联邦学习任务，使用的数据格式是结构化的数据，使用的算法是经典的LR算法。</p><p>能不能使用FATE做计算机视觉的神经网络的联邦学习呢？</p><p>答案是可以的。本篇就通过手写数字识别这一经典任务来学习如何使用FATE来完成一个计算机视觉方面的神经网络算法的联邦学习job</p></blockquote><p>‍</p><h1 id="实验环境"><a href="#实验环境" class="headerlink" title="实验环境"></a>实验环境</h1><p>fate standalone 1.9.0</p><ul><li>数据集mnist：<code>/data/projects/fate/examples/data/mnist_train</code></li><li>code:<code>/data/projects/fate/examples/dsl/v2/homo_nn/mnist_demo</code></li></ul><blockquote><p>最好把这几个文件夹复制出来，再改</p></blockquote><p>code文件夹中有以下几个文件，后面需要用到。</p><p>‍</p><p>在README.md中已经写出了用法，本篇将详细讲解。</p><p><img src="image-20221028155604-ny1t6o7.png" alt="image.png"></p><p>‍</p><h1 id="实验步骤"><a href="#实验步骤" class="headerlink" title="实验步骤"></a>实验步骤</h1><h2 id="下载数据集"><a href="#下载数据集" class="headerlink" title="下载数据集"></a>下载数据集</h2><p>执行<code>fate_test data download -t mnist</code>命令下载mnist数据集，下载的位置位于<code>FATE/examples/data/mnist_train</code></p><h2 id="绑定数据"><a href="#绑定数据" class="headerlink" title="绑定数据"></a>绑定数据</h2><p>修改bind_local_path.json的address.path为数据集文件夹所在的位置，修改后如下。</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">&#123;</span><br><span class="line">    <span class="string">&quot;engine&quot;</span>: <span class="string">&quot;PATH&quot;</span>,</span><br><span class="line">    <span class="string">&quot;namespace&quot;</span>: <span class="string">&quot;experiment&quot;</span>,</span><br><span class="line">    <span class="string">&quot;name&quot;</span>: <span class="string">&quot;mnist_images&quot;</span>,</span><br><span class="line">    <span class="string">&quot;address&quot;</span>: &#123;</span><br><span class="line">        <span class="string">&quot;path&quot;</span>: <span class="string">&quot;/data/projects/fate/examples/data/mnist_train&quot;</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>修改完成后执行<code>flow table bind -c bind_local_path.json</code>命令进行数据绑定。这样一来，文件夹中的数据就和命名空间为experiment，表名为mnist_images的表关联了起来。</p><p>返回类似即绑定成功。</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="string">&quot;retcode&quot;</span>: 0,</span><br><span class="line"><span class="string">&quot;retmsg&quot;</span>: <span class="string">&quot;success&quot;</span></span><br></pre></td></tr></table></figure><h2 id="配置文件并提交job"><a href="#配置文件并提交job" class="headerlink" title="配置文件并提交job"></a>配置文件并提交job</h2><p>mnist_dsl.json文件：</p><figure class="highlight json"><table><tr><td class="code"><pre><span class="line"><span class="punctuation">&#123;</span></span><br><span class="line">    <span class="attr">&quot;components&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">        <span class="attr">&quot;reader_0&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">            <span class="attr">&quot;module&quot;</span><span class="punctuation">:</span> <span class="string">&quot;Reader&quot;</span><span class="punctuation">,</span></span><br><span class="line">            <span class="attr">&quot;output&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">                <span class="attr">&quot;data&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span></span><br><span class="line">                    <span class="string">&quot;data&quot;</span></span><br><span class="line">                <span class="punctuation">]</span></span><br><span class="line">            <span class="punctuation">&#125;</span></span><br><span class="line">        <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">&quot;homo_nn_0&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">            <span class="attr">&quot;module&quot;</span><span class="punctuation">:</span> <span class="string">&quot;HomoNN&quot;</span><span class="punctuation">,</span></span><br><span class="line">            <span class="attr">&quot;input&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">                <span class="attr">&quot;data&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">                    <span class="attr">&quot;train_data&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span></span><br><span class="line">                        <span class="string">&quot;reader_0.data&quot;</span></span><br><span class="line">                    <span class="punctuation">]</span></span><br><span class="line">                <span class="punctuation">&#125;</span></span><br><span class="line">            <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">            <span class="attr">&quot;output&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">                <span class="attr">&quot;data&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span></span><br><span class="line">                    <span class="string">&quot;data&quot;</span></span><br><span class="line">                <span class="punctuation">]</span><span class="punctuation">,</span></span><br><span class="line">                <span class="attr">&quot;model&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span></span><br><span class="line">                    <span class="string">&quot;model&quot;</span></span><br><span class="line">                <span class="punctuation">]</span></span><br><span class="line">            <span class="punctuation">&#125;</span></span><br><span class="line">        <span class="punctuation">&#125;</span></span><br><span class="line">    <span class="punctuation">&#125;</span></span><br><span class="line"><span class="punctuation">&#125;</span></span><br></pre></td></tr></table></figure><p>mnist_conf.json文件：</p><figure class="highlight json"><table><tr><td class="code"><pre><span class="line"><span class="punctuation">&#123;</span></span><br><span class="line">    <span class="attr">&quot;dsl_version&quot;</span><span class="punctuation">:</span> <span class="number">2</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;initiator&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">        <span class="attr">&quot;role&quot;</span><span class="punctuation">:</span> <span class="string">&quot;guest&quot;</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">&quot;party_id&quot;</span><span class="punctuation">:</span> <span class="number">9999</span></span><br><span class="line">    <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;role&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">        <span class="attr">&quot;arbiter&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span></span><br><span class="line">            <span class="number">9999</span></span><br><span class="line">        <span class="punctuation">]</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">&quot;host&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span></span><br><span class="line">            <span class="number">9999</span></span><br><span class="line">        <span class="punctuation">]</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">&quot;guest&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span></span><br><span class="line">            <span class="number">9999</span></span><br><span class="line">        <span class="punctuation">]</span></span><br><span class="line">    <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;component_parameters&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">        <span class="attr">&quot;common&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">            <span class="attr">&quot;homo_nn_0&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">                <span class="attr">&quot;api_version&quot;</span><span class="punctuation">:</span> <span class="number">2</span><span class="punctuation">,</span></span><br><span class="line">                <span class="attr">&quot;encode_label&quot;</span><span class="punctuation">:</span> <span class="keyword">true</span><span class="punctuation">,</span></span><br><span class="line">                <span class="attr">&quot;max_iter&quot;</span><span class="punctuation">:</span> <span class="number">2</span><span class="punctuation">,</span></span><br><span class="line">                <span class="attr">&quot;batch_size&quot;</span><span class="punctuation">:</span> <span class="number">32</span><span class="punctuation">,</span></span><br><span class="line">                <span class="attr">&quot;early_stop&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">                    <span class="attr">&quot;early_stop&quot;</span><span class="punctuation">:</span> <span class="string">&quot;diff&quot;</span><span class="punctuation">,</span></span><br><span class="line">                    <span class="attr">&quot;eps&quot;</span><span class="punctuation">:</span> <span class="number">0.0001</span></span><br><span class="line">                <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">                <span class="attr">&quot;optimizer&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">                    <span class="attr">&quot;lr&quot;</span><span class="punctuation">:</span> <span class="number">0.001</span><span class="punctuation">,</span></span><br><span class="line">                    <span class="attr">&quot;optimizer&quot;</span><span class="punctuation">:</span> <span class="string">&quot;Adam&quot;</span></span><br><span class="line">                <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">                <span class="attr">&quot;loss&quot;</span><span class="punctuation">:</span> <span class="string">&quot;NLLLoss&quot;</span><span class="punctuation">,</span></span><br><span class="line">                <span class="attr">&quot;metrics&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span></span><br><span class="line">                    <span class="string">&quot;accuracy&quot;</span></span><br><span class="line">                <span class="punctuation">]</span><span class="punctuation">,</span></span><br><span class="line">                <span class="attr">&quot;nn_define&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span></span><br><span class="line">                    <span class="punctuation">&#123;</span></span><br><span class="line">                        <span class="attr">&quot;layer&quot;</span><span class="punctuation">:</span> <span class="string">&quot;Conv2d&quot;</span><span class="punctuation">,</span></span><br><span class="line">                        <span class="attr">&quot;in_channels&quot;</span><span class="punctuation">:</span> <span class="number">1</span><span class="punctuation">,</span></span><br><span class="line">                        <span class="attr">&quot;out_channels&quot;</span><span class="punctuation">:</span> <span class="number">10</span><span class="punctuation">,</span></span><br><span class="line">                        <span class="attr">&quot;kernel_size&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span></span><br><span class="line">                            <span class="number">5</span><span class="punctuation">,</span></span><br><span class="line">                            <span class="number">5</span></span><br><span class="line">                        <span class="punctuation">]</span></span><br><span class="line">                    <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">                    <span class="punctuation">&#123;</span></span><br><span class="line">                        <span class="attr">&quot;layer&quot;</span><span class="punctuation">:</span> <span class="string">&quot;MaxPool2d&quot;</span><span class="punctuation">,</span></span><br><span class="line">                        <span class="attr">&quot;kernel_size&quot;</span><span class="punctuation">:</span> <span class="number">2</span></span><br><span class="line">                    <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">                    <span class="punctuation">&#123;</span></span><br><span class="line">                        <span class="attr">&quot;layer&quot;</span><span class="punctuation">:</span> <span class="string">&quot;ReLU&quot;</span></span><br><span class="line">                    <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">                    <span class="punctuation">&#123;</span></span><br><span class="line">                        <span class="attr">&quot;layer&quot;</span><span class="punctuation">:</span> <span class="string">&quot;Conv2d&quot;</span><span class="punctuation">,</span></span><br><span class="line">                        <span class="attr">&quot;in_channels&quot;</span><span class="punctuation">:</span> <span class="number">10</span><span class="punctuation">,</span></span><br><span class="line">                        <span class="attr">&quot;out_channels&quot;</span><span class="punctuation">:</span> <span class="number">20</span><span class="punctuation">,</span></span><br><span class="line">                        <span class="attr">&quot;kernel_size&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span></span><br><span class="line">                            <span class="number">5</span><span class="punctuation">,</span></span><br><span class="line">                            <span class="number">5</span></span><br><span class="line">                        <span class="punctuation">]</span></span><br><span class="line">                    <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">                    <span class="punctuation">&#123;</span></span><br><span class="line">                        <span class="attr">&quot;layer&quot;</span><span class="punctuation">:</span> <span class="string">&quot;Dropout2d&quot;</span></span><br><span class="line">                    <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">                    <span class="punctuation">&#123;</span></span><br><span class="line">                        <span class="attr">&quot;layer&quot;</span><span class="punctuation">:</span> <span class="string">&quot;MaxPool2d&quot;</span><span class="punctuation">,</span></span><br><span class="line">                        <span class="attr">&quot;kernel_size&quot;</span><span class="punctuation">:</span> <span class="number">2</span></span><br><span class="line">                    <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">                    <span class="punctuation">&#123;</span></span><br><span class="line">                        <span class="attr">&quot;layer&quot;</span><span class="punctuation">:</span> <span class="string">&quot;ReLU&quot;</span></span><br><span class="line">                    <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">                    <span class="punctuation">&#123;</span></span><br><span class="line">                        <span class="attr">&quot;layer&quot;</span><span class="punctuation">:</span> <span class="string">&quot;Flatten&quot;</span></span><br><span class="line">                    <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">                    <span class="punctuation">&#123;</span></span><br><span class="line">                        <span class="attr">&quot;layer&quot;</span><span class="punctuation">:</span> <span class="string">&quot;Linear&quot;</span><span class="punctuation">,</span></span><br><span class="line">                        <span class="attr">&quot;in_features&quot;</span><span class="punctuation">:</span> <span class="number">320</span><span class="punctuation">,</span></span><br><span class="line">                        <span class="attr">&quot;out_features&quot;</span><span class="punctuation">:</span> <span class="number">50</span></span><br><span class="line">                    <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">                    <span class="punctuation">&#123;</span></span><br><span class="line">                        <span class="attr">&quot;layer&quot;</span><span class="punctuation">:</span> <span class="string">&quot;ReLU&quot;</span></span><br><span class="line">                    <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">                    <span class="punctuation">&#123;</span></span><br><span class="line">                        <span class="attr">&quot;layer&quot;</span><span class="punctuation">:</span> <span class="string">&quot;Linear&quot;</span><span class="punctuation">,</span></span><br><span class="line">                        <span class="attr">&quot;in_features&quot;</span><span class="punctuation">:</span> <span class="number">50</span><span class="punctuation">,</span></span><br><span class="line">                        <span class="attr">&quot;out_features&quot;</span><span class="punctuation">:</span> <span class="number">10</span></span><br><span class="line">                    <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">                    <span class="punctuation">&#123;</span></span><br><span class="line">                        <span class="attr">&quot;layer&quot;</span><span class="punctuation">:</span> <span class="string">&quot;LogSoftmax&quot;</span></span><br><span class="line">                    <span class="punctuation">&#125;</span></span><br><span class="line">                <span class="punctuation">]</span><span class="punctuation">,</span></span><br><span class="line">                <span class="attr">&quot;config_type&quot;</span><span class="punctuation">:</span> <span class="string">&quot;pytorch&quot;</span></span><br><span class="line">            <span class="punctuation">&#125;</span></span><br><span class="line">        <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">&quot;role&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">            <span class="attr">&quot;host&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">                <span class="attr">&quot;0&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">                    <span class="attr">&quot;reader_0&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">                        <span class="attr">&quot;table&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">                            <span class="attr">&quot;name&quot;</span><span class="punctuation">:</span> <span class="string">&quot;mnist_images&quot;</span><span class="punctuation">,</span></span><br><span class="line">                            <span class="attr">&quot;namespace&quot;</span><span class="punctuation">:</span> <span class="string">&quot;experiment&quot;</span></span><br><span class="line">                        <span class="punctuation">&#125;</span></span><br><span class="line">                    <span class="punctuation">&#125;</span></span><br><span class="line">                <span class="punctuation">&#125;</span></span><br><span class="line">            <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">            <span class="attr">&quot;guest&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">                <span class="attr">&quot;0&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">                    <span class="attr">&quot;reader_0&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">                        <span class="attr">&quot;table&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">                            <span class="attr">&quot;name&quot;</span><span class="punctuation">:</span> <span class="string">&quot;mnist_images&quot;</span><span class="punctuation">,</span></span><br><span class="line">                            <span class="attr">&quot;namespace&quot;</span><span class="punctuation">:</span> <span class="string">&quot;experiment&quot;</span></span><br><span class="line">                        <span class="punctuation">&#125;</span></span><br><span class="line">                    <span class="punctuation">&#125;</span></span><br><span class="line">                <span class="punctuation">&#125;</span></span><br><span class="line">            <span class="punctuation">&#125;</span></span><br><span class="line">        <span class="punctuation">&#125;</span></span><br><span class="line">    <span class="punctuation">&#125;</span></span><br><span class="line"><span class="punctuation">&#125;</span></span><br><span class="line"></span><br></pre></td></tr></table></figure><p>执行<code>flow job submit -c mnist_conf.json -d mnist_dsl.json</code>命令提交job：</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[root@693afd940463 mnist_demo]<span class="comment"># flow job submit -c mnist_conf.json -d mnist_dsl.json </span></span><br><span class="line">&#123;</span><br><span class="line">    <span class="string">&quot;data&quot;</span>: &#123;</span><br><span class="line">        <span class="string">&quot;board_url&quot;</span>: <span class="string">&quot;http://127.0.0.1:8080/index.html#/dashboard?job_id=202209210827526887030&amp;role=guest&amp;party_id=10000&quot;</span>,</span><br><span class="line">        <span class="string">&quot;code&quot;</span>: 0,</span><br><span class="line">        <span class="string">&quot;dsl_path&quot;</span>: <span class="string">&quot;/data/projects/fate/fateflow/jobs/202209210827526887030/job_dsl.json&quot;</span>,</span><br><span class="line">        <span class="string">&quot;job_id&quot;</span>: <span class="string">&quot;202209210827526887030&quot;</span>,</span><br><span class="line">        <span class="string">&quot;logs_directory&quot;</span>: <span class="string">&quot;/data/projects/fate/fateflow/logs/202209210827526887030&quot;</span>,</span><br><span class="line">        <span class="string">&quot;message&quot;</span>: <span class="string">&quot;success&quot;</span>,</span><br><span class="line">        <span class="string">&quot;model_info&quot;</span>: &#123;</span><br><span class="line">            <span class="string">&quot;model_id&quot;</span>: <span class="string">&quot;arbiter-10000#guest-10000#host-10000#model&quot;</span>,</span><br><span class="line">            <span class="string">&quot;model_version&quot;</span>: <span class="string">&quot;202209210827526887030&quot;</span></span><br><span class="line">        &#125;,</span><br><span class="line">        <span class="string">&quot;pipeline_dsl_path&quot;</span>: <span class="string">&quot;/data/projects/fate/fateflow/jobs/202209210827526887030/pipeline_dsl.json&quot;</span>,</span><br><span class="line">        <span class="string">&quot;runtime_conf_on_party_path&quot;</span>: <span class="string">&quot;/data/projects/fate/fateflow/jobs/202209210827526887030/guest/10000/job_runtime_on_party_conf.json&quot;</span>,</span><br><span class="line">        <span class="string">&quot;runtime_conf_path&quot;</span>: <span class="string">&quot;/data/projects/fate/fateflow/jobs/202209210827526887030/job_runtime_conf.json&quot;</span>,</span><br><span class="line">        <span class="string">&quot;train_runtime_conf_path&quot;</span>: <span class="string">&quot;/data/projects/fate/fateflow/jobs/202209210827526887030/train_runtime_conf.json&quot;</span></span><br><span class="line">    &#125;,</span><br><span class="line">    <span class="string">&quot;jobId&quot;</span>: <span class="string">&quot;202209210827526887030&quot;</span>,</span><br><span class="line">    <span class="string">&quot;retcode&quot;</span>: 0,</span><br><span class="line">    <span class="string">&quot;retmsg&quot;</span>: <span class="string">&quot;success&quot;</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="使用flow-test提交Job"><a href="#使用flow-test提交Job" class="headerlink" title="使用flow-test提交Job"></a>使用flow-test提交Job</h2><p>除了上述之外，还可以快速提交一个job。</p><p>flow-test 快速的flow测试，比较方便，只需要修改mnist_nn_testsuite.json并执行一次命令即可。他有以下特点：</p><ul><li>不需要提前绑定数据，执行完成后，也不存在被绑定的数据</li><li>日志会保存在到本地目录logs</li><li>不会产生model_id和model_version</li></ul><p>下面介绍执行步骤：</p><h3 id="修改mnist-nn-testsuite-json"><a href="#修改mnist-nn-testsuite-json" class="headerlink" title="修改mnist_nn_testsuite.json"></a>修改<code>mnist_nn_testsuite.json</code></h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">&#123;</span><br><span class="line">    <span class="string">&quot;data&quot;</span>: [</span><br><span class="line">        &#123;</span><br><span class="line">            <span class="string">&quot;engine&quot;</span>: <span class="string">&quot;PATH&quot;</span>,</span><br><span class="line">            <span class="string">&quot;namespace&quot;</span>: <span class="string">&quot;experiment&quot;</span>,</span><br><span class="line">            <span class="string">&quot;name&quot;</span>: <span class="string">&quot;mnist_images&quot;</span>,</span><br><span class="line">            <span class="string">&quot;address&quot;</span>: &#123;</span><br><span class="line">                <span class="string">&quot;path&quot;</span>: <span class="string">&quot;/data/projects/fate/work/mnist_fed/mnist_images&quot;</span></span><br><span class="line">            &#125;,</span><br><span class="line">            <span class="string">&quot;role&quot;</span>: <span class="string">&quot;guest_0&quot;</span></span><br><span class="line">        &#125;,</span><br><span class="line">        &#123;</span><br><span class="line">            <span class="string">&quot;engine&quot;</span>: <span class="string">&quot;PATH&quot;</span>,</span><br><span class="line">            <span class="string">&quot;namespace&quot;</span>: <span class="string">&quot;experiment&quot;</span>,</span><br><span class="line">            <span class="string">&quot;name&quot;</span>: <span class="string">&quot;mnist_images&quot;</span>,</span><br><span class="line">            <span class="string">&quot;address&quot;</span>: &#123;</span><br><span class="line">                <span class="string">&quot;path&quot;</span>: <span class="string">&quot;/data/projects/fate/work/mnist_fed/mnist_images&quot;</span></span><br><span class="line">            &#125;,</span><br><span class="line">            <span class="string">&quot;role&quot;</span>: <span class="string">&quot;host_0&quot;</span></span><br><span class="line">        &#125;</span><br><span class="line">    ],</span><br><span class="line">    <span class="string">&quot;tasks&quot;</span>: &#123;</span><br><span class="line">        <span class="string">&quot;mnist&quot;</span>: &#123;</span><br><span class="line">            <span class="string">&quot;conf&quot;</span>: <span class="string">&quot;./mnist_conf.json&quot;</span>,</span><br><span class="line">            <span class="string">&quot;dsl&quot;</span>: <span class="string">&quot;./mnist_dsl.json&quot;</span></span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure><h3 id="执行flow-test"><a href="#执行flow-test" class="headerlink" title="执行flow-test"></a>执行flow-test</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">fate_test suite -i mnist_nn_testsuite.json</span><br></pre></td></tr></table></figure><p>执行结果如下：</p><p><img src="image-20220922142054-e4f41jc.png" alt="image.png"></p><p>‍</p><h1 id="模型评估"><a href="#模型评估" class="headerlink" title="模型评估"></a>模型评估</h1><p>上述训练完成之后，如何进行评估本次训练得到的模型效果呢？</p><p>答案是：截止到1.9.0版本，FATE还暂不支持对计算机视觉类任务进行模型评估。。。</p><p>我的做法是，<strong>直接在FATE-FLOW中找到Job生成的模型文件，自行实现对模型的评估。</strong></p><p>要做到这一点需要熟悉源码。</p><h1 id="从How到Why"><a href="#从How到Why" class="headerlink" title="从How到Why"></a>从How到Why</h1><p>前面我们了解了FATE提交一个视觉分类任务的基本流程，但是我们还有很多未知的东西：比如为什么要这样组织数据，FATE是如何读取配置创建模型的，联邦学习结束后保存的模型在哪里，如何调用？</p><p>想要知道这些需要读懂FATE源码。</p><h1 id="源码（部分）"><a href="#源码（部分）" class="headerlink" title="源码（部分）"></a>源码（部分）</h1><p>该部分介绍FATE是如何根据DSL和CONF配置读入数据、创建和训练模型以及导出模型的。</p><p>这里先介绍一些比较重要的目录：</p><blockquote><ul><li><a href="https://github.com/FederatedAI/FATE：">https://github.com/FederatedAI/FATE：</a> FATE官方开源的根目录</li><li><a href="https://github.com/FederatedAI/FATE/tree/master/python/federatedml：FATE联邦学习算法组件的源码目录，也是后面重点研究的目录，读懂该目录下的源码就可以开始开发新的算法组件。">https://github.com/FederatedAI/FATE/tree/master/python/federatedml：FATE联邦学习算法组件的源码目录，也是后面重点研究的目录，读懂该目录下的源码就可以开始开发新的算法组件。</a></li><li><a href="https://github.com/FederatedAI/FATE-Flow/tree/3afbc3e5d335ac96634eadfc493c4c697ecbfc19/python/fate_flow/apps：FATE">https://github.com/FederatedAI/FATE-Flow/tree/3afbc3e5d335ac96634eadfc493c4c697ecbfc19/python/fate_flow/apps：FATE</a> API源码目录，可以在这里开发新的API</li></ul></blockquote><p>‍</p><p>从上面的案例中可以看到，我们主要使用的是HomoNN算法组件，所以这里我们要找到NN对应的位置：<a href="https://github.com/FederatedAI/FATE/tree/master/python/federatedml/nn，这里nn是神经网络的意思。">https://github.com/FederatedAI/FATE/tree/master/python/federatedml/nn，这里nn是神经网络的意思。</a></p><p>在该目录下，可以看到三个文件夹：</p><ul><li>backend：公共后端代码</li><li>hetero_nn：纵向nn组件</li><li>homo_nn：横向nn组件</li></ul><p>这三个文件夹中是需要重点读懂的代码。</p><p>首先，这里明确，我们要弄懂的问题：</p><ol><li>图像数据是如何input的</li><li>为什么做图像任务时，数据的组织形式要分为images/、config.yaml、filenames以及targets</li><li>FATE是如何根据CONF生成模型，optimizer等算法参数的。</li><li>FATE是如何进行训练的。</li><li>FATE是否支持使用预训练的模型进行训练，是否支持使用GPU进行训练，是否可以自定义添加log等等，如果不能，可否开发自己的组件来实现。</li><li>如果使用配置定义模型，那么FATE支持的layer以及参数有哪些？</li></ol><p>带着这些问题，我们来学习源码。</p><h2 id="enter-point-py"><a href="#enter-point-py" class="headerlink" title="enter_point.py"></a>enter_point.py</h2><p>enter_point是homo_nn组件被调用的起点（存疑），文件位置：<a href="https://github.com/FederatedAI/FATE/blob/master/python/federatedml/nn/homo_nn/enter_point.py">https://github.com/FederatedAI/FATE/blob/master/python/federatedml/nn/homo_nn/enter_point.py</a></p><p>重点关注<code>HomoNNClient</code>类。它包含几个重要的方法：</p><ul><li>fit：模型训练</li><li>predict：模型预测</li><li>export_model和load_model：模型的导出和加载。</li></ul><h3 id="fit"><a href="#fit" class="headerlink" title="fit"></a>fit</h3><p>以下是该方法的主要代码。</p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">fit</span>(<span class="params">self, data, *args</span>):</span><br><span class="line">...</span><br><span class="line">        <span class="keyword">from</span> federatedml.nn.homo_nn._torch <span class="keyword">import</span> build_trainer</span><br><span class="line">...</span><br><span class="line">        self._trainer, dataloader = build_trainer(</span><br><span class="line">            param=self.param,</span><br><span class="line">            data=data,</span><br><span class="line">            should_label_align=<span class="keyword">not</span> self.component_properties.is_warm_start,</span><br><span class="line">            trainer=self._trainer,</span><br><span class="line">        ) <span class="comment"># 调用build_trainer获取trainer和dataloader</span></span><br><span class="line">        self._trainer.fit(dataloader) <span class="comment"># 执行训练</span></span><br><span class="line">        self.set_summary(self._trainer.summary())</span><br><span class="line">        <span class="comment"># save model to local filesystem</span></span><br><span class="line">        self._trainer.save_checkpoint()</span><br><span class="line">...</span><br></pre></td></tr></table></figure><p>可以看到trainer和dataloader是通过调用build_trainer返回的。</p><p>‍</p><h2 id="torch-py"><a href="#torch-py" class="headerlink" title="_torch.py"></a>_torch.py</h2><p>这是FATE进行联邦学习，homo_nn组件的主要实现代码。</p><h3 id="build-trainer"><a href="#build-trainer" class="headerlink" title="build_trainer"></a>build_trainer</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">build_trainer</span>(<span class="params">param: HomoNNParam, data, should_label_align=<span class="literal">True</span>, trainer=<span class="literal">None</span></span>):</span><br><span class="line">    ...</span><br><span class="line">    pl_trainer = pl.Trainer(</span><br><span class="line">        max_epochs=total_epoch,</span><br><span class="line">        callbacks=[EarlyStopCallback(context)],</span><br><span class="line">        num_sanity_val_steps=<span class="number">0</span>,</span><br><span class="line">    )</span><br><span class="line">    ...</span><br><span class="line">    pl_model = FedLightModule(</span><br><span class="line">        context,</span><br><span class="line">        layers_config=param.nn_define,</span><br><span class="line">        optimizer_config=param.optimizer,</span><br><span class="line">        loss_config=&#123;<span class="string">&quot;loss&quot;</span>: param.loss&#125;,</span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">    ...</span><br><span class="line"></span><br><span class="line">    dataset = make_dataset(</span><br><span class="line">        data=data,</span><br><span class="line">        is_train=should_label_align,</span><br><span class="line">        expected_label_type=expected_label_type,</span><br><span class="line">    )</span><br><span class="line">    ...</span><br><span class="line">    dataloader = torch.utils.data.DataLoader(</span><br><span class="line">        dataset=dataset, batch_size=batch_size, num_workers=<span class="number">1</span></span><br><span class="line">    )</span><br><span class="line"><span class="keyword">return</span> trainer, dataloader</span><br></pre></td></tr></table></figure><p>这里就可以看到dataset是调用make_dataset方法得到，model是FedLightModule的实例化对象。</p><p>‍</p><h3 id="make-dataset"><a href="#make-dataset" class="headerlink" title="make_dataset"></a>make_dataset</h3><p>这里可以看到，图像数据，是通过VisionDataSet实例化得到的。具体VisionDataSet后面再谈。</p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">make_dataset</span>(<span class="params">data, **kwargs</span>):</span><br><span class="line">    <span class="keyword">if</span> is_table(data):</span><br><span class="line">        dataset = TableDataSet(data_instances=data, **kwargs)</span><br><span class="line">    <span class="keyword">elif</span> <span class="built_in">isinstance</span>(data, LocalData):</span><br><span class="line">        dataset = VisionDataSet(data.path, **kwargs)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">raise</span> TypeError(<span class="string">f&quot;data type <span class="subst">&#123;data&#125;</span> not supported&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> dataset</span><br></pre></td></tr></table></figure><p>‍</p><h3 id="FedLightModule-init"><a href="#FedLightModule-init" class="headerlink" title="FedLightModule.init()"></a>FedLightModule.<strong>init</strong>()</h3><p>关注<code>FedLightModule</code>这个类。该类继承了<code>LightningModule</code>。这东西看上去是一个将pytorch轻量化、规范化的库。</p><p>该类有以下方法：</p><ul><li><strong>init</strong>：初始化</li><li>forward：前向传播</li><li>training_step：每个batch训练的执行代码，传入batch和batch_idx，返回loss</li><li>validation_step：每个batch验证的执行代码，传入batch和batch_idx，返回loss和acc</li><li>validation_epoch_end：每个epoch结束后执行，输入的是所有batch的outputs，打印该epoch的local loss和local acc。（local的意思是，只基于自己这一方的数据计算的结果）</li><li>configure_optimizers：配置optimizer</li></ul><p>在init方法中，非常清晰的可以看到，model、loss和optimizer是如何读取配置定义出来的。</p><p>model是通过读取配置中的layer_config，生成模型的每一层，然后在“组装起来”。</p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params"></span></span><br><span class="line"><span class="params">    self,</span></span><br><span class="line"><span class="params">    context: PyTorchSAClientContext,</span></span><br><span class="line"><span class="params">    layers_config: typing.<span class="type">List</span>[typing.Mapping],</span></span><br><span class="line"><span class="params">    optimizer_config: types.SimpleNamespace,</span></span><br><span class="line"><span class="params">    loss_config: typing.Mapping,</span></span><br><span class="line"><span class="params"></span>):</span><br><span class="line">    <span class="built_in">super</span>().__init__()</span><br><span class="line">    self.save_hyperparameters()</span><br><span class="line">    self.context = context</span><br><span class="line"></span><br><span class="line">    <span class="comment"># model</span></span><br><span class="line">    layers = []</span><br><span class="line">    <span class="keyword">for</span> layer_config <span class="keyword">in</span> layers_config:</span><br><span class="line">        layer_name = layer_config[<span class="string">&quot;layer&quot;</span>]</span><br><span class="line">        layer_kwargs = &#123;k: v <span class="keyword">for</span> k, v <span class="keyword">in</span> layer_config.items() <span class="keyword">if</span> k != <span class="string">&quot;layer&quot;</span>&#125;</span><br><span class="line">        layers.append(get_layer_fn(layer_name, layer_kwargs))</span><br><span class="line">    self.model = nn.Sequential(*layers)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># loss</span></span><br><span class="line">    loss_name = loss_config[<span class="string">&quot;loss&quot;</span>]</span><br><span class="line">    loss_kwargs = &#123;k: v <span class="keyword">for</span> k, v <span class="keyword">in</span> loss_config.items() <span class="keyword">if</span> k != <span class="string">&quot;loss&quot;</span>&#125;</span><br><span class="line">    self.loss_fn, self.expected_label_type = get_loss_fn(loss_name, loss_kwargs)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># optimizer</span></span><br><span class="line">    self._optimizer_name = optimizer_config.optimizer</span><br><span class="line">    self._optimizer_kwargs = optimizer_config.kwargs</span><br><span class="line"></span><br><span class="line">    self.num_data_consumed = <span class="number">0</span></span><br><span class="line">    self._all_consumed_data_aggregated = <span class="literal">True</span></span><br><span class="line"></span><br><span class="line">    self._should_early_stop = <span class="literal">False</span></span><br><span class="line">    self._loss = <span class="literal">None</span></span><br></pre></td></tr></table></figure><p>如果我们需要定义自己的模型，比如，我们想要定义一个预训练的vgg16，则修改代码：</p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">self.model = models.vgg16(pretrained=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure><p>这里，我们可以回答第三、四、五个问题： FATE本身不支持加载预训练模型、使用GPU训练、自定义日志，但是您可以自行开发。</p><h3 id="PyTorchFederatedTrainer"><a href="#PyTorchFederatedTrainer" class="headerlink" title="PyTorchFederatedTrainer"></a>PyTorchFederatedTrainer</h3><p>这个类和模型有关。从<code>save_checkpoint</code>方法中可以知道，FATE将模型文件保存为model.ckpt。从<code>load_model</code>方法中可以了解到，加载最后得到的模型文件的方式：</p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">pl_model = FedLightModule.load_from_checkpoint(filepath)</span><br></pre></td></tr></table></figure><p>这样，我们只需要找到最后生成的模型，就可以load进来， 自己开发进行模型评估。</p><h2 id="data-py"><a href="#data-py" class="headerlink" title="data.py"></a>data.py</h2><p><a href="https://github.com/FederatedAI/FATE/blob/master/python/federatedml/nn/backend/pytorch/data.py">https://github.com/FederatedAI/FATE/blob/master/python/federatedml/nn/backend/pytorch/data.py</a></p><p>FATE通过<code>VisionDataSet</code>类加载图像数据，这也回答了第一、二个问题。</p><p>‍</p><h2 id="FATE支持的layer"><a href="#FATE支持的layer" class="headerlink" title="FATE支持的layer"></a>FATE支持的layer</h2><p>在CONF文件的“nn_define”中出现了很多类型的layer：Conv2d、ReLu…</p><p>FATE支持的层的定义位于<a href="https://github.com/FederatedAI/FATE/blob/master/python/federatedml/nn/backend/fate_torch/nn.py">https://github.com/FederatedAI/FATE/blob/master/python/federatedml/nn/backend/fate_torch/nn.py</a></p><blockquote><p>这里我一开始误以为定义的层位于：<a href="https://github.com/FederatedAI/FATE/blob/master/python/federatedml/nn/backend/pytorch/nn_model.py">https://github.com/FederatedAI/FATE/blob/master/python/federatedml/nn/backend/pytorch/nn_model.py</a></p><p>后来发现是不对的，为什么不对。我也没搞清楚。</p></blockquote>]]></content>
    
    
      
      
    <summary type="html">&lt;blockquote&gt;
&lt;p&gt;上上一篇介绍了如何使用FATE发起一个横向联邦学习任务，使用的数据格式是结构化的数据，使用的算法是经典的LR算法。&lt;/p&gt;
&lt;p&gt;能不能使用FATE做计算机视觉的神经网络的联邦学习呢？&lt;/p&gt;
&lt;p&gt;答案是可以的。本篇就通过手写数字识别这一经典任务</summary>
      
    
    
    
    <category term="联邦学习" scheme="https://guoyujian.github.io/categories/%E8%81%94%E9%82%A6%E5%AD%A6%E4%B9%A0/"/>
    
    
    <category term="联邦学习" scheme="https://guoyujian.github.io/tags/%E8%81%94%E9%82%A6%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>FATE DSL配置文件详细解释</title>
    <link href="https://guoyujian.github.io/2022/11/04/FATE-DSL%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6%E8%AF%A6%E7%BB%86%E8%A7%A3%E9%87%8A/"/>
    <id>https://guoyujian.github.io/2022/11/04/FATE-DSL%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6%E8%AF%A6%E7%BB%86%E8%A7%A3%E9%87%8A/</id>
    <published>2022-11-03T16:03:55.000Z</published>
    <updated>2022-11-03T16:04:41.428Z</updated>
    
    <content type="html"><![CDATA[<p>这里对FATE DSL文件做详细解释。</p><h1 id="DSL"><a href="#DSL" class="headerlink" title="DSL"></a>DSL</h1><p>DSL有两个版本，FATE 1.7以上版本强制使用v2。</p><p>dsl.json提供了流程，conf.json提供了个流程参数。</p><p>其中dsl.json的配置参见：<a href="https://github.com/FederatedAI/FATE/blob/master/doc/tutorial/dsl_conf/dsl_conf_v2_setting_guide.zh.md">https://github.com/FederatedAI/FATE/blob/master/doc/tutorial/dsl_conf/dsl_conf_v2_setting_guide.zh.md</a></p><p>下面选取一个案例。</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">//dsl.json</span><br><span class="line">&#123;</span><br><span class="line">    &quot;components&quot;: &#123; // 一级配置，表示这个任务会使用的组件</span><br><span class="line">        &quot;reader_0&quot;: &#123; // 组件的名字，自定义</span><br><span class="line">    // 指定模块，参数需要和目录/data/projects/fate/fate/python/federatedml/components一致，里面有一些定义好的组件，但是感觉不全，我的建议还是看官方docs：https://fate.readthedocs.io/en/latest/federatedml_component/</span><br><span class="line">            &quot;module&quot;: &quot;Reader&quot;, //数据需要通过Reader组件从数据存储拿取数据，注意此组件仅有输出output，此模块必须要有</span><br><span class="line">            &quot;output&quot;: &#123;</span><br><span class="line">                &quot;data&quot;: [</span><br><span class="line">                    &quot;data&quot; // 这个地方是自定义还是必须是train？需要尝试</span><br><span class="line">                ]</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;,</span><br><span class="line">// 除reader之外，每个组件下包含input和output，input和output下又包含data和model</span><br><span class="line">// data input: 来自于之前的组件有四种可能的类型，</span><br><span class="line">// 1. data: 用在data_transform, feature_engineering modules 和 evaluation模块</span><br><span class="line">// 2. train_data: 用在训练组件，比如HeteroLR、HeteroSBT，如果使用了这个字段， 则这个task会被解析为一个fit task（训练任务？）</span><br><span class="line">// 3. validate_data: 如果有了train_data，那么该字段就是可选地. 这种情况下，数据被用作validation集.</span><br><span class="line">// 4. test_data: 指定用于预测的数据，如果设置了这个字段，模型也需要。</span><br><span class="line"></span><br><span class="line">// model input: 来自于之前的模块，有2种可能的类型，</span><br><span class="line">// 1. model: 由同类型（指“module”字段相同）组件输入的模型。把其他组件的模型输出作为输入。</span><br><span class="line">// 2. isometric_model: 模型输入来自上游组件。</span><br><span class="line"></span><br><span class="line">// data output: 来自于之前的模块，有4种可能的类型，</span><br><span class="line">// 1. data: </span><br><span class="line">// 2. train_data、validate_data、test_data: 仅用于数据分片？</span><br><span class="line"></span><br><span class="line">// model : 来自于之前的模块，有1种可能的类型，</span><br><span class="line">// 1. model</span><br><span class="line"></span><br><span class="line">        &quot;data_transform_0&quot;: &#123;</span><br><span class="line">            &quot;module&quot;: &quot;DataTransform&quot;,</span><br><span class="line">            &quot;input&quot;: &#123;</span><br><span class="line">                &quot;data&quot;: &#123;</span><br><span class="line">                    &quot;data&quot;: [</span><br><span class="line">                        &quot;reader_0.data&quot;</span><br><span class="line">                    ]</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;,</span><br><span class="line">            &quot;output&quot;: &#123;</span><br><span class="line">                &quot;data&quot;: [</span><br><span class="line">                    &quot;data&quot;</span><br><span class="line">                ],</span><br><span class="line">                &quot;model&quot;: [</span><br><span class="line">                    &quot;model&quot;</span><br><span class="line">                ]</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;,</span><br><span class="line">        &quot;scale_0&quot;: &#123;</span><br><span class="line">            &quot;module&quot;: &quot;FeatureScale&quot;,</span><br><span class="line">            &quot;input&quot;: &#123;</span><br><span class="line">                &quot;data&quot;: &#123;</span><br><span class="line">                    &quot;data&quot;: [</span><br><span class="line">                        &quot;data_transform_0.data&quot;</span><br><span class="line">                    ]</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;,</span><br><span class="line">            &quot;output&quot;: &#123;</span><br><span class="line">                &quot;data&quot;: [</span><br><span class="line">                    &quot;data&quot;</span><br><span class="line">                ],</span><br><span class="line">                &quot;model&quot;: [</span><br><span class="line">                    &quot;model&quot;</span><br><span class="line">                ]</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;,</span><br><span class="line">        &quot;homo_lr_0&quot;: &#123;</span><br><span class="line">            &quot;module&quot;: &quot;HomoLR&quot;,</span><br><span class="line">            &quot;input&quot;: &#123;</span><br><span class="line">                &quot;data&quot;: &#123;</span><br><span class="line">                    &quot;train_data&quot;: [</span><br><span class="line">                        &quot;scale_0.data&quot;</span><br><span class="line">                    ]</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;,</span><br><span class="line">            &quot;output&quot;: &#123;</span><br><span class="line">                &quot;data&quot;: [</span><br><span class="line">                    &quot;data&quot;</span><br><span class="line">                ],</span><br><span class="line">                &quot;model&quot;: [</span><br><span class="line">                    &quot;model&quot;</span><br><span class="line">                ]</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;,</span><br><span class="line">        &quot;evaluation_0&quot;: &#123;</span><br><span class="line">            &quot;module&quot;: &quot;Evaluation&quot;,</span><br><span class="line">            &quot;input&quot;: &#123;</span><br><span class="line">                &quot;data&quot;: &#123;</span><br><span class="line">                    &quot;data&quot;: [</span><br><span class="line">                        &quot;homo_lr_0.data&quot;</span><br><span class="line">                    ]</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;,</span><br><span class="line">            &quot;output&quot;: &#123;</span><br><span class="line">                &quot;data&quot;: [</span><br><span class="line">                    &quot;data&quot;</span><br><span class="line">                ]</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure><p>‍</p><h1 id="CONF"><a href="#CONF" class="headerlink" title="CONF"></a>CONF</h1><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">//conf.json</span><br><span class="line">&#123;</span><br><span class="line">    //fate版本大于等于1.7时，必须设置dsl_version=2</span><br><span class="line">    &quot;dsl_version&quot;: 2,</span><br><span class="line"></span><br><span class="line">    &quot;initiator&quot;: &#123; //定义发起者的角色和partyid</span><br><span class="line">        &quot;role&quot;: &quot;guest&quot;,</span><br><span class="line">        &quot;party_id&quot;: 10000</span><br><span class="line">    &#125;,</span><br><span class="line">    //定义所有的参与方</span><br><span class="line">    &quot;role&quot;: &#123;</span><br><span class="line">        &quot;guest&quot;: [</span><br><span class="line">            10000</span><br><span class="line">        ],</span><br><span class="line">        &quot;host&quot;: [</span><br><span class="line">            10000</span><br><span class="line">        ],</span><br><span class="line">        &quot;arbiter&quot;: [</span><br><span class="line">            10000</span><br><span class="line">        ]</span><br><span class="line">    &#125;,</span><br><span class="line">  </span><br><span class="line">    &quot;component_parameters&quot;: &#123;</span><br><span class="line">        //common：参数应用到所有的参与方, role：参数应用到指定的参与方</span><br><span class="line">        &quot;common&quot;: &#123;</span><br><span class="line">    //组件的详细参数参见：https://fate.readthedocs.io/en/latest/federatedml_component/</span><br><span class="line">            &quot;data_transform_0&quot;: &#123;</span><br><span class="line">                &quot;with_label&quot;: true,</span><br><span class="line">                &quot;output_format&quot;: &quot;dense&quot;</span><br><span class="line">            &#125;,</span><br><span class="line">            &quot;homo_lr_0&quot;: &#123;</span><br><span class="line">                &quot;penalty&quot;: &quot;L2&quot;,</span><br><span class="line">                &quot;tol&quot;: 1e-05,</span><br><span class="line">                &quot;alpha&quot;: 0.01,</span><br><span class="line">                &quot;optimizer&quot;: &quot;sgd&quot;,</span><br><span class="line">                &quot;batch_size&quot;: -1,</span><br><span class="line">                &quot;learning_rate&quot;: 0.15,</span><br><span class="line">                &quot;init_param&quot;: &#123;</span><br><span class="line">                    &quot;init_method&quot;: &quot;zeros&quot;</span><br><span class="line">                &#125;,</span><br><span class="line">                &quot;max_iter&quot;: 30,</span><br><span class="line">                &quot;early_stop&quot;: &quot;diff&quot;,</span><br><span class="line">                &quot;encrypt_param&quot;: &#123;</span><br><span class="line">                    &quot;method&quot;: null</span><br><span class="line">                &#125;,</span><br><span class="line">                &quot;cv_param&quot;: &#123;</span><br><span class="line">                    &quot;n_splits&quot;: 4,</span><br><span class="line">                    &quot;shuffle&quot;: true,</span><br><span class="line">                    &quot;random_seed&quot;: 33,</span><br><span class="line">                    &quot;need_cv&quot;: false</span><br><span class="line">                &#125;,</span><br><span class="line">                &quot;decay&quot;: 1,</span><br><span class="line">                &quot;decay_sqrt&quot;: true</span><br><span class="line">            &#125;,</span><br><span class="line">            &quot;evaluation_0&quot;: &#123;</span><br><span class="line">                &quot;eval_type&quot;: &quot;binary&quot;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;,</span><br><span class="line"></span><br><span class="line">        &quot;role&quot;: &#123;</span><br><span class="line">            &quot;host&quot;: &#123;</span><br><span class="line">                &quot;0&quot;: &#123; //role.host.0：参数应用到host的index=0的参与方</span><br><span class="line">                    &quot;reader_0&quot;: &#123;</span><br><span class="line">                        &quot;table&quot;: &#123;</span><br><span class="line">                            &quot;name&quot;: &quot;homo_default_credit_host&quot;,</span><br><span class="line">                            &quot;namespace&quot;: &quot;homo_default_credit_host&quot;</span><br><span class="line">                        &#125;</span><br><span class="line">                    &#125;,</span><br><span class="line">                    &quot;evaluation_0&quot;: &#123;</span><br><span class="line">                        &quot;need_run&quot;: false</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;,</span><br><span class="line">            &quot;guest&quot;: &#123;</span><br><span class="line">                &quot;0&quot;: &#123;</span><br><span class="line">                    &quot;reader_0&quot;: &#123;</span><br><span class="line">                        &quot;table&quot;: &#123;</span><br><span class="line">                            &quot;name&quot;: &quot;homo_default_credit_guest&quot;,</span><br><span class="line">                            &quot;namespace&quot;: &quot;homo_default_credit_guest&quot;</span><br><span class="line">                        &#125;</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>注：</p><ol><li>上面的conf没有使用到provider组件，该组件支持加载多种且多版本的组件提供方</li><li>上面conf没涉及系统运行时参数，具体参见：<a href="https://federatedai.github.io/FATE-Flow/latest/zh/fate_flow_job_scheduling/#43">https://federatedai.github.io/FATE-Flow/latest/zh/fate_flow_job_scheduling/#43</a></li><li>dsl v2中，predict dsl不会在训练后自动生成，用户需要通过flow client部署所需的组件：<a href="https://github.com/FederatedAI/FATE-Flow/blob/main/doc/cli/model.md#deploy">https://github.com/FederatedAI/FATE-Flow/blob/main/doc/cli/model.md#deploy</a></li><li>train dsl 和predict dsl examples：</li></ol><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&quot;components&quot;: &#123;</span><br><span class="line">    &quot;reader_0&quot;: &#123;</span><br><span class="line">        &quot;module&quot;: &quot;Reader&quot;,</span><br><span class="line">        &quot;output&quot;: &#123;</span><br><span class="line">            &quot;data&quot;: [</span><br><span class="line">                &quot;data&quot;</span><br><span class="line">            ]</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;,</span><br><span class="line">    &quot;data_transform_0&quot;: &#123;</span><br><span class="line">        &quot;module&quot;: &quot;DataTransform&quot;,</span><br><span class="line">        &quot;input&quot;: &#123;</span><br><span class="line">            &quot;data&quot;: &#123;</span><br><span class="line">                &quot;data&quot;: [</span><br><span class="line">                    &quot;reader_0.data&quot;</span><br><span class="line">                ]</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;,</span><br><span class="line">        &quot;output&quot;: &#123;</span><br><span class="line">            &quot;data&quot;: [</span><br><span class="line">                &quot;data&quot;</span><br><span class="line">            ],</span><br><span class="line">            &quot;model&quot;: [</span><br><span class="line">                &quot;model&quot;</span><br><span class="line">            ]</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;,</span><br><span class="line">    &quot;intersection_0&quot;: &#123;</span><br><span class="line">        &quot;module&quot;: &quot;Intersection&quot;,</span><br><span class="line">        &quot;input&quot;: &#123;</span><br><span class="line">            &quot;data&quot;: &#123;</span><br><span class="line">                &quot;data&quot;: [</span><br><span class="line">                    &quot;data_transform_0.data&quot;</span><br><span class="line">                ]</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;,</span><br><span class="line">        &quot;output&quot;: &#123;</span><br><span class="line">            &quot;data&quot;:[</span><br><span class="line">                &quot;data&quot;</span><br><span class="line">            ]</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;,</span><br><span class="line">    &quot;hetero_nn_0&quot;: &#123;</span><br><span class="line">        &quot;module&quot;: &quot;HeteroNN&quot;,</span><br><span class="line">        &quot;input&quot;: &#123;</span><br><span class="line">            &quot;data&quot;: &#123;</span><br><span class="line">                &quot;train_data&quot;: [</span><br><span class="line">                    &quot;intersection_0.data&quot;</span><br><span class="line">                ]</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;,</span><br><span class="line">        &quot;output&quot;: &#123;</span><br><span class="line">            &quot;data&quot;: [</span><br><span class="line">                &quot;data&quot;</span><br><span class="line">            ],</span><br><span class="line">            &quot;model&quot;: [</span><br><span class="line">                &quot;model&quot;</span><br><span class="line">            ]</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>‍</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&quot;components&quot;: &#123;</span><br><span class="line">    &quot;reader_0&quot;: &#123;</span><br><span class="line">        &quot;module&quot;: &quot;Reader&quot;,</span><br><span class="line">        &quot;output&quot;: &#123;</span><br><span class="line">            &quot;data&quot;: [</span><br><span class="line">                &quot;data&quot;</span><br><span class="line">            ]</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;,</span><br><span class="line">    &quot;data_transform_0&quot;: &#123;</span><br><span class="line">        &quot;module&quot;: &quot;DataTransform&quot;,</span><br><span class="line">        &quot;input&quot;: &#123;</span><br><span class="line">            &quot;data&quot;: &#123;</span><br><span class="line">                &quot;data&quot;: [</span><br><span class="line">                    &quot;reader_0.data&quot;</span><br><span class="line">                ]</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;,</span><br><span class="line">        &quot;output&quot;: &#123;</span><br><span class="line">            &quot;data&quot;: [</span><br><span class="line">                &quot;data&quot;</span><br><span class="line">            ],</span><br><span class="line">            &quot;model&quot;: [</span><br><span class="line">                &quot;model&quot;</span><br><span class="line">            ]</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;,</span><br><span class="line">    &quot;intersection_0&quot;: &#123;</span><br><span class="line">        &quot;module&quot;: &quot;Intersection&quot;,</span><br><span class="line">        &quot;input&quot;: &#123;</span><br><span class="line">            &quot;data&quot;: &#123;</span><br><span class="line">                &quot;data&quot;: [</span><br><span class="line">                    &quot;data_transform_0.data&quot;</span><br><span class="line">                ]</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;,</span><br><span class="line">        &quot;output&quot;: &#123;</span><br><span class="line">            &quot;data&quot;:[</span><br><span class="line">                &quot;data&quot;</span><br><span class="line">            ]</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;,</span><br><span class="line">    &quot;hetero_nn_0&quot;: &#123;</span><br><span class="line">        &quot;module&quot;: &quot;HeteroNN&quot;,</span><br><span class="line">        &quot;input&quot;: &#123;</span><br><span class="line">            &quot;data&quot;: &#123;</span><br><span class="line">                &quot;train_data&quot;: [</span><br><span class="line">                    &quot;intersection_0.data&quot;</span><br><span class="line">                ]</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;,</span><br><span class="line">        &quot;output&quot;: &#123;</span><br><span class="line">            &quot;data&quot;: [</span><br><span class="line">                &quot;data&quot;</span><br><span class="line">            ],</span><br><span class="line">            &quot;model&quot;: [</span><br><span class="line">                &quot;model&quot;</span><br><span class="line">            ]</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;,</span><br><span class="line">    &quot;evaluation_0&quot;: &#123;</span><br><span class="line">        &quot;module&quot;: &quot;Evaluation&quot;,</span><br><span class="line">        &quot;input&quot;: &#123;</span><br><span class="line">            &quot;data&quot;: &#123;</span><br><span class="line">                &quot;data&quot;: [</span><br><span class="line">                    &quot;hetero_nn_0.data&quot;</span><br><span class="line">                ]</span><br><span class="line">            &#125;</span><br><span class="line">         &#125;,</span><br><span class="line">         &quot;output&quot;: &#123;</span><br><span class="line">             &quot;data&quot;: [</span><br><span class="line">                 &quot;data&quot;</span><br><span class="line">             ]</span><br><span class="line">          &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure><h1 id="基本工作流"><a href="#基本工作流" class="headerlink" title="基本工作流"></a>基本工作流</h1><ol><li>提交作业后，作业的dsl和配置会存储到相应的目录：<code>/data/projects/fate/fateflow/jobs</code></li><li>解析dsl和conf，生成配置，分发共同的配置给每一方，并生成存储特定方的配置在目录：<code>/data/projects/fate/fateflow/jobs/[job_id]/[role]/[party_id]</code></li></ol><p>‍</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;这里对FATE DSL文件做详细解释。&lt;/p&gt;
&lt;h1 id=&quot;DSL&quot;&gt;&lt;a href=&quot;#DSL&quot; class=&quot;headerlink&quot; title=&quot;DSL&quot;&gt;&lt;/a&gt;DSL&lt;/h1&gt;&lt;p&gt;DSL有两个版本，FATE 1.7以上版本强制使用v2。&lt;/p&gt;
&lt;p&gt;dsl</summary>
      
    
    
    
    <category term="联邦学习" scheme="https://guoyujian.github.io/categories/%E8%81%94%E9%82%A6%E5%AD%A6%E4%B9%A0/"/>
    
    
    <category term="联邦学习" scheme="https://guoyujian.github.io/tags/%E8%81%94%E9%82%A6%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>FATE横向联邦学习：信用数据案例</title>
    <link href="https://guoyujian.github.io/2022/11/04/FATE%E6%A8%AA%E5%90%91%E8%81%94%E9%82%A6%E5%AD%A6%E4%B9%A0%EF%BC%9A%E4%BF%A1%E7%94%A8%E6%95%B0%E6%8D%AE%E6%A1%88%E4%BE%8B/"/>
    <id>https://guoyujian.github.io/2022/11/04/FATE%E6%A8%AA%E5%90%91%E8%81%94%E9%82%A6%E5%AD%A6%E4%B9%A0%EF%BC%9A%E4%BF%A1%E7%94%A8%E6%95%B0%E6%8D%AE%E6%A1%88%E4%BE%8B/</id>
    <published>2022-11-03T16:01:28.000Z</published>
    <updated>2022-11-03T16:03:23.148Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>通过FATE平台提交联邦学习job，有两种方式：DSL和pipline；</p><p>DSL是通过写配置文件的方式，配置联邦学习job的各个参数；pipeline是通过写python代码的方式配置和提交job</p><p>本文使用Fate的信用样例数据，介绍通过DSL的方式进行Fate横向联邦学习的使用案例。</p></blockquote><h1 id="实验设置"><a href="#实验设置" class="headerlink" title="实验设置"></a>实验设置</h1><blockquote><p>fate lastest 1.9 standalone</p><p>数据集：信用数据，位置FATE/examples/data/default_credit_homo_guest/</p><p>算法：logistics regression</p></blockquote><h1 id="实验配置"><a href="#实验配置" class="headerlink" title="实验配置"></a>实验配置</h1><h2 id="上传两方数据"><a href="#上传两方数据" class="headerlink" title="上传两方数据"></a>上传两方数据</h2><p>编辑上传数据配置文件：upload_my_homolr_guest.json</p><figure class="highlight json"><table><tr><td class="code"><pre><span class="line"><span class="punctuation">&#123;</span></span><br><span class="line"> <span class="attr">&quot;file&quot;</span><span class="punctuation">:</span><span class="string">&quot;/data/projects/fate/examples/data/default_credit_homo_guest.csv&quot;</span><span class="punctuation">,</span></span><br><span class="line"> <span class="attr">&quot;head&quot;</span><span class="punctuation">:</span><span class="number">1</span><span class="punctuation">,</span></span><br><span class="line"> <span class="attr">&quot;partition&quot;</span><span class="punctuation">:</span><span class="number">10</span><span class="punctuation">,</span></span><br><span class="line"> <span class="attr">&quot;work_mode&quot;</span><span class="punctuation">:</span><span class="number">0</span><span class="punctuation">,</span></span><br><span class="line"> <span class="attr">&quot;namespace&quot;</span><span class="punctuation">:</span><span class="string">&quot;homo_default_credit_guest&quot;</span><span class="punctuation">,</span></span><br><span class="line"> <span class="attr">&quot;table_name&quot;</span><span class="punctuation">:</span><span class="string">&quot;homo_default_credit_guest&quot;</span></span><br><span class="line"><span class="punctuation">&#125;</span></span><br><span class="line"></span><br></pre></td></tr></table></figure><p>upload_my_homolr_host.json</p><figure class="highlight json"><table><tr><td class="code"><pre><span class="line"><span class="punctuation">&#123;</span></span><br><span class="line"> <span class="attr">&quot;file&quot;</span><span class="punctuation">:</span><span class="string">&quot;/data/projects/fate/examples/data/default_credit_homo_host_1.csv&quot;</span><span class="punctuation">,</span></span><br><span class="line"> <span class="attr">&quot;head&quot;</span><span class="punctuation">:</span><span class="number">1</span><span class="punctuation">,</span></span><br><span class="line"> <span class="attr">&quot;partition&quot;</span><span class="punctuation">:</span><span class="number">10</span><span class="punctuation">,</span></span><br><span class="line"> <span class="attr">&quot;work_mode&quot;</span><span class="punctuation">:</span><span class="number">0</span><span class="punctuation">,</span></span><br><span class="line"> <span class="attr">&quot;namespace&quot;</span><span class="punctuation">:</span><span class="string">&quot;homo_default_credit_host&quot;</span><span class="punctuation">,</span></span><br><span class="line"> <span class="attr">&quot;table_name&quot;</span><span class="punctuation">:</span><span class="string">&quot;homo_default_credit_host&quot;</span></span><br><span class="line"><span class="punctuation">&#125;</span></span><br><span class="line"></span><br></pre></td></tr></table></figure><p>说明：</p><ul><li>file指出数据文件的位置</li><li>namespace和table_name确定上传表的命名空间和表名。</li></ul><h2 id="DSL配置文件"><a href="#DSL配置文件" class="headerlink" title="DSL配置文件"></a>DSL配置文件</h2><p>找到dsl配置文件：<code>/data/projects/fate/examples/dsl/v2/homo_logistic_regression/homo_lr_train_dsl.json</code>，内容如下：</p><figure class="highlight json"><table><tr><td class="code"><pre><span class="line"><span class="punctuation">&#123;</span></span><br><span class="line">    <span class="attr">&quot;components&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">        <span class="attr">&quot;reader_0&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">            <span class="attr">&quot;module&quot;</span><span class="punctuation">:</span> <span class="string">&quot;Reader&quot;</span><span class="punctuation">,</span></span><br><span class="line">            <span class="attr">&quot;output&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">                <span class="attr">&quot;data&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span></span><br><span class="line">                    <span class="string">&quot;data&quot;</span></span><br><span class="line">                <span class="punctuation">]</span></span><br><span class="line">            <span class="punctuation">&#125;</span></span><br><span class="line">        <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">&quot;data_transform_0&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">            <span class="attr">&quot;module&quot;</span><span class="punctuation">:</span> <span class="string">&quot;DataTransform&quot;</span><span class="punctuation">,</span></span><br><span class="line">            <span class="attr">&quot;input&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">                <span class="attr">&quot;data&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">                    <span class="attr">&quot;data&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span></span><br><span class="line">                        <span class="string">&quot;reader_0.data&quot;</span></span><br><span class="line">                    <span class="punctuation">]</span></span><br><span class="line">                <span class="punctuation">&#125;</span></span><br><span class="line">            <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">            <span class="attr">&quot;output&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">                <span class="attr">&quot;data&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span></span><br><span class="line">                    <span class="string">&quot;data&quot;</span></span><br><span class="line">                <span class="punctuation">]</span><span class="punctuation">,</span></span><br><span class="line">                <span class="attr">&quot;model&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span></span><br><span class="line">                    <span class="string">&quot;model&quot;</span></span><br><span class="line">                <span class="punctuation">]</span></span><br><span class="line">            <span class="punctuation">&#125;</span></span><br><span class="line">        <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">&quot;scale_0&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">            <span class="attr">&quot;module&quot;</span><span class="punctuation">:</span> <span class="string">&quot;FeatureScale&quot;</span><span class="punctuation">,</span></span><br><span class="line">            <span class="attr">&quot;input&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">                <span class="attr">&quot;data&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">                    <span class="attr">&quot;data&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span></span><br><span class="line">                        <span class="string">&quot;data_transform_0.data&quot;</span></span><br><span class="line">                    <span class="punctuation">]</span></span><br><span class="line">                <span class="punctuation">&#125;</span></span><br><span class="line">            <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">            <span class="attr">&quot;output&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">                <span class="attr">&quot;data&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span></span><br><span class="line">                    <span class="string">&quot;data&quot;</span></span><br><span class="line">                <span class="punctuation">]</span><span class="punctuation">,</span></span><br><span class="line">                <span class="attr">&quot;model&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span></span><br><span class="line">                    <span class="string">&quot;model&quot;</span></span><br><span class="line">                <span class="punctuation">]</span></span><br><span class="line">            <span class="punctuation">&#125;</span></span><br><span class="line">        <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">&quot;homo_lr_0&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">            <span class="attr">&quot;module&quot;</span><span class="punctuation">:</span> <span class="string">&quot;HomoLR&quot;</span><span class="punctuation">,</span></span><br><span class="line">            <span class="attr">&quot;input&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">                <span class="attr">&quot;data&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">                    <span class="attr">&quot;train_data&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span></span><br><span class="line">                        <span class="string">&quot;scale_0.data&quot;</span></span><br><span class="line">                    <span class="punctuation">]</span></span><br><span class="line">                <span class="punctuation">&#125;</span></span><br><span class="line">            <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">            <span class="attr">&quot;output&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">                <span class="attr">&quot;data&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span></span><br><span class="line">                    <span class="string">&quot;data&quot;</span></span><br><span class="line">                <span class="punctuation">]</span><span class="punctuation">,</span></span><br><span class="line">                <span class="attr">&quot;model&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span></span><br><span class="line">                    <span class="string">&quot;model&quot;</span></span><br><span class="line">                <span class="punctuation">]</span></span><br><span class="line">            <span class="punctuation">&#125;</span></span><br><span class="line">        <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">&quot;evaluation_0&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">            <span class="attr">&quot;module&quot;</span><span class="punctuation">:</span> <span class="string">&quot;Evaluation&quot;</span><span class="punctuation">,</span></span><br><span class="line">            <span class="attr">&quot;input&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">                <span class="attr">&quot;data&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">                    <span class="attr">&quot;data&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span></span><br><span class="line">                        <span class="string">&quot;homo_lr_0.data&quot;</span></span><br><span class="line">                    <span class="punctuation">]</span></span><br><span class="line">                <span class="punctuation">&#125;</span></span><br><span class="line">            <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">            <span class="attr">&quot;output&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">                <span class="attr">&quot;data&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span></span><br><span class="line">                    <span class="string">&quot;data&quot;</span></span><br><span class="line">                <span class="punctuation">]</span></span><br><span class="line">            <span class="punctuation">&#125;</span></span><br><span class="line">        <span class="punctuation">&#125;</span></span><br><span class="line">    <span class="punctuation">&#125;</span></span><br><span class="line"><span class="punctuation">&#125;</span></span><br></pre></td></tr></table></figure><p>该文件配置了job的各个组件的类型，以及组件的输入、输出。</p><p>找到conf配置文件：<code>/data/projects/fate/examples/dsl/v2/homo_logistic_regression/homo_lr_train_conf.json</code>，内容（略作修改）如下：</p><figure class="highlight json"><table><tr><td class="code"><pre><span class="line"><span class="punctuation">&#123;</span></span><br><span class="line">    <span class="attr">&quot;dsl_version&quot;</span><span class="punctuation">:</span> <span class="number">2</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;initiator&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">        <span class="attr">&quot;role&quot;</span><span class="punctuation">:</span> <span class="string">&quot;guest&quot;</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">&quot;party_id&quot;</span><span class="punctuation">:</span> <span class="number">10000</span></span><br><span class="line">    <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;role&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">        <span class="attr">&quot;guest&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span></span><br><span class="line">            <span class="number">10000</span></span><br><span class="line">        <span class="punctuation">]</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">&quot;host&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span></span><br><span class="line">            <span class="number">10000</span></span><br><span class="line">        <span class="punctuation">]</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">&quot;arbiter&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span></span><br><span class="line">            <span class="number">10000</span></span><br><span class="line">        <span class="punctuation">]</span></span><br><span class="line">    <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;component_parameters&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">        <span class="attr">&quot;common&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">            <span class="attr">&quot;data_transform_0&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">                <span class="attr">&quot;with_label&quot;</span><span class="punctuation">:</span> <span class="keyword">true</span><span class="punctuation">,</span></span><br><span class="line">                <span class="attr">&quot;output_format&quot;</span><span class="punctuation">:</span> <span class="string">&quot;dense&quot;</span></span><br><span class="line">            <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">            <span class="attr">&quot;homo_lr_0&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">                <span class="attr">&quot;penalty&quot;</span><span class="punctuation">:</span> <span class="string">&quot;L2&quot;</span><span class="punctuation">,</span></span><br><span class="line">                <span class="attr">&quot;tol&quot;</span><span class="punctuation">:</span> <span class="number">1e-05</span><span class="punctuation">,</span></span><br><span class="line">                <span class="attr">&quot;alpha&quot;</span><span class="punctuation">:</span> <span class="number">0.01</span><span class="punctuation">,</span></span><br><span class="line">                <span class="attr">&quot;optimizer&quot;</span><span class="punctuation">:</span> <span class="string">&quot;sgd&quot;</span><span class="punctuation">,</span></span><br><span class="line">                <span class="attr">&quot;batch_size&quot;</span><span class="punctuation">:</span> <span class="number">-1</span><span class="punctuation">,</span></span><br><span class="line">                <span class="attr">&quot;learning_rate&quot;</span><span class="punctuation">:</span> <span class="number">0.15</span><span class="punctuation">,</span></span><br><span class="line">                <span class="attr">&quot;init_param&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">                    <span class="attr">&quot;init_method&quot;</span><span class="punctuation">:</span> <span class="string">&quot;zeros&quot;</span></span><br><span class="line">                <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">                <span class="attr">&quot;max_iter&quot;</span><span class="punctuation">:</span> <span class="number">30</span><span class="punctuation">,</span></span><br><span class="line">                <span class="attr">&quot;early_stop&quot;</span><span class="punctuation">:</span> <span class="string">&quot;diff&quot;</span><span class="punctuation">,</span></span><br><span class="line">                <span class="attr">&quot;encrypt_param&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">                    <span class="attr">&quot;method&quot;</span><span class="punctuation">:</span> <span class="keyword">null</span></span><br><span class="line">                <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">                <span class="attr">&quot;cv_param&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">                    <span class="attr">&quot;n_splits&quot;</span><span class="punctuation">:</span> <span class="number">4</span><span class="punctuation">,</span></span><br><span class="line">                    <span class="attr">&quot;shuffle&quot;</span><span class="punctuation">:</span> <span class="keyword">true</span><span class="punctuation">,</span></span><br><span class="line">                    <span class="attr">&quot;random_seed&quot;</span><span class="punctuation">:</span> <span class="number">33</span><span class="punctuation">,</span></span><br><span class="line">                    <span class="attr">&quot;need_cv&quot;</span><span class="punctuation">:</span> <span class="keyword">false</span></span><br><span class="line">                <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">                <span class="attr">&quot;decay&quot;</span><span class="punctuation">:</span> <span class="number">1</span><span class="punctuation">,</span></span><br><span class="line">                <span class="attr">&quot;decay_sqrt&quot;</span><span class="punctuation">:</span> <span class="keyword">true</span></span><br><span class="line">            <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">            <span class="attr">&quot;evaluation_0&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">                <span class="attr">&quot;eval_type&quot;</span><span class="punctuation">:</span> <span class="string">&quot;binary&quot;</span></span><br><span class="line">            <span class="punctuation">&#125;</span></span><br><span class="line">        <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">&quot;role&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">            <span class="attr">&quot;host&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">                <span class="attr">&quot;0&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">                    <span class="attr">&quot;reader_0&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">                        <span class="attr">&quot;table&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">                            <span class="attr">&quot;name&quot;</span><span class="punctuation">:</span> <span class="string">&quot;homo_default_credit_guest&quot;</span><span class="punctuation">,</span></span><br><span class="line">                            <span class="attr">&quot;namespace&quot;</span><span class="punctuation">:</span> <span class="string">&quot;homo_default_credit_guest&quot;</span></span><br><span class="line">                        <span class="punctuation">&#125;</span></span><br><span class="line">                    <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">                    <span class="attr">&quot;evaluation_0&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">                        <span class="attr">&quot;need_run&quot;</span><span class="punctuation">:</span> <span class="keyword">false</span></span><br><span class="line">                    <span class="punctuation">&#125;</span></span><br><span class="line">                <span class="punctuation">&#125;</span></span><br><span class="line">            <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">            <span class="attr">&quot;guest&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">                <span class="attr">&quot;0&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">                    <span class="attr">&quot;reader_0&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">                        <span class="attr">&quot;table&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">                            <span class="attr">&quot;name&quot;</span><span class="punctuation">:</span> <span class="string">&quot;homo_default_credit_host&quot;</span><span class="punctuation">,</span></span><br><span class="line">                            <span class="attr">&quot;namespace&quot;</span><span class="punctuation">:</span> <span class="string">&quot;homo_default_credit_host&quot;</span></span><br><span class="line">                        <span class="punctuation">&#125;</span></span><br><span class="line">                    <span class="punctuation">&#125;</span></span><br><span class="line">                <span class="punctuation">&#125;</span></span><br><span class="line">            <span class="punctuation">&#125;</span></span><br><span class="line">        <span class="punctuation">&#125;</span></span><br><span class="line">    <span class="punctuation">&#125;</span></span><br><span class="line"><span class="punctuation">&#125;</span></span><br></pre></td></tr></table></figure><p>该文件配置了联邦学习发起方（initiator）、参与方（role）以及每一方组件的参数（component_parameters）。</p><blockquote><ol><li>initiator段设置了联邦发起者的角色和id</li><li>role段设置了联邦的参与方，和参与方的角色</li><li>job_parameters定义了工作模式（单机/集群）</li><li>component_parameters设置了组件的参数，分为各参与方公共的参数（common），以及各参与方的独特的参数（role）</li></ol></blockquote><h1 id="实验步骤"><a href="#实验步骤" class="headerlink" title="实验步骤"></a>实验步骤</h1><p>进入实验环境；这里使用standalone模拟两方联邦学习，所以所有操作是在同一机器上进行。</p><h2 id="上传训练数据"><a href="#上传训练数据" class="headerlink" title="上传训练数据"></a>上传训练数据</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">(venv) [root@5af726377674 fate]<span class="comment"># flow data upload -c upload_my_homolr_guest.json</span></span><br><span class="line">...</span><br><span class="line">(venv) [root@5af726377674 fate]<span class="comment"># flow data upload -c upload_my_homolr_host.json</span></span><br><span class="line">...</span><br><span class="line"><span class="comment">#guest host分两次上传。</span></span><br></pre></td></tr></table></figure><p>使用flow table 查看上传的表信息：homo_default_credit_host</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">(venv) [root@5af726377674 fate]# flow table info -n homo_default_credit_host -t homo_default_credit_host</span><br><span class="line">&#123;</span><br><span class="line">    &quot;data&quot;: &#123;</span><br><span class="line">        &quot;address&quot;: &#123;</span><br><span class="line">            &quot;connector_name&quot;: null,</span><br><span class="line">            &quot;home&quot;: null,</span><br><span class="line">            &quot;name&quot;: &quot;homo_default_credit_host&quot;,</span><br><span class="line">            &quot;namespace&quot;: &quot;homo_default_credit_host&quot;,</span><br><span class="line">            &quot;storage_type&quot;: &quot;LMDB&quot;</span><br><span class="line">        &#125;,</span><br><span class="line">        &quot;count&quot;: 8000,</span><br><span class="line">        &quot;enable&quot;: true,</span><br><span class="line">        &quot;exist&quot;: 1,</span><br><span class="line">        &quot;namespace&quot;: &quot;homo_default_credit_host&quot;,</span><br><span class="line">        &quot;origin&quot;: &quot;upload&quot;,</span><br><span class="line">        &quot;partition&quot;: 10,</span><br><span class="line">        &quot;schema&quot;: &#123;</span><br><span class="line">            &quot;header&quot;: &quot;y,x0,x1,x2,x3,x4,x5,x6,x7,x8,x9,x10,x11,x12,x13,x14,x15,x16,x17,x18,x19,x20,x21,x22&quot;,</span><br><span class="line">            &quot;sid&quot;: &quot;id&quot;</span><br><span class="line">        &#125;,</span><br><span class="line">        &quot;table_name&quot;: &quot;homo_default_credit_host&quot;</span><br><span class="line">    &#125;,</span><br><span class="line">    &quot;retcode&quot;: 0,</span><br><span class="line">    &quot;retmsg&quot;: &quot;success&quot;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure><h2 id="提交训练任务"><a href="#提交训练任务" class="headerlink" title="提交训练任务"></a>提交训练任务</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">(venv) [root@5af726377674 fate]<span class="comment"># flow job submit -d test_my_homolr_train_dsl.json -c test_my_homolr_train_conf.json </span></span><br><span class="line">&#123;</span><br><span class="line">    <span class="string">&quot;data&quot;</span>: &#123;</span><br><span class="line">        <span class="string">&quot;board_url&quot;</span>: <span class="string">&quot;http://127.0.0.1:8080/index.html#/dashboard?job_id=202209200821441165650&amp;role=guest&amp;party_id=10000&quot;</span>,</span><br><span class="line">        <span class="string">&quot;code&quot;</span>: 0,</span><br><span class="line">        <span class="string">&quot;dsl_path&quot;</span>: <span class="string">&quot;/data/projects/fate/fateflow/jobs/202209200821441165650/job_dsl.json&quot;</span>,</span><br><span class="line">        <span class="string">&quot;job_id&quot;</span>: <span class="string">&quot;202209200821441165650&quot;</span>,</span><br><span class="line">        <span class="string">&quot;logs_directory&quot;</span>: <span class="string">&quot;/data/projects/fate/fateflow/logs/202209200821441165650&quot;</span>,</span><br><span class="line">        <span class="string">&quot;message&quot;</span>: <span class="string">&quot;success&quot;</span>,</span><br><span class="line">        <span class="string">&quot;model_info&quot;</span>: &#123;</span><br><span class="line">            <span class="string">&quot;model_id&quot;</span>: <span class="string">&quot;arbiter-10000#guest-10000#host-10000#model&quot;</span>,</span><br><span class="line">            <span class="string">&quot;model_version&quot;</span>: <span class="string">&quot;202209200821441165650&quot;</span></span><br><span class="line">        &#125;,</span><br><span class="line">        <span class="string">&quot;pipeline_dsl_path&quot;</span>: <span class="string">&quot;/data/projects/fate/fateflow/jobs/202209200821441165650/pipeline_dsl.json&quot;</span>,</span><br><span class="line">        <span class="string">&quot;runtime_conf_on_party_path&quot;</span>: <span class="string">&quot;/data/projects/fate/fateflow/jobs/202209200821441165650/guest/10000/job_runtime_on_party_conf.json&quot;</span>,</span><br><span class="line">        <span class="string">&quot;runtime_conf_path&quot;</span>: <span class="string">&quot;/data/projects/fate/fateflow/jobs/202209200821441165650/job_runtime_conf.json&quot;</span>,</span><br><span class="line">        <span class="string">&quot;train_runtime_conf_path&quot;</span>: <span class="string">&quot;/data/projects/fate/fateflow/jobs/202209200821441165650/train_runtime_conf.json&quot;</span></span><br><span class="line">    &#125;,</span><br><span class="line">    <span class="string">&quot;jobId&quot;</span>: <span class="string">&quot;202209200821441165650&quot;</span>,</span><br><span class="line">    <span class="string">&quot;retcode&quot;</span>: 0,</span><br><span class="line">    <span class="string">&quot;retmsg&quot;</span>: <span class="string">&quot;success&quot;</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure><h2 id="查看状态"><a href="#查看状态" class="headerlink" title="查看状态"></a>查看状态</h2><p>在fate-board上查看训练状态：<code>http://ip:8086</code></p><p><img src="image-20220920170949-v81vtm8.png" alt="image.png"></p><p>选择<code>guest</code>的那条记录，进入详情页。点击<code>evaluation</code>，选择<code>view the outputs</code>，查看模型效果。</p><p><img src="image-20220920203955-qua2axz.png" alt="image.png"></p><p><img src="image-20220920204118-0eu2i1y.png" alt="image.png"></p><p>loss在<code>homo_lr_0</code>的outputs</p><p>‍</p><h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><ol><li>使用DSL进行FATE横向联邦学习的流程包括：各方上传数据；编写DSL和CONF文件配置组件、参与方信息等；提交job。</li><li>为了方便测试，这里使用的standalone单机版本，所以所有操作都在同一台机器上。实际在集群上可能会有所不同，例如需要在多方机器上上传不同的数据。</li><li>FATE的组件列表、组件输入的格式、组件的参数配置可以查看官方文档：<a href="https://fate.readthedocs.io/en/latest/federatedml_component/">https://fate.readthedocs.io/en/latest/federatedml_component/</a></li><li>FATE关于DSL和CONF文件的配置说明可以参考：<a href="https://github.com/FederatedAI/FATE/blob/master/doc/tutorial/dsl_conf/dsl_conf_v2_setting_guide.zh.md">https://github.com/FederatedAI/FATE/blob/master/doc/tutorial/dsl_conf/dsl_conf_v2_setting_guide.zh.md</a></li><li>flow命令指南：<a href="https://federatedai.github.io/FATE-Flow/latest/zh/document_navigation/">https://federatedai.github.io/FATE-Flow/latest/zh/document_navigation/</a></li><li>flow api文档：<a href="https://federatedai.github.io/FATE-Flow/latest/zh/swagger/">https://federatedai.github.io/FATE-Flow/latest/zh/swagger/</a></li></ol><h1 id="Refs"><a href="#Refs" class="headerlink" title="Refs"></a>Refs</h1><ol><li><a href="https://www.freesion.com/article/2169210597/#1_3">联邦学习框架FATE使用案例记录</a></li><li><a href="https://blog.csdn.net/WenDong1997/article/details/106743620">联邦学习框架FATE实践（训练/测试步骤及参数说明</a></li></ol><p>‍</p>]]></content>
    
    
      
      
    <summary type="html">&lt;blockquote&gt;
&lt;p&gt;通过FATE平台提交联邦学习job，有两种方式：DSL和pipline；&lt;/p&gt;
&lt;p&gt;DSL是通过写配置文件的方式，配置联邦学习job的各个参数；pipeline是通过写python代码的方式配置和提交job&lt;/p&gt;
&lt;p&gt;本文使用Fate的信用</summary>
      
    
    
    
    <category term="联邦学习" scheme="https://guoyujian.github.io/categories/%E8%81%94%E9%82%A6%E5%AD%A6%E4%B9%A0/"/>
    
    
    <category term="联邦学习" scheme="https://guoyujian.github.io/tags/%E8%81%94%E9%82%A6%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>FATE联邦学习框架简介</title>
    <link href="https://guoyujian.github.io/2022/11/03/FATE%E8%81%94%E9%82%A6%E5%AD%A6%E4%B9%A0%E6%A1%86%E6%9E%B6%E7%AE%80%E4%BB%8B/"/>
    <id>https://guoyujian.github.io/2022/11/03/FATE%E8%81%94%E9%82%A6%E5%AD%A6%E4%B9%A0%E6%A1%86%E6%9E%B6%E7%AE%80%E4%BB%8B/</id>
    <published>2022-11-03T15:57:19.000Z</published>
    <updated>2022-11-03T16:00:29.302Z</updated>
    
    <content type="html"><![CDATA[<h1 id="联邦学习介绍"><a href="#联邦学习介绍" class="headerlink" title="联邦学习介绍"></a>联邦学习介绍</h1><h2 id="联邦学习的出现解决什么问题"><a href="#联邦学习的出现解决什么问题" class="headerlink" title="联邦学习的出现解决什么问题"></a>联邦学习的出现解决什么问题</h2><p>解决“数据孤岛”问题，保证数据安全与隐私保护。</p><p>由于各种原因，数据孤岛问题普遍存在。在用户和企业角度下，商业公司所拥有的数据往往都有巨大的潜在价值。两个公司甚至公司间的部门都要考虑利益的交换，往往这些机构不会提供各自数据与其他公司做与单的聚合，导致即使在同一个公司内，数据也往往以孤岛形式出现。</p><h2 id="联邦学习的概念"><a href="#联邦学习的概念" class="headerlink" title="联邦学习的概念"></a>联邦学习的概念</h2><p>本质：联邦学习本质上是一种<strong>分布式</strong>机器学习技术，或机器学习<strong>框架</strong>。</p><p>目标：联邦学习的目标是在保证数据隐私安全及合法合规的基础上，实现共同建模，提升AI模型的效果。</p><h2 id="联邦学习的分类"><a href="#联邦学习的分类" class="headerlink" title="联邦学习的分类"></a>联邦学习的分类</h2><p>根据每个参与共同建模的企业称为参与方，根据多参与方之间数据分布的不同，把联邦学习分为三类：横向联邦学习、纵向联邦学习和联邦迁移学习。</p><p><img src="image-20221016171301-jpflppr.png" alt="image.png"></p><ul><li>横向联邦适用于，参与方之间的数据特征相似，但样本不同。</li><li>纵向联邦适用于，参与方之间的数据特征重叠多，但样本重叠少。</li><li>联邦迁移学习则适用于，参与方之间的数据特征重叠少，样本重叠也少。</li></ul><p>这三种类型的联邦学习的学习过程不太相同，这里不做详细描述。</p><h2 id="联邦学习框架"><a href="#联邦学习框架" class="headerlink" title="联邦学习框架"></a>联邦学习框架</h2><p>据了解，联邦学习框架有Fate、PySyft、FedLab、Rosetta、PaddleFL等等。具体可参见<a href="https://zhuanlan.zhihu.com/p/387101962">联邦学习开源框架调研</a></p><p>不同框架的受众定位、加密手段、支持的算法、开发的机构不同。下面是对比图。图片来源于Fate官网。</p><p>这张图时间比较久了，具体还是要看最新版本。</p><p><img src="image-20220907160332-fp0kf9k.png" alt="image.png"></p><p>‍</p><h1 id="Fate介绍"><a href="#Fate介绍" class="headerlink" title="Fate介绍"></a>Fate介绍</h1><p>FATE (Federated AI Technology Enabler) 是微众银行AI部门发起的开源项目，为联邦学习生态系统提供了可靠的安全计算框架。FATE项目使用多方安全计算 (MPC) 以及同态加密 (HE) 技术构建底层安全计算协议，以此支持不同种类的机器学习的安全计算，包括逻辑回归、基于树的算法、深度学习和迁移学习等。</p><h2 id="Fate架构"><a href="#Fate架构" class="headerlink" title="Fate架构"></a>Fate架构</h2><p><img src="image-20220907151347-1sl8y67.png" alt="image.png"></p><p>其中，</p><ul><li>FATE Board：联邦学习可视化界面。</li><li>FATE Flow：联邦学习端到端全流程的多方联合任务安全调度平台，提供生产级的服务能力。</li><li>FATE Serving：在线模型管理服务（只支持纵向联邦学习）</li><li>FederatedML：联邦学习的核心组件</li><li>Secure Protocols：FATE的安全协议</li></ul><h2 id="FATE核心功能"><a href="#FATE核心功能" class="headerlink" title="FATE核心功能"></a>FATE核心功能</h2><ul><li>联邦在线模型服务（FATE Serving）</li><li>联邦建模Pipline和可视化（FATE Flow）</li><li>联邦学习算法的各个功能组件（FederatedML）</li><li>分布式计算和存储抽象（EggRoll）</li><li>跨站点网络通信抽象（Federated Network）</li></ul><h2 id="更多介绍"><a href="#更多介绍" class="headerlink" title="更多介绍"></a>更多介绍</h2><p>FATE github地址：<a href="https://github.com/FederatedAI/FATE">https://github.com/FederatedAI/FATE</a></p><h2 id="单机版FATE安装"><a href="#单机版FATE安装" class="headerlink" title="单机版FATE安装"></a>单机版FATE安装</h2><p>这里采用docker安装</p><p><a href="https://github.com/FederatedAI/FATE/blob/master/deploy/standalone-deploy/README.zh.md">部署文档</a></p><p>如果需要docker使用GPU资源，需要在docker容器启动时加上参数<code>--gpus</code></p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">docker run -d --gpus all --name standalone_fate -p 8080:8080 federatedai/standalone_fate:1.9.0</span><br></pre></td></tr></table></figure><p>如果启动报类似错误：<code>Error could not select device driver with capabilities: [[gpu]]</code>，则查看下面的链接进行解决。</p><p><a href="https://developer.aliyun.com/article/767168">Centos7安装nvidia-container-toolkit</a></p><p>安装完成后，进入容器，要先执行命令：<code>source bin/init_env.sh</code></p><p>FATE Board 默认用户名密码：admin/admin</p><p>想要修改用户名和密码</p><p><code>/data/projects/fate/fateboard/conf/application.properties</code></p><h2 id="集群版"><a href="#集群版" class="headerlink" title="集群版"></a>集群版</h2><p>集群可以使用docker-compose或者kube安装，这里不做介绍。</p><p>集群版会加入eggroll、mysql之类的组件，其开放的端口如下：</p><p><img src="C:/Users/11599/Desktop/FATE联邦学习框架/FATE联邦学习框架/assets/image-20220923161817-1viqwi3.png" alt="image.png"></p><p>9380端口是FATE flow调用api的接口，有哪些接口可以参看下面的链接。</p><p><a href="https://federatedai.github.io/FATE-Flow/latest/zh/swagger/">https://federatedai.github.io/FATE-Flow/latest/zh/swagger/</a></p><p>集群安装后，每个节点应该有以下docker容器</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">fate@vm172-31-0-217:~$ docker ps </span><br><span class="line">CONTAINER ID   IMAGE                                   COMMAND                  CREATED       STATUS                PORTS                                            NAMES</span><br><span class="line">f2ab95400e3f   federatedai/client:1.9.0-release        <span class="string">&quot;/bin/sh -c &#x27;flow in…&quot;</span>   2 weeks ago   Up 7 days             0.0.0.0:20000-&gt;20000/tcp                         confs-10000-client-1</span><br><span class="line">f24fac183cbe   federatedai/fateboard:1.9.0-release     <span class="string">&quot;/bin/sh -c &#x27;java -D…&quot;</span>   2 weeks ago   Up 7 days             0.0.0.0:6080-&gt;6080/tcp, 8080/tcp                 confs-10000-fateboard-1</span><br><span class="line">33ca56f46fe3   federatedai/fateflow-nn:1.9.0-release   <span class="string">&quot;/bin/bash -c &#x27;set -…&quot;</span>   2 weeks ago   Up 7 days (healthy)   0.0.0.0:9360-&gt;9360/tcp, 0.0.0.0:9380-&gt;9380/tcp   confs-10000-fateflow-1</span><br><span class="line">4dbb83db37cc   mysql:8.0.28                            <span class="string">&quot;docker-entrypoint.s…&quot;</span>   2 weeks ago   Up 7 days             3306/tcp, 33060/tcp                              confs-10000-mysql-1</span><br><span class="line">7e4567d52d9d   federatedai/eggroll-nn:1.9.0-release    <span class="string">&quot;/tini -- bash -c &#x27;j…&quot;</span>   2 weeks ago   Up 7 days             0.0.0.0:9370-&gt;9370/tcp                           confs-10000-rollsite-1</span><br><span class="line">10f118347296   federatedai/eggroll-nn:1.9.0-release    <span class="string">&quot;/tini -- bash -c &#x27;j…&quot;</span>   2 weeks ago   Up 7 days             4670/tcp                                         confs-10000-clustermanager-1</span><br><span class="line">7ceafb32bfd9   federatedai/eggroll-nn:1.9.0-release    <span class="string">&quot;/tini -- bash -c &#x27;j…&quot;</span>   2 weeks ago   Up 7 days             4671/tcp   </span><br></pre></td></tr></table></figure><p>集群开放的端口：</p><div class="table-container"><table><thead><tr><th>port</th><th>service</th></tr></thead><tbody><tr><td>6080</td><td>fate-board</td></tr><tr><td>8350</td><td>serving</td></tr><tr><td>20000</td><td>jupyter</td></tr><tr><td>9370</td><td>rollsite</td></tr><tr><td>9380</td><td>flow api</td></tr></tbody></table></div><p>这里我们使用了四个节点，分别是FATE9997-10000，其中FATE10000为arbiter用于将梯度聚合和分发，其余为guest/host，是参与联邦学习的各方。</p><h2 id="Toy-Test"><a href="#Toy-Test" class="headerlink" title="Toy Test"></a>Toy Test</h2><p>安装完成后可以进行简单测试，以检查安装是否成功。10000是各个参与方的partyid</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">flow test toy -gid 10000 -hid 10000</span><br></pre></td></tr></table></figure><h1 id="Refs"><a href="#Refs" class="headerlink" title="Refs"></a>Refs</h1><ol><li><a href="https://zhuanlan.zhihu.com/p/79284686">详解联邦学习Federated Learning</a></li></ol><p>‍</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;联邦学习介绍&quot;&gt;&lt;a href=&quot;#联邦学习介绍&quot; class=&quot;headerlink&quot; title=&quot;联邦学习介绍&quot;&gt;&lt;/a&gt;联邦学习介绍&lt;/h1&gt;&lt;h2 id=&quot;联邦学习的出现解决什么问题&quot;&gt;&lt;a href=&quot;#联邦学习的出现解决什么问题&quot; class=&quot;he</summary>
      
    
    
    
    <category term="联邦学习" scheme="https://guoyujian.github.io/categories/%E8%81%94%E9%82%A6%E5%AD%A6%E4%B9%A0/"/>
    
    
    <category term="联邦学习" scheme="https://guoyujian.github.io/tags/%E8%81%94%E9%82%A6%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>FATE联邦学习框架（共八篇）</title>
    <link href="https://guoyujian.github.io/2022/11/03/FATE%E8%81%94%E9%82%A6%E5%AD%A6%E4%B9%A0%E6%A1%86%E6%9E%B6%EF%BC%88%E5%85%B1%E5%85%AB%E7%AF%87%EF%BC%89/"/>
    <id>https://guoyujian.github.io/2022/11/03/FATE%E8%81%94%E9%82%A6%E5%AD%A6%E4%B9%A0%E6%A1%86%E6%9E%B6%EF%BC%88%E5%85%B1%E5%85%AB%E7%AF%87%EF%BC%89/</id>
    <published>2022-11-03T15:55:20.000Z</published>
    <updated>2022-11-07T13:48:50.085Z</updated>
    
    <content type="html"><![CDATA[<h1 id="目录"><a href="#目录" class="headerlink" title="目录"></a>目录</h1><ol><li>FATE联邦学习框架简介：联邦学习+fate介绍+单机版docker安装+toy test</li><li>FATE横向联邦学习：信用数据案例</li><li>FATE DSL配置文件详细解释</li><li>FATE横向联邦学习：手写数字识别（开发组件：自定义的模型、使用gpu、模型评估？）</li><li>FATE横向联邦学习：肠癌图像分类任务（上）——baseline</li><li>FATE横向联邦学习：肠癌图像分类任务（下）——联邦化</li><li>FATE横向联邦学习：肺炎的多模态任务的联邦学习</li><li>FATE使用遇到的问题汇总</li></ol><h1 id="仓库"><a href="#仓库" class="headerlink" title="仓库"></a>仓库</h1><p><a href="https://github.com/guoyujian/FATE">https://github.com/guoyujian/FATE</a></p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;目录&quot;&gt;&lt;a href=&quot;#目录&quot; class=&quot;headerlink&quot; title=&quot;目录&quot;&gt;&lt;/a&gt;目录&lt;/h1&gt;&lt;ol&gt;
&lt;li&gt;FATE联邦学习框架简介：联邦学习+fate介绍+单机版docker安装+toy test&lt;/li&gt;
&lt;li&gt;FATE横向联邦学</summary>
      
    
    
    
    <category term="联邦学习" scheme="https://guoyujian.github.io/categories/%E8%81%94%E9%82%A6%E5%AD%A6%E4%B9%A0/"/>
    
    
    <category term="联邦学习" scheme="https://guoyujian.github.io/tags/%E8%81%94%E9%82%A6%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>HTTP缓存</title>
    <link href="https://guoyujian.github.io/2022/09/24/HTTP%E7%BC%93%E5%AD%98/"/>
    <id>https://guoyujian.github.io/2022/09/24/HTTP%E7%BC%93%E5%AD%98/</id>
    <published>2022-09-23T16:26:34.000Z</published>
    <updated>2022-09-23T16:32:47.718Z</updated>
    
    <content type="html"><![CDATA[<h1 id="前端缓存知识点"><a href="#前端缓存知识点" class="headerlink" title="前端缓存知识点"></a>前端缓存知识点</h1><p><img src="前端缓存一览.png" alt="前端缓存一览">​</p><h1 id="什么是HTTP缓存"><a href="#什么是HTTP缓存" class="headerlink" title="什么是HTTP缓存"></a>什么是HTTP缓存</h1><p>http缓存指的是: 当客户端向服务器请求资源时，会先抵达浏览器缓存，如果浏览器有“要请求资源”的副本，就可以直接从浏览器缓存中提取而不是从原始服务器中提取这个资源。</p><p>常见的http缓存只能缓存get请求响应的资源，对于其他类型的响应则无能为力，所以后续说的请求缓存都是指GET请求。</p><p>http缓存都是从第二次请求开始的。第一次请求资源时，服务器返回资源，并在respone header头中回传资源的缓存参数；第二次请求时，浏览器判断这些请求参数，命中强缓存就直接200，否则就把请求参数加到request header头中传给服务器，看是否命中协商缓存，命中则返回304，否则服务器会返回新的资源。</p><h1 id="为什么要使用HTTP缓存-？"><a href="#为什么要使用HTTP缓存-？" class="headerlink" title="为什么要使用HTTP缓存 ？"></a>为什么要使用HTTP缓存 ？</h1><ol><li>减少了冗余的数据传输，节省了网费。</li><li>缓解了服务器的压力， 大大提高了网站的性能</li><li>加快了客户端加载网页的速度</li></ol><h1 id="如何使用HTTP缓存-？"><a href="#如何使用HTTP缓存-？" class="headerlink" title="如何使用HTTP缓存 ？"></a>如何使用HTTP缓存 ？</h1><p>一般需要缓存的资源有html页面和其他静态资源：</p><blockquote><p>1、 <strong>html页面缓存的设置主要是在<code>&lt;head&gt;</code>标签中嵌入<code>&lt;meta&gt;</code>标签，这种方式只对页面有效，对页面上的资源无效</strong></p></blockquote><p>1.1 html页面禁用缓存的设置如下：</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&lt;meta http-equiv=&quot;cache-control&quot; content=&quot;no-cache&quot; \&gt;</span><br></pre></td></tr></table></figure><p>1.2 html设置缓存如下：</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&lt;meta http-equiv=&quot;Cache-Control&quot; content=&quot;max-age=7200&quot; /&gt;</span><br></pre></td></tr></table></figure><blockquote><p>2、 <strong>静态资源的缓存一般是在web服务器上配置的，常用的web服务器有：nginx、apache。具体的配置这里不做详细介绍，大家自行查阅。</strong></p><p><strong>3、不想使用缓存的几种方式</strong></p></blockquote><ul><li>Ctrl + F5强制刷新，都会直接向服务器提取数据。</li><li>按F5刷新或浏览器的刷新按钮，默认加上Cache-Control：max-age=0，即会走协商缓存。</li><li>还有就是上面1、2中禁用缓存的做法</li></ul><h1 id="HTTP缓存的几个注意点"><a href="#HTTP缓存的几个注意点" class="headerlink" title="HTTP缓存的几个注意点"></a>HTTP缓存的几个注意点</h1><p>1、强缓存情况下，只要缓存还没过期，就会直接从缓存中取数据，就算服务器端有数据变化，也不会从服务器端获取了，这样就无法获取到修改后的数据。解决的办法有：在修改后的资源加上随机数，确保不会从缓存中取。</p><p>例如：<code>http://www.kimshare.club/kim/common.css?v=22324432</code></p><p>2、尽量减少304的请求，因为我们知道，协商缓存每次都会与后台服务器进行交互，所以性能上不是很好。从性能上来看尽量多使用强缓存。</p><p>3、与缓存相关的几个header属性有：Vary、Date/Age。</p><h1 id="HTTP缓存的分类"><a href="#HTTP缓存的分类" class="headerlink" title="HTTP缓存的分类"></a><strong>HTTP缓存的分类</strong></h1><ul><li>根据是否需要重新向服务器发起请求来分类，可分为强制缓存，协商缓存</li><li>根据是否可以被单个或者多个用户使用来分类，可分为私有缓存，共享缓存（不care）</li></ul><p>强制缓存如果生效，不需要再和服务器发生交互，而协商缓存不管是否生效，都需要与服务端发生交互。下面是强制缓存和协商缓存的一些对比：</p><p><img src="HTTP缓存分类.png" alt="HTTP缓存分类"></p><h2 id="强缓存"><a href="#强缓存" class="headerlink" title="强缓存"></a>强缓存</h2><p>强制缓存在缓存数据未失效的情况下（即Cache-Control的max-age没有过期或者Expires的缓存时间没有过期），那么就会直接使用浏览器的缓存数据，不会再向服务器发送任何请求。</p><p>强制缓存生效时，http状态码为200。这种方式页面的加载速度是最快的，性能也是很好的，但是在这期间，如果服务器端的资源修改了，页面上是拿不到的，因为它不会再向服务器发请求了。</p><p>这种情况就是我们在开发种经常遇到的，比如你修改了页面上的某个样式，在页面上刷新了但没有生效，因为走的是强缓存，所以Ctrl + F5一顿操作之后就好了。 </p><p>跟强制缓存相关的header头属性有（Pragma/Cache-Control/Expires）</p><h2 id="协商缓存"><a href="#协商缓存" class="headerlink" title="协商缓存"></a>协商缓存</h2><p>当第一次请求时服务器返回的响应头中没有Cache-Control和Expires或者Cache-Control和Expires过期还或者它的属性设置为no-cache时(即不走强缓存)，那么浏览器第二次请求时就会与服务器进行协商，与服务器端对比判断资源是否进行了修改更新。</p><p>如果服务器端的资源没有修改，那么就会返回304状态码，告诉浏览器可以使用缓存中的数据，这样就减少了服务器的数据传输压力。</p><p>如果数据有更新就会返回200状态码，服务器就会返回更新后的资源并且将缓存信息一起返回。</p><p>跟协商缓存相关的header头属性有（ETag/If-Not-Match 、Last-Modified/If-Modified-Since）请求头和响应头需要成对出现。</p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p><strong>下图是浏览器首次和再次发送http请求的执行流程图：</strong></p><p><img src="首次HTTP请求.png" alt="首次HTTP请求"></p><p><img src="再次HTTP请求.png" alt="再次HTTP请求"></p><h1 id="Refs"><a href="#Refs" class="headerlink" title="Refs"></a>Refs</h1><ol><li><a href="https://www.jianshu.com/p/227cee9c8d15">https://www.jianshu.com/p/227cee9c8d15</a></li></ol>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;前端缓存知识点&quot;&gt;&lt;a href=&quot;#前端缓存知识点&quot; class=&quot;headerlink&quot; title=&quot;前端缓存知识点&quot;&gt;&lt;/a&gt;前端缓存知识点&lt;/h1&gt;&lt;p&gt;&lt;img src=&quot;前端缓存一览.png&quot; alt=&quot;前端缓存一览&quot;&gt;​&lt;/p&gt;
&lt;h1 id=&quot;什</summary>
      
    
    
    
    <category term="计算机网络" scheme="https://guoyujian.github.io/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/"/>
    
    <category term="HTTP协议" scheme="https://guoyujian.github.io/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/HTTP%E5%8D%8F%E8%AE%AE/"/>
    
    
    <category term="计算机网络" scheme="https://guoyujian.github.io/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/"/>
    
    <category term="HTTP协议" scheme="https://guoyujian.github.io/tags/HTTP%E5%8D%8F%E8%AE%AE/"/>
    
  </entry>
  
  <entry>
    <title>HTTPS协议</title>
    <link href="https://guoyujian.github.io/2022/09/24/HTTPS%E5%8D%8F%E8%AE%AE/"/>
    <id>https://guoyujian.github.io/2022/09/24/HTTPS%E5%8D%8F%E8%AE%AE/</id>
    <published>2022-09-23T16:22:25.000Z</published>
    <updated>2022-09-23T16:25:50.622Z</updated>
    
    <content type="html"><![CDATA[<h1 id="前置知识"><a href="#前置知识" class="headerlink" title="前置知识"></a>前置知识</h1><p>加密分为对称加密和非对称加密，HTTPS兼顾两者。</p><p>关于非对称加密，可以查阅相关资料。这里只提一点：</p><blockquote><p><strong>公钥加密，私钥解密！</strong></p></blockquote><h1 id="为什么需要HTTPS"><a href="#为什么需要HTTPS" class="headerlink" title="为什么需要HTTPS"></a>为什么需要HTTPS</h1><p>HTTP 主要有这些不足：</p><ul><li>通信使用明文（不加密），内容可能会被窃听；</li><li>不验证通信方的身份，因此有可能遭遇伪装；</li><li>无法证明报文的完整性，所以有可能已遭篡改；</li></ul><p>为了解决这些问题，HTTPS顺应而生。</p><h1 id="HTTPS介绍"><a href="#HTTPS介绍" class="headerlink" title="HTTPS介绍"></a>HTTPS介绍</h1><p><strong>HTTP+ 加密 + 认证 + 完整性保护=HTTPS</strong>。</p><p>可以这么理解，HTTPS是安全版的HTTP，它不是一个新的协议，而是HTTP 加上加密处理（解决HTTP通信使用明文的问题）和认证（解决HTTP不验证通信方的身份问题）以及完整性保护（解决HTTP无法证明报文完整性的问题）后的东西。</p><p><strong>端口：443</strong></p><p><img src="HTTP和HTTPS对比.png" alt="HTTP和HTTPS对比"></p><p>注：上图并不代表顺序。也就是说<strong>HTTPS是先建立TCP连接，再进行TLS/SSL握手。</strong></p><h1 id="HTTPS通信"><a href="#HTTPS通信" class="headerlink" title="HTTPS通信"></a>HTTPS通信</h1><p>直接上图</p><p><img src="HTTPS通信.png" alt="HTTPS通信">​</p><p>上图基本把HTTPS的通信流程说的非常清晰了，补充两点：</p><ol><li>这里对比HASH是为了防止握手消息被篡改。浏览器与网站互相发送加密的握手消息并验证，目的是为了保证双方都获得了一致的密码，并且可以正常的加密解密数据，为后续真正数据的传输做一次测试。</li><li>因为对称加密要比非对称加密的计算快很多，所以HTTPS没有全程使用非对称加密，而是先使用非对称加密交换对称密钥，再使用对称加密手段通信。</li><li>证书确保了双方身份。</li></ol><p>另外，HTTPS一般使用的加密与HASH算法如下：</p><ul><li>非对称加密算法：RSA，DSA/DSS</li><li>对称加密算法：AES，RC4，3DES</li><li>HASH算法：MD5，SHA1，SHA256</li></ul><h1 id="HTTPS-的优缺点"><a href="#HTTPS-的优缺点" class="headerlink" title="HTTPS 的优缺点?"></a>HTTPS 的优缺点?</h1><p>优点</p><ul><li><p>安全性：</p><ul><li>使用HTTPS协议可认证用户和服务器，确保数据发送到正确的客户机和服务器；</li><li>HTTPS协议是由SSL+HTTP协议构建的可进行加密传输、身份认证的网络协议，要比http协议安全，可防止数据在传输过程中不被窃取、改变，确保数据的完整性。</li><li>HTTPS是现行架构下最安全的解决方案，虽然不是绝对安全，但它大幅增加了中间人攻击的成本。</li></ul></li><li>SEO方面：谷歌曾在2014年8月份调整搜索引擎算法，并称“比起同等HTTP网站，采用HTTPS加密的网站在搜索结果中的排名将会更高”。</li></ul><p>缺点</p><ul><li>在相同网络环境中，HTTPS 相比 HTTP 无论是响应时间还是耗电量都有大幅度上升。</li><li>HTTPS 的安全是有范围的，在黑客攻击、服务器劫持等情况下几乎起不到作用。</li><li>在现有的证书机制下，中间人攻击依然有可能发生。</li><li>HTTPS 需要更多的服务器资源，也会导致成本的升高。</li></ul><h1 id="Refs"><a href="#Refs" class="headerlink" title="Refs"></a>Refs</h1><ol><li><a href="https://www.ruanyifeng.com/blog/2014/02/ssl_tls.html">SSL/TLS协议运行机制的概述</a></li><li><a href="https://www.cnblogs.com/zery/p/5164795.html">HTTPS 原理解析</a></li><li><a href="https://cloud.tencent.com/developer/article/1007810?from=article.detail.1017988">HTTPS 建立连接的详细过程</a></li><li><a href="https://juejin.cn/post/6906126429381984264">HTTPS连接过程</a></li><li><a href="https://zhuanlan.zhihu.com/p/45390160">HTTPS详细介绍</a></li></ol>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;前置知识&quot;&gt;&lt;a href=&quot;#前置知识&quot; class=&quot;headerlink&quot; title=&quot;前置知识&quot;&gt;&lt;/a&gt;前置知识&lt;/h1&gt;&lt;p&gt;加密分为对称加密和非对称加密，HTTPS兼顾两者。&lt;/p&gt;
&lt;p&gt;关于非对称加密，可以查阅相关资料。这里只提一点：&lt;/p&gt;
</summary>
      
    
    
    
    <category term="计算机网络" scheme="https://guoyujian.github.io/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/"/>
    
    <category term="HTTP协议" scheme="https://guoyujian.github.io/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/HTTP%E5%8D%8F%E8%AE%AE/"/>
    
    
    <category term="计算机网络" scheme="https://guoyujian.github.io/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/"/>
    
    <category term="HTTP协议" scheme="https://guoyujian.github.io/tags/HTTP%E5%8D%8F%E8%AE%AE/"/>
    
  </entry>
  
  <entry>
    <title>HTTP面试题</title>
    <link href="https://guoyujian.github.io/2022/09/24/HTTP%E9%9D%A2%E8%AF%95%E9%A2%98/"/>
    <id>https://guoyujian.github.io/2022/09/24/HTTP%E9%9D%A2%E8%AF%95%E9%A2%98/</id>
    <published>2022-09-23T16:07:45.000Z</published>
    <updated>2022-09-23T16:21:17.281Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>作为复习，也作为一个目录</p></blockquote><h1 id="说一下HTTP协议"><a href="#说一下HTTP协议" class="headerlink" title="说一下HTTP协议"></a>说一下HTTP协议</h1><p>HTTP全称是Hyper Text Transfer Protocol。即<strong>超文本传输协议</strong>，它是以<strong>TCP/IP</strong>为基础来传输HTML，文件，图片等。 它本身处于<strong>应用层</strong>，<strong>端口号80</strong>。</p><ol><li>HTTP是基于<strong>浏览器/服务器</strong>架构；</li><li>HTTP是<strong>无状态</strong>协议：HTTP本身并不保存用户的任何信息，也不会对传输的数据，状态信息进行持久化；</li><li>HTTP是<strong>无连接</strong>协议：每次连接只处理一个请求，服务器处理完用户请求，即断开连接，借此节约传输时间。</li></ol><h1 id="HTTP通信过程"><a href="#HTTP通信过程" class="headerlink" title="HTTP通信过程"></a>HTTP通信过程</h1><ol><li>用户输入网址</li><li>DNS服务器解析域名</li><li>浏览器和服务器建立TCP连接</li><li>浏览器向服务器发送请求行</li><li>浏览器向服务器发送请求头，并以空行代表发送结束，如果请求类型为<code>post</code>，则继续发送请求体</li><li>服务器应答协议版本号和应答状态码</li><li>服务器发送响应头，并以空行代表发送结束</li><li>服务器发送数据：以<code>Content-Type</code>给出的格式发送用户所请求的信息</li><li>服务器关闭TCP连接：如果浏览器或者服务器的头信息中加入了这样一段代码：<code>connection：Keep-alive</code> 则TCP连接会保持打开状态</li><li>客户端浏览器解析HTML内容</li></ol><p>下图整理了HTTP通信的关键步骤：</p><p><img src="http通信过程.png" alt="计算机网络-http通信过程">​</p><h1 id="说一下HTTPS协议"><a href="#说一下HTTPS协议" class="headerlink" title="说一下HTTPS协议"></a>说一下HTTPS协议</h1><p>可以看我的博客：《HTTPS协议》</p><h1 id="HTTP与HTTPS的对比"><a href="#HTTP与HTTPS的对比" class="headerlink" title="HTTP与HTTPS的对比"></a>HTTP与HTTPS的对比</h1><ul><li>两者工作的端口号不同：HTTP工作在80，HTTPS工作在443；</li><li>HTTPS需要用到CA（数字证书认证机构）申请证书，一般需要一定费用；</li><li>HTTP响应比HTTPS快，主要因为HTTPS除了TCP3次握手外还要加上<strong>SSL9次握手</strong>共12次握手；</li><li>HTTPS是构建在SSL/TLS上的HTTP协议，因此需要占用服务器资源。</li></ul><h1 id="HTTP缓存​"><a href="#HTTP缓存​" class="headerlink" title="HTTP缓存​"></a>HTTP缓存​</h1><p>http缓存指的是: 当客户端向服务器请求资源时，会先抵达<strong>浏览器缓存</strong>，如果浏览器有“要请求资源”的副本，就可以<strong>直接从浏览器缓存中提取</strong>而不是从原始服务器中提取这个资源。</p><p>常见的http缓存<strong>只能缓存get请求</strong>响应的资源，对于其他类型的响应则无能为力，所以后续说的请求缓存都是指GET请求。<br>http缓存都是从第二次请求开始的。第一次请求资源时，服务器返回资源，并在respone header头中回传资源的缓存参数；第二次请求时，浏览器判断这些请求参数，命中强缓存就直接200，否则就把请求参数加到request header头中传给服务器，看是否命中协商缓存，命中则返回304，否则服务器会返回新的资源。（可以画个图理解一下）</p><p>HTTP 缓存又分为<strong>强缓存</strong>和 <strong>协商缓存</strong> ：</p><p><strong>强制缓存</strong>：在缓存数据未失效的情况下（即Cache-Control的max-age没有过期或者Expires的缓存时间没有过期），那么就会直接使用浏览器的缓存数据，不会再向服务器发送任何请求。</p><p><strong>协商缓存</strong>：当第一次请求时服务器返回的响应头中没有Cache-Control和Expires或者Cache-Control和Expires过期还或者它的属性设置为no-cache时(即不走强缓存)，那么浏览器第二次请求时就会与服务器进行 <strong>协商</strong>，与服务器端对比判断资源是否进行了修改更新。如果服务器端的资源没有修改，那么就会返回304状态码，告诉浏览器可以使用缓存中的数据，这样就减少了服务器的数据传输压力。如果数据有更新就会返回200状态码，服务器就会返回更新后的资源并且将缓存信息一起返回。</p><h1 id="HTTP状态码"><a href="#HTTP状态码" class="headerlink" title="HTTP状态码"></a>HTTP状态码</h1><ul><li>1xx：<strong>目前是协议的中间状态，还需要后续请求。</strong><ul><li>101 切换请求协议，从 HTTP 切换到 WebSocket</li></ul></li><li>2xx：<strong>表示请求成功。</strong><ul><li>200 请求成功，有响应体</li></ul></li><li><p>3xx：<strong>表示重定向状态，需要重新请求。</strong></p><ul><li>301 永久重定向：会缓存</li><li>302 临时重定向：不会缓存</li><li>304 协商缓存命中</li></ul></li><li><p>4xx：<strong>请求报文错误。</strong></p><ul><li>403 服务器禁止访问</li><li>404 资源未找到</li><li>400 请求错误</li></ul></li><li><p>5xx：<strong>服务器错误。</strong></p><ul><li>500 服务器端错误</li><li>503 服务器繁忙</li></ul></li></ul><h1 id="一个典型的HTTP请求报文包括哪些部分？响应报文呢？"><a href="#一个典型的HTTP请求报文包括哪些部分？响应报文呢？" class="headerlink" title="一个典型的HTTP请求报文包括哪些部分？响应报文呢？"></a>一个典型的HTTP请求报文包括哪些部分？响应报文呢？</h1><p>一个HTTP请求报文包括：  <strong>请求头，请求行，空行，请求体</strong>。</p><p>一个响应报文包括： <strong>响应行，响应头，空行，响应体</strong> 。</p><p>具体参考我的博客《详解HTTP协议》</p><h1 id="HTTP1-0、HTTP1-1、HTTP2-0区别"><a href="#HTTP1-0、HTTP1-1、HTTP2-0区别" class="headerlink" title="HTTP1.0、HTTP1.1、HTTP2.0区别"></a>HTTP1.0、HTTP1.1、HTTP2.0区别</h1><h2 id="HTTP1-0和HTTP1-1的区别-长短连接的区别"><a href="#HTTP1-0和HTTP1-1的区别-长短连接的区别" class="headerlink" title="HTTP1.0和HTTP1.1的区别/长短连接的区别"></a>HTTP1.0和HTTP1.1的区别/长短连接的区别</h2><p>这里主要回答长短连接的区别就行吧。。</p><p>在HTTP/1.0中采用短连接。客户端和服务器每进行一次HTTP操作，就建立一次连接，任务中断连接；Connection: close</p><p>在HTTP/1.1默认采用长连接和请求的流水线（Pipelining）处理，在一个TCP连接上可以传送多个HTTP请求和响应，减少了建立和关闭连接的消耗和延迟。Connection: keep-alive，就是保持连接。</p><hr><p>长连接适用的场景：长连接适用于操作频繁/点对点通讯等连接数不太多的情况，如：一些游戏/即时通讯场景应该使用长连接；</p><p>短连接适用的场景： 短连接适用于大量连接的场景，如Web【wapWeb/H5等】的http服务，长连接对于服务端来说会耗费一定资源。</p><blockquote><p>补充其他区别：</p><ul><li>长短连接</li><li><strong>缓存处理</strong>：在HTTP1.0中主要使用header里的If-Modified-Since,Expires来做为缓存判断的标准，HTTP1.1则引入了更多的缓存控制策略，可供选择的缓存头来控制缓存策略。</li><li><strong>带宽优化及网络连接的使用</strong>：HTTP1.0中，存在一些浪费带宽的现象，例如客户端只是需要某个对象的一部分，而服务器却将整个对象送过来了，并且不支持断点续传功能，HTTP1.1则在请求头引入了range头域，它允许只请求资源的某个部分，即返回码是206（Partial Content），这样就方便了开发者自由的选择以便于充分利用带宽和连接。</li><li><strong>错误通知的管理</strong>：在HTTP1.1中新增了24个错误状态响应码，如409（Conflict）表示请求的资源与资源的当前状态发生冲突；410（Gone）表示服务器上的某个资源被永久性的删除。</li><li><strong>Host头处理</strong>：在HTTP1.0中认为每台服务器都绑定一个唯一的IP地址，因此，请求消息中的URL并没有传递主机名（hostname）。但随着虚拟主机技术的发展，在一台物理服务器上可以存在多个虚拟主机（Multi-homed Web Servers），并且它们共享一个IP地址。HTTP1.1的请求消息和响应消息都应支持Host头域，且请求消息中如果没有Host头域会报告一个错误（400 Bad Request）。</li></ul></blockquote><h2 id="HTTP1和HTTP2的区别"><a href="#HTTP1和HTTP2的区别" class="headerlink" title="HTTP1和HTTP2的区别"></a>HTTP1和HTTP2的区别</h2><p>HTTP2.0是第二代TCP协议。它与HTTP1.1的不同点在于：</p><ul><li>HTTP2采用<strong>二进制</strong>而非文本格式；此属性减轻了框架的复杂性，并简化了由于包含文本和可选空格的命令而导致混淆的命令的实现。</li><li>HTTP2是 <strong>完全多路复用</strong> ，而线端阻塞的——只需一个连接可以实现并行；</li><li>HTTP2使用<strong>标头（headers）压缩</strong> ，减小了开销；</li><li>HTTP2让服务器可以将响应主动推送到客户端缓存中。</li></ul><p>名词解释：</p><blockquote><p>线端阻塞和多路复用</p><p>HTTP/1.x 有个问题叫线端阻塞(head-of-line blocking), 它是指<strong>一个连接(connection)一次只提交一个请求的效率比较高, 多了就会变慢</strong>。 HTTP/1.1 试过用流水线(pipelining)来解决这个问题, 但是效果并不理想(数据量较大或者速度较慢的响应, 会阻碍排在他后面的请求)。</p><p>多路传输(Multiplexing)能很好的解决这些问题, 因为它能同时处理多个消息的请求和响应; 甚至可以在传输过程中将一个消息跟另外一个掺杂在一起。所以<strong>客户端只需要一个连接</strong>就能加载一个页面。减少额外的往返时间。</p><p><img src="http1和2建立连接.png" alt="http1和2建立连接"></p><p>主动推送：通俗理解就是客户端请求了html，服务器觉得和其相关的css也会被关联到，于是主动同送其他资源到客户端。</p></blockquote><h1 id="GET、POST区别"><a href="#GET、POST区别" class="headerlink" title="GET、POST区别"></a>GET、POST区别</h1><p>具体看我的博客《详解HTTP协议》和《HTTP协议幂等性》</p><p><img src="get和post区别.png" alt="get和post区别"></p><p>‍</p>]]></content>
    
    
      
      
    <summary type="html">&lt;blockquote&gt;
&lt;p&gt;作为复习，也作为一个目录&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h1 id=&quot;说一下HTTP协议&quot;&gt;&lt;a href=&quot;#说一下HTTP协议&quot; class=&quot;headerlink&quot; title=&quot;说一下HTTP协议&quot;&gt;&lt;/a&gt;说一下HTTP协议&lt;/h</summary>
      
    
    
    
    <category term="计算机网络" scheme="https://guoyujian.github.io/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/"/>
    
    <category term="HTTP协议" scheme="https://guoyujian.github.io/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/HTTP%E5%8D%8F%E8%AE%AE/"/>
    
    
    <category term="计算机网络" scheme="https://guoyujian.github.io/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/"/>
    
    <category term="HTTP协议" scheme="https://guoyujian.github.io/tags/HTTP%E5%8D%8F%E8%AE%AE/"/>
    
  </entry>
  
  <entry>
    <title>使用腾讯会议的屏幕共享功能时开启PPT演示者视图的方法</title>
    <link href="https://guoyujian.github.io/2022/09/11/%E4%BD%BF%E7%94%A8%E8%85%BE%E8%AE%AF%E4%BC%9A%E8%AE%AE%E7%9A%84%E5%B1%8F%E5%B9%95%E5%85%B1%E4%BA%AB%E5%8A%9F%E8%83%BD%E6%97%B6%E5%BC%80%E5%90%AFPPT%E6%BC%94%E7%A4%BA%E8%80%85%E8%A7%86%E5%9B%BE%E7%9A%84%E6%96%B9%E6%B3%95/"/>
    <id>https://guoyujian.github.io/2022/09/11/%E4%BD%BF%E7%94%A8%E8%85%BE%E8%AE%AF%E4%BC%9A%E8%AE%AE%E7%9A%84%E5%B1%8F%E5%B9%95%E5%85%B1%E4%BA%AB%E5%8A%9F%E8%83%BD%E6%97%B6%E5%BC%80%E5%90%AFPPT%E6%BC%94%E7%A4%BA%E8%80%85%E8%A7%86%E5%9B%BE%E7%9A%84%E6%96%B9%E6%B3%95/</id>
    <published>2022-09-11T06:13:47.000Z</published>
    <updated>2022-09-11T06:14:43.767Z</updated>
    
    <content type="html"><![CDATA[<p><a href="https://meeting.tencent.com/support-doc-detail/79/index.html">https://meeting.tencent.com/support-doc-detail/79/index.html</a></p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;&lt;a href=&quot;https://meeting.tencent.com/support-doc-detail/79/index.html&quot;&gt;https://meeting.tencent.com/support-doc-detail/79/index.html&lt;/a&gt;&lt;/</summary>
      
    
    
    
    <category term="工具箱" scheme="https://guoyujian.github.io/categories/%E5%B7%A5%E5%85%B7%E7%AE%B1/"/>
    
    
    <category term="腾讯会议" scheme="https://guoyujian.github.io/tags/%E8%85%BE%E8%AE%AF%E4%BC%9A%E8%AE%AE/"/>
    
    <category term="ppt" scheme="https://guoyujian.github.io/tags/ppt/"/>
    
    <category term="演示者视图" scheme="https://guoyujian.github.io/tags/%E6%BC%94%E7%A4%BA%E8%80%85%E8%A7%86%E5%9B%BE/"/>
    
  </entry>
  
  <entry>
    <title>markdown公式编辑语法</title>
    <link href="https://guoyujian.github.io/2022/09/11/markdown%E5%85%AC%E5%BC%8F%E7%BC%96%E8%BE%91%E8%AF%AD%E6%B3%95/"/>
    <id>https://guoyujian.github.io/2022/09/11/markdown%E5%85%AC%E5%BC%8F%E7%BC%96%E8%BE%91%E8%AF%AD%E6%B3%95/</id>
    <published>2022-09-11T06:06:19.000Z</published>
    <updated>2022-09-11T06:10:33.036Z</updated>
    
    <content type="html"><![CDATA[<p>下面两个连接给出的公式语法涵盖了大部分的内容，第一个是官方连接。</p><ol><li><a href="https://katex.org/docs/supported.html">Supported Functions</a></li><li><a href="https://blog.csdn.net/weixin_42782150/article/details/104878759">史上最全Markdown公式、符号总结！！！</a></li></ol><p>另外推荐一款公式生成软件</p><blockquote><p><strong>mathpix snipping tool</strong></p></blockquote><p>通过截图生成公式code，可以直接复制公式代码，也可以直接复制到word等。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;下面两个连接给出的公式语法涵盖了大部分的内容，第一个是官方连接。&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;a href=&quot;https://katex.org/docs/supported.html&quot;&gt;Supported Functions&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;h</summary>
      
    
    
    
    <category term="工具箱" scheme="https://guoyujian.github.io/categories/%E5%B7%A5%E5%85%B7%E7%AE%B1/"/>
    
    
    <category term="markdown" scheme="https://guoyujian.github.io/tags/markdown/"/>
    
    <category term="typora" scheme="https://guoyujian.github.io/tags/typora/"/>
    
  </entry>
  
  <entry>
    <title>【不经意传输】算法介绍</title>
    <link href="https://guoyujian.github.io/2022/09/11/%E3%80%90%E4%B8%8D%E7%BB%8F%E6%84%8F%E4%BC%A0%E8%BE%93%E3%80%91%E7%AE%97%E6%B3%95%E4%BB%8B%E7%BB%8D/"/>
    <id>https://guoyujian.github.io/2022/09/11/%E3%80%90%E4%B8%8D%E7%BB%8F%E6%84%8F%E4%BC%A0%E8%BE%93%E3%80%91%E7%AE%97%E6%B3%95%E4%BB%8B%E7%BB%8D/</id>
    <published>2022-09-11T05:32:22.000Z</published>
    <updated>2022-09-11T05:38:01.807Z</updated>
    
    <content type="html"><![CDATA[<h1 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h1><p>“不经意传输”要解决这类问题：你需要给对方多条信息，但是你又必须确保对方只获得其中一条，但是对方又希望能够确保你不知道他看到哪一条信息。</p><p>设计一个具体场景：你给你的哥们介绍相亲女朋友，你有两个可供介绍的单身女性，但是你不想同时将两人的情况和联系方式给对方。但你也无法抉择到底给哪个，所以你想让他随机抽签选择一个。但与此同时，你的哥们也不想让你知道，他最终抽到了谁。</p><h1 id="定义"><a href="#定义" class="headerlink" title="定义"></a>定义</h1><p><strong>不经意传输</strong>（Oblivious Transfer，简称OT）是一个密码学协议，在这个协议中，消息发送者从一些待发送的消息中发送一条给接收者，但事后对发送了哪一条消息仍然oblivious（不知道），这个协议也叫茫然传输协议。</p><p>不经意传输是密码学中的一个基本而重要的问题，被认为是该领域的关键问题之一，对于<strong>安全多方计算</strong>来说是完整的实现。</p><p>例如下图，Alice是消息发送者，Bob是消息接受者。Alice想要将消息$M_0$、$M_1$之一传给Bob，Bob只能得到自己想要的那个（$M_0$或$M_1$）不能获取另外一个消息，Alice也不能知道Bob选的是哪一条消息。</p><p><img src="不经意传输1.png" alt="不经意传输1"></p><h1 id="历史"><a href="#历史" class="headerlink" title="历史"></a>历史</h1><p>第一种形式的不经意传输，最初是在1981由Michael O.Rabin提出，在这种不经意传输中，发送者Alice发送一条消息给接收着Bob，而Bob以1/2的概率接收到信息，在结束后Alice并不知道Bob是否接收到了信息，而Bob能确信地知道自己是否收到了信息。</p><p>另一种更实用的不经意传输协议，被称为2选一不经意传输（1 out 2 oblivious transfer）由 Shimon Even，Oded Goldreich和Abraham Lempel在1985年提出，在这种形式的不经意传输模型中，Alice每次发两条信息（m1、m2）给Bob，<strong>Bob提供一个输入</strong>，并根据输入获得输出信息，在协议结束后，Bob得到了自己想要的那条信息（m1或者m2），而Alice并不知道Bob最终得到的是哪条。</p><blockquote><p>这个输入，我的理解是通知发送者发哪些消息，发送消息的范围</p></blockquote><p>1986年，Brassard等人将2选1不经意传输拓展为n选1。</p><p><img src="不经意传输2.png" alt="不经意传输2"></p><p>不经意传输一种实现方式是<strong>基于RSA公钥算法</strong>，下面就2选1不经意传输的实现做简要介绍。</p><h1 id="基于RSA公钥算法的2选1不经意传输"><a href="#基于RSA公钥算法的2选1不经意传输" class="headerlink" title="基于RSA公钥算法的2选1不经意传输"></a>基于RSA公钥算法的2选1不经意传输</h1><p>先把「基于RSA公钥算法的2选1不经意传输」的流程图列出来：</p><p><img src="不经意传输流程.png" alt="不经意传输流程"></p><h2 id="流程"><a href="#流程" class="headerlink" title="流程"></a>流程</h2><ol><li>发送者Alice生成两对RSA公私钥$(puk0, pri0)$，$(puk1, pri1)$，并将两个公钥$puk0$和$puk1$发送给Bob。</li><li>Bob生成一个随机数$r$，并用收到的两个公钥之一加密随机数，$c=Encrypt(r)$。（用哪个秘钥取决于想获取哪条数据，例如如果想要得到消息$M_0$就用$puk0$加密随机数，如果想要得到$M_1$就用$puk1$加密随机数），并将密文结果发送给Alice。</li><li>Alice用自己的两个私钥分别解密收到随机数密文，得到两个解密结果：$k_0=Decrypt(c, pri_0)$，$k_1=Decrypt(c, pri_1)$。（$k_0$，$k_1$其中一个就是随机数$r$）。并将两个结果分别与两条信息进行异或，生成掩码消息：$e_0=k_0\bigoplus m_0$，$e_1=k_1\bigoplus m_1$，并将两个结果$e_0$，$e_1$发给Bob。</li><li>Bob用之前生成的随机数$r$与收到的$e_0$，$e_1$分别做异或操作，得到的两个结果中只有一条为真实数据，另外一条为随机数：$m^{‘}_0=e_0\bigoplus r$，$m^{‘}_1=e_1\bigoplus r$。</li><li>Bob在步骤2中，如果使用$puk0$加密，得到的$m^{‘}_0=m_0$，反之是$m_1$。</li></ol><h2 id="分析"><a href="#分析" class="headerlink" title="分析"></a>分析</h2><p>在此过程中第3步最为关键，如果Alice无法从用两条私钥解密得到的结果$k_0$、$k_1$中区分出Bob的真实随机数，则能保证Alice无法得知Bob将要获取的是哪条数据。Bob没有私钥也就无法得出真实的私钥解密结果（如果$k_0$为真实随机数，Bob无法得知$k_1$的值），所以也就只能得到自己想要的那条数据而无法得到另外一条，保障协议能执行成功。</p><h1 id="Refs"><a href="#Refs" class="headerlink" title="Refs"></a>Refs</h1><ol><li><a href="https://learnblockchain.cn/article/2022">区块链中的数学 - 不经意传输</a></li><li><a href="https://zhuanlan.zhihu.com/p/208295083">什么是不经意传输</a></li></ol>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;背景&quot;&gt;&lt;a href=&quot;#背景&quot; class=&quot;headerlink&quot; title=&quot;背景&quot;&gt;&lt;/a&gt;背景&lt;/h1&gt;&lt;p&gt;“不经意传输”要解决这类问题：你需要给对方多条信息，但是你又必须确保对方只获得其中一条，但是对方又希望能够确保你不知道他看到哪一条信息。&lt;/</summary>
      
    
    
    
    <category term="密码学" scheme="https://guoyujian.github.io/categories/%E5%AF%86%E7%A0%81%E5%AD%A6/"/>
    
    
    <category term="密码学" scheme="https://guoyujian.github.io/tags/%E5%AF%86%E7%A0%81%E5%AD%A6/"/>
    
  </entry>
  
  <entry>
    <title>RSA加密算法</title>
    <link href="https://guoyujian.github.io/2022/08/28/RSA%E5%8A%A0%E5%AF%86%E7%AE%97%E6%B3%95/"/>
    <id>https://guoyujian.github.io/2022/08/28/RSA%E5%8A%A0%E5%AF%86%E7%AE%97%E6%B3%95/</id>
    <published>2022-08-28T15:17:00.000Z</published>
    <updated>2022-08-28T15:28:04.869Z</updated>
    
    <content type="html"><![CDATA[<h1 id="对称加密与非对称加密"><a href="#对称加密与非对称加密" class="headerlink" title="对称加密与非对称加密"></a>对称加密与非对称加密</h1><p>使用相同的规则（秘钥）进行加密解密的算法成为“<strong>对称加密算法</strong>”，这种加密模式有一个最大弱点：甲方必须把加密规则告诉乙方，否则无法解密。保存和传递密钥，就成了最头疼的问题。</p><p>1976年，两位美国计算机学家Whitfield Diffie 和 Martin Hellman，提出了一种崭新构思，可以在不直接传递密钥的情况下，完成解密。这被称为<a href="https://en.wikipedia.org/wiki/Diffie–Hellman_key_exchange">“Diffie-Hellman密钥交换算法”</a>。这个算法启发了其他科学家。人们认识到，加密和解密可以使用不同的规则，只要这两种规则之间存在某种对应关系即可，这样就避免了直接传递密钥。</p><p>这种新的加密模式被称为”非对称加密算法”。</p><blockquote><p>（1）乙方生成两把密钥（公钥和私钥）。公钥是公开的，任何人都可以获得，私钥则是保密的。</p><p>（2）甲方获取乙方的公钥，然后用它对信息加密。</p><p>（3）乙方得到加密后的信息，用私钥解密。</p></blockquote><p>如果公钥加密的信息只有私钥解得开，那么只要私钥不泄漏，通信就是安全的。</p><blockquote><p> 我的理解：RSA加密算法就是一种非对称加密算法。甲向乙发送消息，乙先生成私钥和公钥，乙把公钥给甲，甲用公钥将信息加密，将加密信息发给乙，乙拿私钥解密。</p></blockquote><p>在介绍RSA算法之前需要先介绍一点数学知识。</p><h1 id="RSA算法的数学基础"><a href="#RSA算法的数学基础" class="headerlink" title="RSA算法的数学基础"></a>RSA算法的数学基础</h1><h2 id="互质关系"><a href="#互质关系" class="headerlink" title="互质关系"></a>互质关系</h2><p>如果两个正整数，除了1以外，没有其他公因子，我们就称这两个数是<a href="https://zh.wikipedia.org/zh-cn/互素">互质关系</a>（coprime）。比如，15和32没有公因子，所以它们是互质关系。这说明，不是质数也可以构成互质关系。</p><p>关于互质关系，不难得到以下结论：</p><blockquote><ol><li>任意两个质数构成互质关系，比如13和61。☆</li><li>一个数是质数，另一个数只要不是前者的倍数，两者就构成互质关系，比如3和10。</li><li>如果两个数之中，较大的那个数是质数，则两者构成互质关系，比如97和57。</li><li>1和任意一个自然数是都是互质关系，比如1和99。</li><li>p是大于1的整数，则p和p-1构成互质关系，比如57和56。</li><li>p是大于1的奇数，则p和p-2构成互质关系，比如17和15。</li></ol></blockquote><h2 id="欧拉函数"><a href="#欧拉函数" class="headerlink" title="欧拉函数"></a>欧拉函数</h2><p>对于任意给定的正整数n，计算在小于等于n的正整数之中，有多少个与n构成互质关系的方法就叫做<strong>欧拉函数</strong>。以φ(n)表示。在1到8之中，与8形成互质关系的是1、3、5、7，所以 φ(n) = 4。</p><p><strong>第一种情况</strong></p><p>如果n=1，则 φ(1) = 1 。因为1与任何数（包括自身）都构成互质关系。</p><p><strong>第二种情况</strong></p><p>如果n是质数，则 φ(n)=n-1。因为质数与小于它的每一个数，都构成互质关系。比如5与1、2、3、4都构成互质关系。</p><p><strong>第三种情况</strong></p><p>如果n是质数的某一个次方，即$ n = p^k $ （p为质数，k为大于等于1的整数），则</p><script type="math/tex; mode=display">φ(p^k) = p^k - p^{k-1}</script><p>比如 $φ(8) = φ(2^3) = 2^3 - 2^2 = 4$。</p><p>这是因为只有当一个数不包含质数p，才可能与n互质。而包含质数p的数一共有$p^{k-1}$个，即$1×p$、$2×p$、$3×p$、…、$p^{k-1}×p$，把它们去除，剩下的就是与n互质的数。</p><p>上面的式子还可以写成下面的形式：</p><script type="math/tex; mode=display">φ(p^k) = p^k - p^{k-1} = p^k(1-\frac{1}{p})</script><p>可以看出，上面的第二种情况是 k=1 时的特例。</p><p><strong>第四种情况</strong></p><p>如果n可以分解成两个互质的整数之积，$n = p_1 <em> p_2$，则$φ(n) = φ(p_1</em>p_2) = φ(p_1) * φ(p_2)$</p><p>即积的欧拉函数等于欧拉函数的积。比如，$φ(56)=φ(8×7)=φ(8)×φ(7)=4×6=24$。</p><p>这一条的证明要用到<a href="https://en.wikipedia.org/wiki/Chinese_remainder_theorem">“中国剩余定理”</a>，这里就不展开了。</p><p><strong>第五种情况</strong></p><p>因为任意一个大于1的正整数，都可以写成一系列质数的积。</p><script type="math/tex; mode=display">n = p_1^{k_1}p_2^{k_2}…p_r^{k_r}</script><p>根据第4条的结论，得到</p><script type="math/tex; mode=display">φ(n)=φ(p_1^{k_1})φ(p_2^{k_2})…φ(p_r^{k_r})</script><p>再根据第3条的结论，得到</p><script type="math/tex; mode=display">φ(n)=p_1^{k_1}p_2^{k_2}…p_r^{k_r}(1-\frac{1}{p_1})(1-\frac{1}{p_2})…(1-\frac{1}{p_r})</script><p>也就等于</p><script type="math/tex; mode=display">φ(n)=n(1-\frac{1}{p_1})(1-\frac{1}{p_2})…(1-\frac{1}{p_r})</script><p>这就是欧拉函数的通用计算公式。比如，1323的欧拉函数，计算过程如下：</p><script type="math/tex; mode=display">φ(1323)=φ(3^3*7^2)=1323(1-\frac{1}{3})(1-\frac{1}{7})=756</script><h2 id="欧拉定理"><a href="#欧拉定理" class="headerlink" title="欧拉定理"></a>欧拉定理</h2><p>欧拉函数的用处，在于<a href="https://zh.wikipedia.org/wiki/欧拉定理_(数论">欧拉定理</a>)。”欧拉定理”指的是：</p><blockquote><p>如果两个正整数a和n互质，则n的欧拉函数 φ(n) 可以让下面的等式成立：</p><script type="math/tex; mode=display">a^{φ(n)}\equiv1 \pmod n</script></blockquote><p>也就是说，a的φ(n)次方被n除的余数为1。或者说，a的φ(n)次方减去1，可以被n整除。比如，3和7互质，而7的欧拉函数φ(7)等于6，所以3的6次方（729）减去1，可以被7整除（728/7=104）。</p><p>欧拉定理的证明比较复杂，这里就省略了。我们只要记住它的结论就行了。</p><p>欧拉定理可以大大简化某些运算。比如，7和10互质，根据欧拉定理，</p><script type="math/tex; mode=display">7^{φ(10)}\equiv1 \pmod {10}</script><p>已知 φ(10) 等于4，所以马上得到7的4倍数次方的个位数肯定是1。</p><script type="math/tex; mode=display">7^{4k}\equiv1 \pmod {10}</script><p>因此，7的任意次方的个位数（例如7的222次方），心算就可以算出来。</p><p>欧拉定理有一个特殊情况。</p><blockquote><p>假设正整数a与质数p互质，因为质数p的φ(p)等于p-1，则欧拉定理可以写成</p><script type="math/tex; mode=display">a^{p-1} \equiv 1 \pmod p</script></blockquote><p>这就是著名的<a href="https://zh.wikipedia.org/wiki/费马小定理">费马小定理</a>。它是欧拉定理的特例。</p><p>欧拉定理是RSA算法的核心。理解了这个定理，就可以理解RSA。</p><h2 id="模反元素"><a href="#模反元素" class="headerlink" title="模反元素"></a>模反元素</h2><p>还剩下最后一个概念：</p><blockquote><p>如果两个正整数a和n互质，那么一定可以找到整数b，使得 ab-1 被n整除，或者说ab被n除的余数是1。</p><script type="math/tex; mode=display">ab \equiv 1 \pmod n</script><p>这时，b就叫做a的<a href="https://zh.wikipedia.org/wiki/模反元素">“模反元素”</a>。</p></blockquote><p>比如，3和11互质，那么3的模反元素就是4，因为 (3 × 4)-1 可以被11整除。显然，模反元素不止一个， 4加减11的整数倍都是3的模反元素 {…,-18,-7,4,15,26,…}，即如果b是a的模反元素，则 b+kn 都是a的模反元素。</p><p>欧拉定理可以用来证明模反元素必然存在。</p><script type="math/tex; mode=display">a^{φ(n)}=a*a^{φ(n)-1} \equiv 1 \pmod n</script><p>可以看到，a的 φ(n)-1 次方，就是a的模反元素。</p><h1 id="RSA算法"><a href="#RSA算法" class="headerlink" title="RSA算法"></a>RSA算法</h1><h2 id="密钥生成的步骤"><a href="#密钥生成的步骤" class="headerlink" title="密钥生成的步骤"></a>密钥生成的步骤</h2><p>我们通过一个例子，来理解RSA算法。假设爱丽丝要与鲍勃进行加密通信，她该怎么生成公钥和私钥呢？</p><p><img src="bg2013070302.png" alt="img"></p><p><strong>第一步，随机选择两个不相等的质数p和q。</strong></p><p>爱丽丝选择了61和53。（实际应用中，这两个质数越大，就越难破解。）</p><p><strong>第二步，计算p和q的乘积n。</strong></p><p>爱丽丝就把61和53相乘。</p><script type="math/tex; mode=display">n = 61*53 = 3233</script><p>n的二进制长度就是密钥长度。3233写成二进制是110010100001，一共有12位，所以这个密钥就是12位。</p><p>实际应用中，RSA密钥一般是1024位，重要场合则为2048位。</p><p><strong>第三步，计算n的欧拉函数φ(n)。</strong></p><p>根据公式：</p><script type="math/tex; mode=display">φ(n) = (p-1)(q-1)</script><p>$φ(3233)=φ(61<em>53)=φ(61)</em>φ（53）=60*52=3120$</p><p><strong>第四步，随机选择一个整数e，条件是1&lt; e &lt; φ(n)，且e与φ(n) 互质。</strong></p><p>爱丽丝就在1到3120之间，随机选择了17。（实际应用中，常常选择65537。）</p><p><strong>第五步，计算e对于φ(n)的模反元素d。</strong></p><p>所谓<a href="https://zh.wikipedia.org/wiki/模反元素">“模反元素”</a>就是指有一个整数d，可以使得ed被φ(n)除的余数为1。</p><script type="math/tex; mode=display">ed \equiv 1 \pmod {φ(n)}</script><p>这个式子等价于</p><script type="math/tex; mode=display">ed - 1 = k φ(n)</script><p>于是，找到模反元素d，实质上就是对下面这个二元一次方程求解。</p><script type="math/tex; mode=display">ed - kφ(n) = 1</script><p>已知 e=17, φ(n)=3120，</p><script type="math/tex; mode=display">17d-3120k=1</script><p>这个方程可以用<a href="https://zh.wikipedia.org/wiki/扩展欧几里得算法">“扩展欧几里得算法”</a>求解，此处省略具体过程。总之，爱丽丝算出一组整数解为 (d, k)=(2753,-15)，即 d=2753。</p><p>至此所有计算完成。</p><p><strong>第六步，将n和e封装成公钥，n和d封装成私钥。</strong></p><p>在爱丽丝的例子中，n=3233，e=17，d=2753，所以公钥就是(n, e) =  (3233,17)，私钥就是(n, d)=(3233, 2753)。</p><h2 id="RSA算法的可靠性"><a href="#RSA算法的可靠性" class="headerlink" title="RSA算法的可靠性"></a>RSA算法的可靠性</h2><p>回顾上面的密钥生成步骤，一共出现六个数字：</p><blockquote><p>p<br>q<br>n<br>φ(n)<br>e<br>d</p></blockquote><p>这六个数字之中，公钥用到了两个（n和e），其余四个数字都是不公开的。其中最关键的是d，因为n和d组成了私钥，一旦d泄漏，就等于私钥泄漏。</p><p><strong>那么，有无可能在已知n和e的情况下，推导出d？</strong></p><blockquote><ol><li>ed≡1 (mod φ(n))。只有知道e和φ(n)，才能算出d。</li><li>φ(n)=(p-1)(q-1)。只有知道p和q，才能算出φ(n)。</li><li>n=pq。只有将n因数分解，才能算出p和q。</li></ol></blockquote><p><strong>结论：如果n可以被因数分解，d就可以算出，也就意味着私钥被破解。</strong></p><p>可是，大整数的因数分解，是一件非常困难的事情。目前，除了暴力破解，还没有发现别的有效方法。维基百科这样写道：</p><blockquote><p>“对极大整数做因数分解的难度决定了RSA算法的可靠性。换言之，对一极大整数做因数分解愈困难，RSA算法愈可靠。</p><p>假如有人找到一种快速因数分解的算法，那么RSA的可靠性就会极度下降。但找到这样的算法的可能性是非常小的。今天只有短的RSA密钥才可能被暴力破解。到2008年为止，世界上还没有任何可靠的攻击RSA算法的方式。</p><p>只要密钥长度足够长，用RSA加密的信息实际上是不能被解破的。”</p></blockquote><p>举例来说，你可以对3233进行因数分解（61×53），但是你没法对下面这个整数进行因数分解。</p><blockquote><p>12301866845301177551304949<br>58384962720772853569595334<br>79219732245215172640050726<br>36575187452021997864693899<br>56474942774063845925192557<br>32630345373154826850791702<br>61221429134616704292143116<br>02221240479274737794080665<br>351419597459856902143413</p></blockquote><p>它等于这样两个质数的乘积：</p><blockquote><p>33478071698956898786044169<br>84821269081770479498371376<br>85689124313889828837938780<br>02287614711652531743087737<br>814467999489<br>×<br>36746043666799590428244633<br>79962795263227915816434308<br>76426760322838157396665112<br>79233373417143396810270092<br>798736308917</p></blockquote><p>事实上，这大概是人类已经分解的最大整数（232个十进制位，768个二进制位）。比它更大的因数分解，还没有被报道过，因此目前被破解的最长RSA密钥就是768位。</p><h2 id="加密和解密"><a href="#加密和解密" class="headerlink" title="加密和解密"></a>加密和解密</h2><p>有了公钥和密钥，就能进行加密和解密了。</p><p><strong>加密要用公钥 (n,e)</strong></p><p>假设鲍勃要向爱丽丝发送加密信息m，他就要用爱丽丝的公钥 (n,e) 对m进行加密。这里需要注意，m必须是整数（字符串可以取ascii值或unicode值），且m必须小于n。</p><p>所谓”加密”，就是算出下式的c：</p><script type="math/tex; mode=display">m^e \equiv c \pmod n</script><p>爱丽丝的公钥是 (3233, 17)，鲍勃的m假设是65，那么可以算出下面的等式：</p><script type="math/tex; mode=display">65^{17} \equiv 2790 \pmod {3233}</script><p>于是，c等于2790，鲍勃就把2790发给了爱丽丝。</p><p><strong>解密要用私钥(n,d)</strong></p><p>爱丽丝拿到鲍勃发来的2790以后，就用自己的私钥(3233, 2753) 进行解密。可以证明，下面的等式一定成立：</p><script type="math/tex; mode=display">c^d \equiv m \pmod n</script><p>也就是说，c的d次方除以n的余数为m。现在，c等于2790，私钥是(3233, 2753)，那么，爱丽丝算出</p><script type="math/tex; mode=display">2790^{2753}\equiv65 \pmod {3233}</script><p>因此，爱丽丝知道了鲍勃加密前的原文就是65。</p><p>至此，”加密—解密”的整个过程全部完成。</p><p>我们可以看到，如果不知道d，就没有办法从c求出m。而前面已经说过，要知道d就必须分解n，这是极难做到的，所以RSA算法保证了通信安全。</p><p>你可能会问，公钥(n,e) 只能加密小于n的整数m，那么如果要加密大于n的整数，该怎么办？有两种解决方法：一种是把长信息分割成若干段短消息，每段分别加密；另一种是先选择一种”对称性加密算法”（比如<a href="https://zh.wikipedia.org/wiki/资料加密标准">DES</a>），用这种算法的密钥加密信息，再用RSA公钥加密DES密钥。</p><h2 id="私钥解密的证明"><a href="#私钥解密的证明" class="headerlink" title="私钥解密的证明"></a>私钥解密的证明</h2><p>最后，我们来证明，为什么用私钥解密，一定可以正确地得到m。也就是证明下面这个式子：</p><script type="math/tex; mode=display">c^d\equiv m \pmod n</script><p>因为，根据加密规则</p><script type="math/tex; mode=display">m^e\equiv c \pmod n</script><p>于是，c可以写成下面的形式：</p><script type="math/tex; mode=display">c = m^e -kn</script><p>将c代入要我们要证明的那个解密规则：</p><script type="math/tex; mode=display">(m^e-kn)^d=m \pmod n</script><p>左边二项式拆出来，除了第一项$m^e$，其他项都是n的倍数，所以它等同于求证</p><script type="math/tex; mode=display">m^{ed} \equiv m \pmod n</script><p>由于</p><script type="math/tex; mode=display">ed \equiv 1 \pmod {φ(n)}</script><p>所以</p><script type="math/tex; mode=display">ed = h φ(n) + 1</script><p>将ed代入：</p><script type="math/tex; mode=display">m^{hφ(n)+1}=m \pmod n</script><p>接下来，分成两种情况证明上面这个式子。</p><p><strong>（1）m与n互质。</strong></p><p>根据欧拉定理，此时</p><script type="math/tex; mode=display">m^{φ(n)} \equiv 1 \pmod n</script><p>得到</p><script type="math/tex; mode=display">(m^{φ(n)})^h*m \equiv m \pmod n</script><p>原式得到证明。</p><p><strong>（2）m与n不是互质关系。</strong></p><p>此时，由于n等于质数p和q的乘积，所以m必然等于kp或kq。</p><p>以 m = kp为例，考虑到这时k与q必然互质，则根据欧拉定理，下面的式子成立：</p><script type="math/tex; mode=display">(kp)^{q-1} \equiv 1 \pmod q</script><p>进一步得到</p><script type="math/tex; mode=display">[(kp)^{q-1}]^{h(p-1)}*kp \equiv kp \pmod q</script><p>即</p><script type="math/tex; mode=display">(kp)^{ed} \equiv kp \pmod q</script><p>将它改写成下面的等式</p><script type="math/tex; mode=display">(kp)^{ed} = tq + kp</script><p>这时t必然能被p整除，即 t=t’p</p><script type="math/tex; mode=display">(kp)^{ed}=t'pq+kp</script><p>因为 m=kp，n=pq，所以</p><script type="math/tex; mode=display">m^{ed} \equiv m \pmod n</script><p>原式得到证明。</p><h1 id="Refs"><a href="#Refs" class="headerlink" title="Refs"></a>Refs</h1><ol><li><a href="https://www.ruanyifeng.com/blog/2013/06/rsa_algorithm_part_one.html">RSA算法原理（一）</a></li><li><a href="https://www.ruanyifeng.com/blog/2013/07/rsa_algorithm_part_two.html">RSA算法原理（二）</a></li></ol>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;对称加密与非对称加密&quot;&gt;&lt;a href=&quot;#对称加密与非对称加密&quot; class=&quot;headerlink&quot; title=&quot;对称加密与非对称加密&quot;&gt;&lt;/a&gt;对称加密与非对称加密&lt;/h1&gt;&lt;p&gt;使用相同的规则（秘钥）进行加密解密的算法成为“&lt;strong&gt;对称加密算法&lt;</summary>
      
    
    
    
    <category term="加密算法" scheme="https://guoyujian.github.io/categories/%E5%8A%A0%E5%AF%86%E7%AE%97%E6%B3%95/"/>
    
    
    <category term="加密算法" scheme="https://guoyujian.github.io/tags/%E5%8A%A0%E5%AF%86%E7%AE%97%E6%B3%95/"/>
    
  </entry>
  
  <entry>
    <title>深度学习中图像分类问题的总结</title>
    <link href="https://guoyujian.github.io/2022/08/16/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%AD%E5%9B%BE%E5%83%8F%E5%88%86%E7%B1%BB%E9%97%AE%E9%A2%98%E7%9A%84%E6%80%BB%E7%BB%93/"/>
    <id>https://guoyujian.github.io/2022/08/16/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%AD%E5%9B%BE%E5%83%8F%E5%88%86%E7%B1%BB%E9%97%AE%E9%A2%98%E7%9A%84%E6%80%BB%E7%BB%93/</id>
    <published>2022-08-16T12:25:28.000Z</published>
    <updated>2022-08-16T15:11:48.095Z</updated>
    
    <content type="html"><![CDATA[<h1 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h1><blockquote><p>企业实习中遇到的场景。</p><p>输入是ICU中病人的一段视频，输出是基于判断该病人是否贫血。</p><p>甲方给出了300多个的视频，每个视频对应一个病人。其中重度贫血样本最少，轻度贫血的样本量最多。</p><p>（说实在的，这个任务实在是有点玄学，查了一些资料，也没有理论依据。但是甲方说有经验的医生看几眼就能看出来<strong>病人</strong>是否是贫血，所以只能硬着头皮做。）</p><p>在实践过程中，得到了专家的指点，故把专家给出的技巧和实践中遇到的若干问题和解决思路记录下来。</p></blockquote><h1 id="数据处理和算法流程"><a href="#数据处理和算法流程" class="headerlink" title="数据处理和算法流程"></a>数据处理和算法流程</h1><p>如图。圆角矩形是数据，矩形是处理流程</p><p><img src="image-20220816222412537.png" alt="数据处理和算法流程"></p><h1 id="指导纪要"><a href="#指导纪要" class="headerlink" title="指导纪要"></a>指导纪要</h1><p>本节记录专家给出的一些指导要点。</p><h2 id="明确需求"><a href="#明确需求" class="headerlink" title="明确需求"></a>明确需求</h2><p>在开始之前，需要明确需求，针对本次任务主要是明确一下几点：</p><ol><li>目标是什么？最终的算法模型是科研，还是落地应用。如果是落地应用，那么可能更看重重度贫血的召回。</li><li>明确输入：是一段视频，还是一张照片，如果是一段视频还要考虑时序信息。</li><li>预测样本是已知的还是未知的：未知。</li><li>是否能有更多的数据？能，但比较慢，毕竟实际情况就是ICU的病床数量比较少。总样本量就那些。</li></ol><h2 id="分析bad-case"><a href="#分析bad-case" class="headerlink" title="分析bad case"></a>分析bad case</h2><p>找一个模型快速实现，（我们这里使用的是Efficient Net），基于这个baseline，分析bad case。</p><p>所谓bad case 就是模型经过训练后，预测错的case。分析bad case非常重要。（这一点在我实践的过程中没有重视，原因是ICU的病人的视频和照片容易引起不适）</p><p>分析bad case的目的有如下几个：</p><ol><li>确定算法上限：<strong>数据决定算法上限，模型只是在逼近这个上限。</strong>我们的模型做到什么样才算可以交差了，不是拍脑袋决定的，而是由本步骤得到的算法上限决定的。</li><li>如果人眼分辨起来都比较困难，那该任务可能是不可实现的。</li><li>纠正数据（标注）问题。在分析bad case的时候我发现有一些视频帧非常模糊，后面通过计算清晰度，将视频帧中比较模糊的图像去除掉了。</li></ol><h2 id="调参"><a href="#调参" class="headerlink" title="调参"></a>调参</h2><p>在明确了算法上限之后，再进行调参。</p><ol><li>train阶段：<ol><li>针对数据不均衡的问题，主要有三种方式：对每一个类别进行加权；把占比大的分类样本量调低；数据增强。（前两种在以前的实践中提升不大，最后一种PyTorch有现成的code）</li><li>针对模型，一般来说<strong>模型的分类力度要比需求的粒度更细</strong>，在该场景下，需求要求二分类，而模型取四分类。方便后续的调整。</li><li>测试后，画出<strong>混淆矩阵</strong>，看哪几个子类容易混淆，再对混淆的子类单独训练模型。（多个模型级联）</li><li>更换loss：我们尝试了把交叉熵损失换成center loss、focal loss，但效果也没有好到哪去。</li></ol></li><li>val阶段：<ol><li>loss：在该场景下，模型会给出四个分数，分别对应四个类别的可能性。一般是取四个分数中max对应的分类，作为最后的分类结果。<strong>修改阈值</strong>以改变最后的分类结果（比如，当重度贫血的概率大于人为设定的X时，就认为分类结果为重度贫血）。</li><li>X怎么定？X的值取决于指标。比如我想要重度贫血的Recall达到99%，那我把预测的重度贫血的分数由高到低排序，画一个最低线，在该线之上都被预测为重度贫血，那么该线就是我们想要的X。</li><li>loss：也可以给四个分数分别乘上四个权重。这条与上条的区别是，上一条可以轻易的确保Precision或Recall。</li></ol></li></ol><h2 id="其他"><a href="#其他" class="headerlink" title="其他"></a>其他</h2><h3 id="手工提取特征V-S-自动提取特征"><a href="#手工提取特征V-S-自动提取特征" class="headerlink" title="手工提取特征V.S.自动提取特征"></a>手工提取特征V.S.自动提取特征</h3><p>上面的<em>数据处理流程图</em>中可见，为了避免背景（病床等）干扰，我们先用网上一个训练好的模型提取人脸。再把提取的人脸拿去训练。</p><p>由于提取的效果有限，后来又使用K-means算法对颜色进行聚类，设置一个阈值，把大部分图像中病人的插管，口罩等去掉，用黑色背景代替。（当然效果依然有限）</p><p>一开始我们认为通过手工提取特征后，再丢到网络里训练，这样的效果会更好。</p><p>但专家认为并非如此，实际效果也确实如专家所料。</p><p>专家说，手工提取特征的缺点是，提取特征的同时会损害图像本身（图像出现一小块一小块的黑色背景）；其次，手工提取特征需要手工设定一个阈值，而这个阈值的最佳情形在训练集和测试集可能是不同的。</p><p>专家又说，<strong>在以往的实践中，深度学习的自动提取特征效果更好、更稳定。</strong></p><h3 id="三百个样本够不够用"><a href="#三百个样本够不够用" class="headerlink" title="三百个样本够不够用"></a>三百个样本够不够用</h3><p><strong>样本够不够取决于问题的难度。</strong>没有绝对意义上的够不够。</p><h3 id="预训练OR没有预训练"><a href="#预训练OR没有预训练" class="headerlink" title="预训练OR没有预训练"></a>预训练OR没有预训练</h3><p><strong>使用预训练的网络模型要比没有预训练的模型更好。</strong>（具体原因忘了。）</p><h3 id="交叉验证"><a href="#交叉验证" class="headerlink" title="交叉验证"></a>交叉验证</h3><p>虽然数据都是随机的分到train或者val，但是为了防止，分到train的数据太简单、val的数据太难和分到train的数据太难、val的数据太简单，会导致模型最后的效果不一样。<strong>为了提高模型的鲁棒性，需要K-Fold交叉验证。</strong></p><h3 id="多次迭代训练"><a href="#多次迭代训练" class="headerlink" title="多次迭代训练"></a>多次迭代训练</h3><p>由易到难多轮迭代。</p><p>先人工筛选出一些<strong>简单</strong>样本，按照一定比例组织数据进行训练，得到一个可以分类简单样本的模型。</p><p>再筛选出比简单样本稍难一点的样本，按照一定比例组织数据进行训练，得到一个可以分类比简单样本稍难样本的模型。</p><p>……</p><p>依次类推，直到所有样本都丢进去训练。</p><blockquote><p>这里所说的简单是人容易分辨的。</p><p>如果所有样本人都不容易看出来怎么办？</p><p>那就先进行一次整体的训练。找到本次训练中模型预测正确的样本，这样的样本即为模型认为的简单样本</p></blockquote><p>这种方法的优点是，效果会更好。（专家的原话是，屡试不爽）</p><p>我想可能是因为它比较符合人由易到难的学习思路。</p><p>缺点就是耗时长，人干预的时间长。（毕竟需要挑样本，挺累的。。）</p><h3 id="Attention"><a href="#Attention" class="headerlink" title="Attention"></a>Attention</h3><p>如果希望模型集中到某些局部特征可以使用attention机制。</p><h3 id="对于不清楚的代码或者参数"><a href="#对于不清楚的代码或者参数" class="headerlink" title="对于不清楚的代码或者参数"></a>对于不清楚的代码或者参数</h3><p>细究论文、源码。</p><h1 id="Refs"><a href="#Refs" class="headerlink" title="Refs"></a>Refs</h1>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;背景&quot;&gt;&lt;a href=&quot;#背景&quot; class=&quot;headerlink&quot; title=&quot;背景&quot;&gt;&lt;/a&gt;背景&lt;/h1&gt;&lt;blockquote&gt;
&lt;p&gt;企业实习中遇到的场景。&lt;/p&gt;
&lt;p&gt;输入是ICU中病人的一段视频，输出是基于判断该病人是否贫血。&lt;/p&gt;
&lt;p&gt;</summary>
      
    
    
    
    <category term="深度学习" scheme="https://guoyujian.github.io/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
    
    <category term="深度学习" scheme="https://guoyujian.github.io/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
    <category term="计算机视觉" scheme="https://guoyujian.github.io/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/"/>
    
  </entry>
  
  <entry>
    <title>力扣-前K个高频元素-用流来做</title>
    <link href="https://guoyujian.github.io/2022/07/11/%E5%8A%9B%E6%89%A3-%E5%89%8DK%E4%B8%AA%E9%AB%98%E9%A2%91%E5%85%83%E7%B4%A0-%E7%94%A8%E6%B5%81%E6%9D%A5%E5%81%9A/"/>
    <id>https://guoyujian.github.io/2022/07/11/%E5%8A%9B%E6%89%A3-%E5%89%8DK%E4%B8%AA%E9%AB%98%E9%A2%91%E5%85%83%E7%B4%A0-%E7%94%A8%E6%B5%81%E6%9D%A5%E5%81%9A/</id>
    <published>2022-07-11T13:06:28.000Z</published>
    <updated>2022-07-11T13:40:10.607Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>使用Java8 Stream来完成力扣 <a href="https://leetcode.cn/problems/top-k-frequent-elements/">347. 前 K 个高频元素</a></p></blockquote><h1 id="题目及思路"><a href="#题目及思路" class="headerlink" title="题目及思路"></a>题目及思路</h1><blockquote><p>给一个整数数组 nums 和一个整数 k ，请你返回其中出现频率前 k 高的元素。你可以按 <strong>任意顺序</strong> 返回答案。</p><p>例如：</p><p>输入: nums = [1,1,1,2,2,3], k = 2</p><p>输出: [1,2]</p></blockquote><p>思路很简单：</p><p>将<key: 元素，value: 元素出现的次数>存到Map中，将map按value倒序排序，输出前k个返回。</p><h1 id="经典做法"><a href="#经典做法" class="headerlink" title="经典做法"></a>经典做法</h1><p>下面是根据上面的思路实现的代码</p><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="type">int</span>[] topKFrequent(<span class="type">int</span>[] nums, <span class="type">int</span> k) &#123;</span><br><span class="line">        <span class="keyword">if</span>(k == <span class="number">0</span> || nums.length == <span class="number">0</span>)&#123;</span><br><span class="line">            <span class="type">int</span> tmp[] = &#123;&#125;;</span><br><span class="line">            <span class="keyword">return</span> tmp;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">//创建返回的res数组</span></span><br><span class="line">        <span class="type">int</span> res[] = <span class="keyword">new</span> <span class="title class_">int</span>[k];</span><br><span class="line">        <span class="comment">//创建map</span></span><br><span class="line">        Map&lt;Integer, Integer&gt; map = <span class="keyword">new</span> <span class="title class_">HashMap</span>&lt;&gt;();</span><br><span class="line">        <span class="comment">//将nums数组中元素和元素出现的次数保存到map中</span></span><br><span class="line">        <span class="keyword">for</span> (<span class="type">int</span> num : nums) &#123;</span><br><span class="line">            <span class="keyword">if</span>(map.containsKey(num)) &#123;</span><br><span class="line">                map.put(num, map.get(num)+<span class="number">1</span>);</span><br><span class="line">            &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                map.put(num, <span class="number">0</span>);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">//创建map.entrySet()的list用于排序</span></span><br><span class="line">        List&lt;Map.Entry&lt;Integer, Integer&gt;&gt; list = <span class="keyword">new</span> <span class="title class_">ArrayList</span>&lt;&gt;(map.entrySet());</span><br><span class="line">        <span class="comment">//按map的值倒序排序</span></span><br><span class="line">        Collections.sort(list, <span class="keyword">new</span> <span class="title class_">Comparator</span>&lt;Map.Entry&lt;Integer, Integer&gt;&gt;() &#123;</span><br><span class="line">            <span class="meta">@Override</span></span><br><span class="line">            <span class="keyword">public</span> <span class="type">int</span> <span class="title function_">compare</span><span class="params">(Map.Entry&lt;Integer, Integer&gt; o1, Map.Entry&lt;Integer, Integer&gt; o2)</span> &#123;</span><br><span class="line">                <span class="keyword">return</span> o2.getValue() - o1.getValue();</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;);</span><br><span class="line">        <span class="comment">//取出前k个放到res中</span></span><br><span class="line">        <span class="keyword">for</span> (<span class="type">int</span> <span class="variable">i</span> <span class="operator">=</span> <span class="number">0</span>; i &lt; k; i++) &#123;</span><br><span class="line">            res[i] = list.get(i).getKey();</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> res;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h1 id="使用Stream"><a href="#使用Stream" class="headerlink" title="使用Stream"></a>使用Stream</h1><p>使用Stream实现的代码</p><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="type">int</span>[] topKFrequent(<span class="type">int</span>[] nums, <span class="type">int</span> k) &#123;</span><br><span class="line">        <span class="keyword">return</span> Arrays.stream(nums) <span class="comment">// IntStream</span></span><br><span class="line">                .boxed() <span class="comment">// Stream&lt;Integer&gt;</span></span><br><span class="line">                .collect(Collectors.toMap(key -&gt; key, value -&gt; <span class="number">1</span>, Integer::sum)) <span class="comment">// Map&lt;Integer, Integer&gt;</span></span><br><span class="line">                .entrySet() <span class="comment">// Set&lt;Map&lt;K, V&gt;.Entry&lt;Integer, Integer&gt;&gt;</span></span><br><span class="line">                .stream() <span class="comment">// Stream&lt;Map&lt;K, V&gt;.Entry&lt;Integer, Integer&gt;&gt;</span></span><br><span class="line">                .sorted(Map.Entry.comparingByValue(Comparator.reverseOrder()))</span><br><span class="line">                .map(Map.Entry::getKey) <span class="comment">// Stream&lt;Integer&gt;</span></span><br><span class="line">                .limit(k)</span><br><span class="line">                .mapToInt(i -&gt; i) <span class="comment">//IntStream</span></span><br><span class="line">                .toArray();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>是不是非常的简洁明了？下面对代码做一下必要解释</p><ul><li><p>为了将<code>int[]</code>转为流，使用了<code>Arrays.stream(nums)</code></p></li><li><p>需要注意的是，普通的流总是包装类，但这里直接得到了IntStream，为了后面封装为<code>Map&lt;Integer, Integer&gt;</code>，所以需要使用<code>boxed()</code>将IntStream转为<code>Stream&lt;Integer&gt;</code></p></li><li><p><code>collect</code>将Stream收集到一个Map</p></li><li><p><code>Collectors.toMap</code>的三个参数分别是，收集到Map的key，value当遇到重复key时的处理方法；</p></li><li><p>3-5行的代码等价于下面</p><ul><li><pre><code class="lang-java">Map&lt;Integer, Integer&gt; map = new HashMap&lt;&gt;();Arrays.stream(nums).forEach(num -&gt; &#123;    map.put(num, map.getOrDefault(num, 0) + 1);&#125;);</code></pre></li></ul></li><li><p>为了从map中再次获得流，我们使用代码先得到map的set在获得流。代码对应<code>entryset()</code>和<code>stream()</code></p></li><li><p>获得流之后需要根据value进行倒序排序，使用<code>sorted()</code>，其传入的参数是一个比较器</p></li><li><p>排序之后映射使用map()将<code>Stream&lt;Map&lt;K, V&gt;.Entry&lt;Integer, Integer&gt;&gt;</code>映射为<code>Stream&lt;Integer&gt;</code></p></li><li><p>我们只需要前k个，所以用limit(k)</p></li><li><p>使用<code>mapToInt(i -&gt; i)</code>进行拆包，得到IntStream</p></li><li><p><code>toArray()</code>转换为数组并返回。</p></li></ul><h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>Java8 Stream在处理集合方面有着很大的优势：</p><ul><li>逻辑清晰</li><li>代码简洁</li><li>……</li></ul><p>但我刚接触，使用起来不是很熟悉，还需要再多练习。</p><h1 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h1><p>null</p>]]></content>
    
    
      
      
    <summary type="html">&lt;blockquote&gt;
&lt;p&gt;使用Java8 Stream来完成力扣 &lt;a href=&quot;https://leetcode.cn/problems/top-k-frequent-elements/&quot;&gt;347. 前 K 个高频元素&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h1</summary>
      
    
    
    
    <category term="数据结构与算法" scheme="https://guoyujian.github.io/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/"/>
    
    
    <category term="数据结构与算法" scheme="https://guoyujian.github.io/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/"/>
    
  </entry>
  
  <entry>
    <title>分库分表总结</title>
    <link href="https://guoyujian.github.io/2022/07/10/%E5%88%86%E5%BA%93%E5%88%86%E8%A1%A8%E6%80%BB%E7%BB%93/"/>
    <id>https://guoyujian.github.io/2022/07/10/%E5%88%86%E5%BA%93%E5%88%86%E8%A1%A8%E6%80%BB%E7%BB%93/</id>
    <published>2022-07-10T08:45:53.000Z</published>
    <updated>2022-07-10T08:45:53.096Z</updated>
    
    <content type="html"><![CDATA[<h1 id="为什么要分库分表"><a href="#为什么要分库分表" class="headerlink" title="为什么要分库分表"></a>为什么要分库分表</h1><p>移动互联网时代，海量的用户每天产生海量的数量，比如：用户表、订单表、交易流水表。</p><p>以支付宝用户为例，8亿；微信用户更是10亿。订单表更夸张，比如美团外卖，每天都是几千万的订单。淘宝的历史订单总量应该百亿，甚至千亿级别，这些海量数据远不是一张表能Hold住的。</p><p>事实上MySQL单表可以存储10亿级数据，只是这时候性能比较差，<strong>业界公认MySQL单表容量在1KW以下是最佳状态，因为这时它的BTREE索引树高在3~5之间。</strong></p><p>既然<strong>一张表无法搞定，那么就想办法将数据放到多个地方</strong>，目前比较普遍的方案有3个：</p><blockquote><ol><li>分区；</li><li>分库分表；</li><li>NoSQL/NewSQL；NoSQL比较具有代表性的是MongoDB，es。NewSQL比较具有代表性的是TiDB。</li></ol></blockquote><h2 id="数据库架构演变：从读写分离到分库分表"><a href="#数据库架构演变：从读写分离到分库分表" class="headerlink" title="数据库架构演变：从读写分离到分库分表"></a>数据库架构演变：从读写分离到分库分表</h2><p>刚开始我们只用单机数据库就够了，随后面对越来越多的请求，我们将数据库的<strong>写操作和读操作进行分离</strong>， 使用多个从库副本<strong>（Slaver Replication）</strong>负责读，使用主库<strong>（Master）</strong>负责写， 从库从主库同步更新数据，保持数据一致。架构上就是数据库主从同步。 从库可以水平扩展，所以更多的读请求不成问题。</p><p>但是当用户量级上来后，写请求越来越多，该怎么办？加一个Master是不能解决问题的， 因为数据要保存一致性，写操作需要2个master之间同步，相当于是重复了，而且更加复杂。</p><p>这时就需要用到<strong>分库分表（sharding），对写操作进行切分。</strong></p><h2 id="为什么不NoSQL-NewSQL"><a href="#为什么不NoSQL-NewSQL" class="headerlink" title="为什么不NoSQL/NewSQL?"></a>为什么不NoSQL/NewSQL?</h2><p>首先，为什么不选择第三种方案NoSQL/NewSQL，我认为主要是RDBMS有以下几个优点：</p><blockquote><p>RDBMS：关系型数据库管理系统（Relational Database Management System）</p><ul><li>RDBMS生态完善；</li><li>RDBMS绝对稳定；</li><li>RDBMS的事务特性；</li></ul></blockquote><p>NoSQL/NewSQL作为新生儿，在我们把可靠性当做首要考察对象时，它是无法与RDBMS相提并论的。RDBMS发展几十年，只要有软件的地方，它都是核心存储的首选。</p><p>目前绝大部分公司的核心数据都是：<strong>以RDBMS存储为主，NoSQL/NewSQL存储为辅</strong>！互联网公司又以MySQL为主，国企&amp;银行等不差钱的企业以Oracle/DB2为主！NoSQL/NewSQL宣传的无论多牛逼，就现在各大公司对它的定位，都是RDBMS的补充，而不是取而代之！</p><h2 id="为什么不分区"><a href="#为什么不分区" class="headerlink" title="为什么不分区?"></a>为什么不分区?</h2><p>我们再看分区表方案。了解这个方案之前，先了解它的原理：</p><p>分区：就是把一张表的数据分成N个区块，在逻辑上看最终只是一张表，但底层是由N个物理区块组成的，分区实现比较简单，数据库mysql、oracle等很容易就可支持。</p><blockquote><p><strong>分区表是由多个相关的底层表实现，这些底层表也是由句柄对象表示</strong>，所以我们也可以直接访问各个分区，存储引擎管理分区的各个底层表和管理普通表一样（所有的底层表都必须使用相同的存储引擎），<strong>分区表的索引只是在各个底层表上各自加上一个相同的索引</strong>，从存储引擎的角度来看，底层表和一个普通表没有任何不同，存储引擎也无须知道这是一个普通表还是一个分区表的一部分。</p></blockquote><p>一旦分表，一个库中的表会越来越多</p><blockquote><p>将整个数据库比作图书馆，一张表就是一本书。当要在一本书中查找某项内容时，如果不分章节，查找的效率将会下降。而同理，在数据库中就是分区。</p></blockquote><ul><li><strong>什么时候考虑使用分区</strong>：一张表的查询速度已经慢到影响使用的时候。</li></ul><blockquote><ol><li>sql经过优化</li><li>数据量大</li><li>表中的数据是分段的</li><li>对数据的操作往往只涉及一部分数据，而不是所有的数据</li></ol></blockquote><ul><li><p><strong>分区解决的问题</strong>：主要可以提升查询效率</p></li><li><p><strong>分区的实现方式</strong>（简单）：</p></li></ul><blockquote><p>mysql5 开始支持分区功能</p><p>CREATE TABLE sales (</p><p>id INT AUTO_INCREMENT,</p><p>amount DOUBLE NOT NULL,</p><p>order_day DATETIME NOT NULL,</p><p>PRIMARY KEY(id, order_day)</p><p>) ENGINE=Innodb</p><p>PARTITION BY RANGE(YEAR(order_day)) (</p><p>PARTITION p_2010 VALUES LESS THAN (2010),</p><p>PARTITION p_2011 VALUES LESS THAN (2011),</p><p>PARTITION p_2012 VALUES LESS THAN (2012),</p><p>PARTITION p_catchall VALUES LESS THAN MAXVALUE);</p></blockquote><ul><li>事实上，这个方案也不错，<strong>它对用户屏蔽了sharding的细节，即使查询条件没有sharding column，它也能正常工作（只是这时候性能一般）。</strong></li><li>不过它的缺点很明显：<strong>很多的资源都受到单机的限制，例如连接数，网络吞吐等</strong>！虽然每个分区可以独立存储，但是分区表的总入口还是一个MySQL示例。从而导致它的并发能力非常一般，远远达不到互联网高并发的要求！</li><li>至于网上提到的一些其他缺点比如：无法使用外键，不支持全文索引。我认为这都不算缺点，21世纪的项目如果还是使用外键和数据库的全文索引，我都懒得吐槽了！</li></ul><p>所以，<strong>如果使用分区表，你的业应该具备如下两个特点：</strong></p><blockquote><p>数据不是海量（分区数有限，存储能力就有限）；</p><p>并发能力要求不高；</p></blockquote><h1 id="分库分表概述"><a href="#分库分表概述" class="headerlink" title="分库分表概述"></a>分库分表概述</h1><p><img src="分库分表概述.jpg" alt="分库分表概述"></p><blockquote><p>读写分离：分散数据库读写操作压力</p><p>分库分表：分散存储压力</p></blockquote><h1 id="适用场景"><a href="#适用场景" class="headerlink" title="适用场景"></a>适用场景</h1><p><img src="适用场景.png" alt="适用场景"></p><ul><li>类似读写分离，分库分表也是确定没有其他优化空间之后才采取的优化方案。</li><li>那如果业务真的发展很快岂不是很快要进行分库分表了？那为何不一开始就设计好呢？</li></ul><p><strong>按照架构设计的“三原则”（简单原则，合适原则，演化原则）</strong>，简单分析一下：</p><blockquote><p>首先，<strong>这里的“如果”事实上发生的概率比较低</strong>，做10个业务有一个业务能活下去就很不错了，更何况快速发展，和中彩票的概率差不多。如果我们每个业务上来就按照淘宝、微信的规模去做架构设计，不但会累死自己，还会害死业务。</p><p>其次，<strong>如果业务真的发展很快，后面进行分库分表也不迟</strong>。因为业务发展好，相应的资源投入就会加大，可以投入更多的人和更多的钱，那业务分库带来的代码和业务复杂问题就可以通过加人来解决，成本问题也可以通过增加资金来解决。</p></blockquote><h1 id="分库分表的方式方法"><a href="#分库分表的方式方法" class="headerlink" title="分库分表的方式方法"></a>分库分表的方式方法</h1><blockquote><p>一般就是<strong>垂直切分和水平切分</strong>，这是一种结果集描述的切分方式，是物理空间上的切分。</p><p>我们从面临的问题，开始解决，阐述： 首先是用户请求量太大，我们就堆机器搞定（这不是本文重点）。</p><p>然后是单个库太大，这时我们要看是因为<strong>表多而导致数据多</strong>，还是因为<strong>单张表里面的数据多</strong>。</p><p>如果是因为表多而数据多，使用垂直切分，根据业务切分成不同的库。</p><p>如果是因为单张表的数据量太大，这时要用水平切分，即把表的数据按<strong>某种规则</strong>切分成多张表，甚至多个库上的多张表。 </p><p><strong>分库分表的顺序应该是先垂直分，后水平分</strong>。 因为垂直分更简单，更符合我们处理现实世界问题的方式。</p></blockquote><h2 id="垂直拆分"><a href="#垂直拆分" class="headerlink" title="垂直拆分"></a>垂直拆分</h2><h3 id="垂直分表"><a href="#垂直分表" class="headerlink" title="垂直分表"></a>垂直分表</h3><blockquote><p>也就是“大表拆小表”，基于列字段进行的。</p><p>一般是表中的字段较多，将不常用的， 数据较大，长度较长（比如text类型字段）的拆分到“扩展表“。</p><p>一般是针对那种几百列的大表，也避免查询时，数据量太大造成的“跨页”问题。</p></blockquote><h4 id="垂直分库"><a href="#垂直分库" class="headerlink" title="垂直分库"></a>垂直分库</h4><blockquote><p>垂直分库针对的是一个系统中的不同业务进行拆分，比如用户User一个库，商品Producet一个库，订单Order一个库。</p><p>切分后，要放在多个服务器上，而不是一个服务器上。</p><p>为什么？ 我们想象一下，一个购物网站对外提供服务，会有用户，商品，订单等的CRUD。没拆分之前， 全部都是落到单一的库上的，这会让数据库的<strong>单库处理能力成为瓶颈</strong>。</p><p>按垂直分库后，如果还是放在一个数据库服务器上， 随着用户量增大，这会让<strong>单个数据库的处理能力成为瓶颈</strong>，还有<strong>单个服务器的磁盘空间，内存，tps等非常吃紧</strong>。 所以我们要拆分到多个服务器上，这样上面的问题都解决了，以后也不会面对单机资源问题。</p><p>数据库业务层面的拆分，和服务的“治理”，“降级”机制类似，也能对不同业务的数据分别的进行管理，维护，监控，扩展等。</p><p>数据库往往最容易成为应用系统的瓶颈，<strong>而数据库本身属于“有状态”的，相对于Web和应用服务器来讲，是比较难实现“横向扩展”的。</strong></p><p>数据库的连接资源比较宝贵且单机处理能力也有限，在高并发场景下，垂直分库一定程度上能够突破IO、连接数及单机硬件资源的瓶颈。</p></blockquote><p><img src="业务分库1.jpg" alt="业务分库1"></p><p><img src="业务分库2.jpg" alt="业务分库2"></p><h2 id="水平拆分"><a href="#水平拆分" class="headerlink" title="水平拆分"></a>水平拆分</h2><h3 id="水平分表"><a href="#水平分表" class="headerlink" title="水平分表"></a>水平分表</h3><blockquote><p>针对数据量巨大的单张表（比如订单表），按照某种规则（<strong>RANGE，HASH取模</strong>等），切分到多张表里面去。 但是这些表还是在同一个库中，所以<strong>库级别的数据库操作还是有IO瓶颈</strong>。不建议采用。</p></blockquote><h3 id="水平分库分表"><a href="#水平分库分表" class="headerlink" title="水平分库分表"></a>水平分库分表</h3><blockquote><p>将单张表的数据切分到多个服务器上去，每个服务器具有相应的库与表，只是表中数据集合不同。 水平分库分表能够有效的缓解单机和单库的性能瓶颈和压力，突破IO、连接数、硬件资源等的瓶颈。</p></blockquote><h3 id="水平分库分表切分规则"><a href="#水平分库分表切分规则" class="headerlink" title="水平分库分表切分规则"></a>水平分库分表切分规则</h3><p><strong>RANGE</strong></p><blockquote><p>从0到10000一个表，10001到20000一个表；</p></blockquote><p><strong>HASH取模</strong></p><blockquote><p>一个商场系统，一般都是将用户，订单作为主表，然后将和它们相关的作为附表，这样不会造成跨库事务之类的问题。 <strong>取用户id，然后hash取模</strong>，分配到不同的数据库上。</p></blockquote><p><strong>地理区域</strong></p><blockquote><p>比如按照华东，华南，华北这样来区分业务，七牛云应该就是如此。</p></blockquote><p><strong>时间</strong></p><blockquote><p>按照时间切分，就是将6个月前，甚至一年前的数据切出去放到另外的一张表，因为随着时间流逝，这些表的数据 被查询的概率变小，所以没必要和“热数据”放在一起，这个也是“冷热数据分离”。</p></blockquote><h2 id="业务分表"><a href="#业务分表" class="headerlink" title="业务分表"></a>业务分表</h2><p><img src="业务分表.png" alt="业务分表"></p><p><img src="业务分表2.jpg" alt="业务分表2"></p><h1 id="分库分表后面临的问题"><a href="#分库分表后面临的问题" class="headerlink" title="分库分表后面临的问题"></a>分库分表后面临的问题</h1><h2 id="事务支持"><a href="#事务支持" class="headerlink" title="事务支持"></a>事务支持</h2><blockquote><p>分库分表后，就成了<strong>分布式事务</strong>了。</p><p>如果依赖数据库本身的分布式事务管理功能去执行事务，将付出高昂的性能代价； 如果由应用程序去协助控制，形成程序逻辑上的事务，又会造成编程方面的负担。</p></blockquote><h2 id="路由问题："><a href="#路由问题：" class="headerlink" title="路由问题："></a>路由问题：</h2><blockquote><p>垂直分表：增加表操作的次数</p><p>水平分表：<strong>路由问题</strong></p></blockquote><p> <img src="路由问题.jpg" alt="路由问题"></p><h2 id="数据库操作问题"><a href="#数据库操作问题" class="headerlink" title="数据库操作问题"></a>数据库操作问题</h2><h3 id="多库结果集合并（group-by，order-by）"><a href="#多库结果集合并（group-by，order-by）" class="headerlink" title="多库结果集合并（group by，order by）"></a>多库结果集合并（group by，order by）</h3><h3 id="跨库join"><a href="#跨库join" class="headerlink" title="跨库join"></a>跨库join</h3><blockquote><p>分库分表后表之间的关联操作将受到限制，我们无法join位于不同分库的表，也无法join分表粒度不同的表， 结果原本一次查询能够完成的业务，可能需要多次查询才能完成。</p><p>粗略的解决方法： 全局表：基础数据，所有库都拷贝一份。 字段冗余：这样有些字段就不用join去查询了。 系统层组装：分别查询出所有，然后组装起来，较复杂。</p></blockquote><p><img src="数据库操作问题.png" alt="数据库操作问题"></p><ul><li>解决方法</li></ul><p><img src="解决方法.png" alt="解决方法"></p><p>类似读写分离，具体实现也是“程序代码封装”和“中间件封装”，但具体实现复杂一些，因为还有要判断SQL中具体操作的表，具体操作（例如count、order by、group by等），根据具体操作做不同的处理。</p><h2 id="多分片（水平切分）返回结果合并（排序）"><a href="#多分片（水平切分）返回结果合并（排序）" class="headerlink" title="多分片（水平切分）返回结果合并（排序）"></a>多分片（水平切分）返回结果合并（排序）</h2><h3 id="①-Select-None-Aggregate-Function的有序记录合并排序"><a href="#①-Select-None-Aggregate-Function的有序记录合并排序" class="headerlink" title="① Select + None Aggregate Function的有序记录合并排序"></a>① Select + None Aggregate Function的有序记录合并排序</h3><blockquote><p>解决思路：对各分片返回的有序记录，进行排序去重合并。此处主要是编写排序去重合并算法。</p></blockquote><h3 id="②-Select-None-Aggregate-Function的无序记录合并"><a href="#②-Select-None-Aggregate-Function的无序记录合并" class="headerlink" title="② Select + None Aggregate Function的无序记录合并"></a>② Select + None Aggregate Function的无序记录合并</h3><blockquote><p>解决思路：对各分片返回的无序记录，进行去重合并。</p><ul><li>优点：实现比较简单。</li><li>缺点：数据量越大，字段越多，去重处理就会越耗时。</li></ul></blockquote><h3 id="③-Select-Aggregate-Function的记录合并（排序）Oracle常用聚合函数：Count、Max、Min、Avg、Sum。"><a href="#③-Select-Aggregate-Function的记录合并（排序）Oracle常用聚合函数：Count、Max、Min、Avg、Sum。" class="headerlink" title="③ Select + Aggregate Function的记录合并（排序）Oracle常用聚合函数：Count、Max、Min、Avg、Sum。"></a>③ Select + Aggregate Function的记录合并（排序）Oracle常用聚合函数：Count、Max、Min、Avg、Sum。</h3><blockquote><ul><li>AF：Max、Min<ul><li>思路：通过算法对各分片返回结果再求max、min值。</li></ul></li><li>AF：Avg、Sum、Count<ul><li>思路：分片间无重复记录或字段时，通过算法对各分片返回结果再求avg、sum、count值。分片间有重复记录或字段时，先对各分片记录去重合并，再通过算法求avg、sum、count值。</li></ul></li></ul></blockquote><p>比如：</p><blockquote><p>select count(*) from user</p><p>select count(deptno) from user;</p><p>select count(distinct deptno) from user;</p></blockquote><h2 id="多分片（水平切分）返回结果分页"><a href="#多分片（水平切分）返回结果分页" class="headerlink" title="多分片（水平切分）返回结果分页"></a>多分片（水平切分）返回结果分页</h2><blockquote><p>解决思路：合并各分片返回结果，逻辑分页。</p><ul><li>优点：  实现简单。</li><li>缺点：  数据量越大，缓存压力就越大。分片数据量越大，查询也会越慢。</li></ul></blockquote><h2 id="多分片（水平切分）查询有分组语法的合并"><a href="#多分片（水平切分）查询有分组语法的合并" class="headerlink" title="多分片（水平切分）查询有分组语法的合并"></a>多分片（水平切分）查询有分组语法的合并</h2><h3 id="①-Group-By-Having-None-Aggregate-Function时"><a href="#①-Group-By-Having-None-Aggregate-Function时" class="headerlink" title="① Group By Having + None Aggregate Function时"></a>① Group By Having + None Aggregate Function时</h3><blockquote><ul><li>Select + None Aggregate Function<ul><li>比如：select job user group by job;</li><li>思路：直接去重（排序）合并。</li></ul></li><li>Select + Aggregate Function<ul><li>比如：select max(sal),job user group by job;</li><li>思路：同Select + Aggregate Function的记录合并（排序）。</li></ul></li></ul></blockquote><h3 id="②-Group-By-Having-Aggregate-Function时"><a href="#②-Group-By-Having-Aggregate-Function时" class="headerlink" title="② Group By Having + Aggregate Function时"></a>② Group By Having + Aggregate Function时</h3><blockquote><p>解决思路：去掉having AF条件查询各分片，然后把数据放到一张表里。再用group by having 聚合函数查询。</p></blockquote><h2 id="分布式数据库架构—排序分组分页参考解决方案"><a href="#分布式数据库架构—排序分组分页参考解决方案" class="headerlink" title="分布式数据库架构—排序分组分页参考解决方案"></a>分布式数据库架构—排序分组分页参考解决方案</h2><blockquote><ul><li>解决方案1：Hadoop + Hive。<ul><li>思路：使用Hadoop HDFS来存储数据，通过Hdoop MapReduce完成数据计算，通过Hive HQL语言使用部分与RDBBS一样的表格查询特性和分布式存储计算特性。</li><li>优点：<ul><li>可以解决问题</li><li>具有并发处理能力</li><li>可以离线处理</li></ul></li><li>缺点： <ul><li>实时性不能保证</li><li>网络延迟会增加</li><li>异常捕获难度增加</li><li>Web应用起来比较复杂</li></ul></li></ul></li><li>解决方案2：总库集中查询。<ul><li>优点：<ul><li>可以解决问题</li><li>实现简单</li></ul></li><li>缺点：<ul><li>总库数据不能太大</li><li>并发压力大</li></ul></li></ul></li></ul></blockquote><h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h2><p>对于分布式数据库架构来说，排序、分页、分组一直就是一个比较复杂的问题。避免此问题需要好好地设计分库、分表策略。同时根据特定的场景来解决问题。也可以 充分利用海量数据存储（Hadoop-HDFS|Hive|HBse）、搜索引擎（Lucene|Solr）及分布式计算（MapReduce）等技术来 解决问题。</p><p>另外，也可以用NoSQL技术替代关系性数据库来解决问题，比如MogonDB/Redis。</p><h1 id="参考（COPY）资料"><a href="#参考（COPY）资料" class="headerlink" title="参考（COPY）资料"></a>参考（COPY）资料</h1><ol><li><a href="https://blog.csdn.net/fly910905/article/details/87090092">分库分表：应用场景、方式方法、面临问题</a></li></ol>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;为什么要分库分表&quot;&gt;&lt;a href=&quot;#为什么要分库分表&quot; class=&quot;headerlink&quot; title=&quot;为什么要分库分表&quot;&gt;&lt;/a&gt;为什么要分库分表&lt;/h1&gt;&lt;p&gt;移动互联网时代，海量的用户每天产生海量的数量，比如：用户表、订单表、交易流水表。&lt;/p&gt;
&lt;</summary>
      
    
    
    
    <category term="数据库" scheme="https://guoyujian.github.io/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"/>
    
    
    <category term="数据库" scheme="https://guoyujian.github.io/tags/%E6%95%B0%E6%8D%AE%E5%BA%93/"/>
    
  </entry>
  
</feed>
