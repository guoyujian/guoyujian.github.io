<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Gmet&#39;s Blog</title>
  
  <subtitle>Eureka!</subtitle>
  <link href="https://guoyujian.github.io/atom.xml" rel="self"/>
  
  <link href="https://guoyujian.github.io/"/>
  <updated>2023-02-25T06:44:32.469Z</updated>
  <id>https://guoyujian.github.io/</id>
  
  <author>
    <name>Met Guo</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>软件行业就业方向调研</title>
    <link href="https://guoyujian.github.io/2023/02/25/%E8%BD%AF%E4%BB%B6%E8%A1%8C%E4%B8%9A%E5%B0%B1%E4%B8%9A%E6%96%B9%E5%90%91%E8%B0%83%E7%A0%94/"/>
    <id>https://guoyujian.github.io/2023/02/25/%E8%BD%AF%E4%BB%B6%E8%A1%8C%E4%B8%9A%E5%B0%B1%E4%B8%9A%E6%96%B9%E5%90%91%E8%B0%83%E7%A0%94/</id>
    <published>2023-02-25T06:44:32.000Z</published>
    <updated>2023-02-25T06:44:32.469Z</updated>
    
    <content type="html"><![CDATA[<h1 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h1><p>本文调研了目前软件行业的就业方向。用于个人选择合适的就业岗位使用。主要调研了软件行业有哪些就业方向，针对这些方向又调研了</p><ol><li>职位岗位</li><li>目前需求：多还是少，为什么</li><li>前景如何：好还是坏，还是不明；从国内和国外两个角度；未来发展评估</li><li>企业：有哪些企业在做，龙头企业有哪些，从国内外两方面</li><li>细分领域：比如自然语言处理有对话领域blabla</li><li>特点：难度，特点</li><li>技术路线：整理该方向的技术路线图，对该方向的技术栈进行简单介绍</li><li>职业规划：方向职业的前进路线，初级-中级，blabla</li><li>是否利于出国：国外的需求是否更旺盛，是否更容易出国</li></ol><h1 id="调研方式"><a href="#调研方式" class="headerlink" title="调研方式"></a>调研方式</h1><p>本文汇总的软件行业就业方向的调研方式是，通过知乎、bilibili、谷歌、YouTube、微信公众号、GitHub等平台，使用以下几组关键词：【就业、职业】【程序员、码农、软件行业】【方向、前景、规划、赛道】，时间选取近两年，进行搜索，总结相关视频、文章、评论等内容。</p><p>先搜集整理可能的软件行业方向，再根据将这些软件行业方向作为关键词，二次搜索。</p><p>PS由于国内广告太多，很多话都不太可信。。</p><h1 id="开发方向-前端"><a href="#开发方向-前端" class="headerlink" title="开发方向-前端"></a>开发方向-前端</h1><h2 id="职位岗位"><a href="#职位岗位" class="headerlink" title="职位岗位"></a>职位岗位</h2><p>无</p><h2 id="需求"><a href="#需求" class="headerlink" title="需求"></a>需求</h2><p>和后端差不多。</p><h2 id="前景"><a href="#前景" class="headerlink" title="前景"></a>前景</h2><blockquote><p>Web这种还是挺有生命力的，但是，一切都是在变化，有可能若干年后一个技术变革，Web就丧失优势变得门可罗雀了，所以呢，各位同仁，要有心理准备。</p></blockquote><p>同质化</p><h2 id="企业"><a href="#企业" class="headerlink" title="企业"></a>企业</h2><p>不局限于互联网，但是互联网的技术更新，更有竞争力。</p><h2 id="应用领域"><a href="#应用领域" class="headerlink" title="应用领域"></a>应用领域</h2><p>主要是移动端、PC端的前端开发，还有游戏，后端（NodeJS）以及其他（桌面端）</p><h2 id="特点"><a href="#特点" class="headerlink" title="特点"></a>特点</h2><ol><li>越来越工具化、工程化</li><li>知识琐碎，门槛低</li><li>出效果快、激励周期短</li></ol><h2 id="技术路线"><a href="#技术路线" class="headerlink" title="技术路线"></a>技术路线</h2><p><img src="png-FrontEnd-by-StuQ.png" alt="png-FrontEnd-by-StuQ.png"></p><p>前端发展经历了三个阶段:</p><ol><li>原生html、js、css</li><li>封装库、jquery</li><li>组件化开发：node</li></ol><h2 id="职业规划"><a href="#职业规划" class="headerlink" title="职业规划"></a>职业规划</h2><div class="table-container"><table><thead><tr><th>职称</th><th>职责</th><th>年限(仅供参考)</th></tr></thead><tbody><tr><td>初级工程师</td><td>能在导师的帮助(详细设计, 关键点实现)下完成简单任务</td><td>0</td></tr><tr><td>中级工程师(开发)</td><td>能在导师的协助(概要设计, 关键点说明)下<strong>独立完成</strong>复杂任务</td><td>1+</td></tr><tr><td>高级工程师(研发)</td><td><strong>能高质量高效率地独立完成任务</strong></td><td>5+</td></tr><tr><td>资深/首席/专家/架构</td><td>全局观, 既有广度又有深度, 在某个专业领域有一席之地</td><td>8+</td></tr></tbody></table></div><h2 id="出国"><a href="#出国" class="headerlink" title="出国"></a>出国</h2><p>无</p><h1 id="开发方向-后端"><a href="#开发方向-后端" class="headerlink" title="开发方向-后端"></a>开发方向-后端</h1><h2 id="职位岗位-1"><a href="#职位岗位-1" class="headerlink" title="职位岗位"></a>职位岗位</h2><p>根据语言不同分为很多，例如，Java、Go等。</p><p>去某公司做后端开发，不一定对他们用到的语言和框架很熟练，会其中一部分就够了，很多都是在工作中学的。</p><h2 id="需求-1"><a href="#需求-1" class="headerlink" title="需求"></a>需求</h2><p>前后端差不多。</p><h2 id="前景-1"><a href="#前景-1" class="headerlink" title="前景"></a>前景</h2><p>随时间变化很大。目前不明。</p><h2 id="企业-1"><a href="#企业-1" class="headerlink" title="企业"></a>企业</h2><p>不局限于互联网，但是互联网的技术更新，更有竞争力。</p><h2 id="应用领域-1"><a href="#应用领域-1" class="headerlink" title="应用领域"></a>应用领域</h2><p>领域广泛。</p><h2 id="特点-1"><a href="#特点-1" class="headerlink" title="特点"></a>特点</h2><ol><li>注重功能性和稳定性</li><li>门类分支多：业务、算法、架构。。。</li><li>难以学深，容易瓶颈。这主要是小公司业务量不够&amp;大公司构建技术壁垒，小公司的后端开发容易和大公司拉开差距</li><li>后端的工作范畴很广：设计api、架构、数据库、业务逻辑、高可用等</li><li>非常考验《系统设计》的能力</li></ol><h2 id="RoadMap"><a href="#RoadMap" class="headerlink" title="RoadMap"></a>RoadMap</h2><p>以Java为例</p><p>图片来源：<a href="https://github.com/s4kibs4mi/java-developer-roadmap/blob/master/i18n/zh-CN/ReadMe-zh-CN.md">https://github.com/s4kibs4mi/java-developer-roadmap/blob/master/i18n/zh-CN/ReadMe-zh-CN.md</a></p><p><img src="java-developer-roadmap-zh-CN.png" alt="Roadmap"></p><h2 id="出国-1"><a href="#出国-1" class="headerlink" title="出国"></a>出国</h2><p>无</p><h1 id="小结：前端后端对比"><a href="#小结：前端后端对比" class="headerlink" title="小结：前端后端对比"></a>小结：前端后端对比</h1><h2 id="相同点"><a href="#相同点" class="headerlink" title="相同点"></a>相同点</h2><p>需求、工资、前景都差不多</p><p>职业发展规划差不多</p><div class="table-container"><table><thead><tr><th>职称</th><th>职责</th><th>年限(仅供参考)</th></tr></thead><tbody><tr><td>初级工程师</td><td>能在导师的帮助(详细设计, 关键点实现)下完成简单任务</td><td>0</td></tr><tr><td>中级工程师(开发)</td><td>能在导师的协助(概要设计, 关键点说明)下<strong>独立完成</strong>复杂任务</td><td>1+</td></tr><tr><td>高级工程师(研发)</td><td><strong>能高质量高效率地独立完成任务</strong></td><td>5+</td></tr><tr><td>资深/首席/专家/架构</td><td>全局观, 既有广度又有深度, 在某个专业领域有一席之地</td><td>8+</td></tr></tbody></table></div><h2 id="不同点"><a href="#不同点" class="headerlink" title="不同点"></a>不同点</h2><blockquote><p><strong>后端要学的技术太多了</strong>，而前端相对来说就少多了，压力自然少很多，而且后端也需要学一些前端技术，有的公司就有这样的需求，考虑到地中海干涸问题，肯定选前端，而且对于后面的发展，比如<strong>转型走管理架构什么的，前端基本没有优势</strong>。但是由于<strong>前端技术难度和学习成本不是太大</strong>，而且随着经验积累，即便到了四十多岁也可以继续开发，而后端再继续撸代码就难多了，因为本来前端逻辑代码不是太多，即便是使用node做前后端分离，前端复杂逻辑也不是太多，而且前端现在有很多脚手架和插件，都可以直接拿来用。而后端就不一样了，性能，并发，算法，各种优化，服务器问题等等，都是后端考虑的，虽然随着各种技术的出现，现在后端也开发没有以前费劲了，但是要知道底层原理和源码你还是要去翻，各种问题还是主要在后端这解决的。</p></blockquote><p>评论：</p><p>前端四十多岁也可以继续开发，存疑。随着前端技术的发展，也可能技术难度up，四十多岁不能继续开发。</p><h2 id="怎么选"><a href="#怎么选" class="headerlink" title="怎么选"></a>怎么选</h2><ul><li>兴趣、现状：你了解哪个多一点就选哪个</li><li>职业背景</li><li>年龄</li></ul><h1 id="开发方向-全栈"><a href="#开发方向-全栈" class="headerlink" title="开发方向-全栈"></a>开发方向-全栈</h1><h2 id="RoadMap-1"><a href="#RoadMap-1" class="headerlink" title="RoadMap"></a>RoadMap</h2><p>来源：<a href="https://github.com/easychen/stack-roadmap">https://github.com/easychen/stack-roadmap</a></p><p><img src="方糖全栈路线图.jpg" alt="img"></p><h2 id="特点-2"><a href="#特点-2" class="headerlink" title="特点"></a>特点</h2><p>最大特点就是，<strong>难度高</strong></p><p>特点之二是，美国全栈岗位多，后面再根据个人细分领域。<strong>可能利于出国</strong>。</p><p><strong>不适合应届生</strong></p><p>依据是2019年stack-overflow的调查问卷，程序员岗位分布：</p><p><img src="image-20230223000029-erjot3z.png" alt="image"></p><h1 id="QA"><a href="#QA" class="headerlink" title="QA"></a>QA</h1><p>翻译过来叫质量保证，在国外主要指的是测试，tester。在国内还有另一种不同于测试的质量保证。这点需要注意，招聘时的QA究竟指的是质量保证还是测试工程师。</p><h2 id="特点-3"><a href="#特点-3" class="headerlink" title="特点"></a>特点</h2><ol><li>分成两种，手工测试和自动化测试。</li><li>自动化测试需要写代码，需要懂一两门自动化测试语言和框架。</li><li>手工测试，对开发能力和写代码能力没有要求，但是需要有开发的经验。这类岗位基本被淘汰掉了。</li></ol><h2 id="RoadMap-2"><a href="#RoadMap-2" class="headerlink" title="RoadMap"></a>RoadMap</h2><p><a href="https://github.com/yangzige/qa-roadmap/blob/main/roadmap/%E6%B5%8B%E8%AF%95%E5%BC%80%E5%8F%91%E5%AD%A6%E4%B9%A0%E8%B7%AF%E7%BA%BF.md">https://github.com/yangzige/qa-roadmap/blob/main/roadmap/%E6%B5%8B%E8%AF%95%E5%BC%80%E5%8F%91%E5%AD%A6%E4%B9%A0%E8%B7%AF%E7%BA%BF.md</a></p><h1 id="人工智能-CV方向"><a href="#人工智能-CV方向" class="headerlink" title="人工智能-CV方向"></a>人工智能-CV方向</h1><p>2015-2020是黄金期，找工作比较容易。2020以后赚钱的业务挖掘的差不多了，<strong>对学历和论文的要求高</strong>。</p><p>CV岗位比开发岗<strong>少很多</strong>。</p><h2 id="前景-2"><a href="#前景-2" class="headerlink" title="前景"></a>前景</h2><p>今后会走向“平衡”。人话就是不温不火</p><h2 id="应用领域-2"><a href="#应用领域-2" class="headerlink" title="应用领域"></a>应用领域</h2><p><img src="640.png" alt="图片"></p><ul><li>自动驾驶领域：比较火</li><li>工业视觉领域：应用潜力大</li><li>智慧医疗：有前景但比较困难</li></ul><h2 id="RoadMap-3"><a href="#RoadMap-3" class="headerlink" title="RoadMap"></a>RoadMap</h2><p>没找到比较好的。基本就是Python、PyTorch、数字图象处理，深度学习那一套。。</p><h1 id="人工智能-NLP方向"><a href="#人工智能-NLP方向" class="headerlink" title="人工智能-NLP方向"></a>人工智能-NLP方向</h1><blockquote><p>自然语言处理(<em>NLP</em>)是人工智能技术的王冠，它推动着当代科技的持续发展和重大突破，并越来越多地应用于各行各业；它有着十分重要的实用价值，也有着革命性的理论</p></blockquote><h2 id="前景-3"><a href="#前景-3" class="headerlink" title="前景"></a>前景</h2><p>前景广阔。之前比较卷，现在因为ChatGPT的出现，续了一口气</p><h2 id="应用领域-3"><a href="#应用领域-3" class="headerlink" title="应用领域"></a>应用领域</h2><p>对话、问答。</p><h2 id="RoadMap-4"><a href="#RoadMap-4" class="headerlink" title="RoadMap"></a>RoadMap</h2><p><a href="https://github.com/graykode/nlp-roadmap">https://github.com/graykode/nlp-roadmap</a></p><h1 id="人工智能-其他"><a href="#人工智能-其他" class="headerlink" title="人工智能-其他"></a>人工智能-其他</h1><p>人工智能还包括其他方向，例如推荐算法。</p><h1 id="大数据"><a href="#大数据" class="headerlink" title="大数据"></a>大数据</h1><h2 id="职位岗位-2"><a href="#职位岗位-2" class="headerlink" title="职位岗位"></a>职位岗位</h2><p>大数据是一个比较笼统的方向，既可以做大数据开发方向，也可以做数据挖掘等算法方向，也有商业智能BI。。。</p><p>具体方向有以下：</p><ol><li>ETL/数仓工程师：负责数仓建设，偏脚本开发以及SQL开发。</li><li>大数据开发工程师：负责数据计算，偏离线。实时代码开发。</li><li>大数据分析师：负责数据挖掘分析、偏业务分析/SQL</li><li>大数据算法工程师：算法建模、基于人工智能建模。往往是和推荐算法相关。</li><li>大数据BI工程师：偏报表和SQL开发。</li></ol><p>不同方向的学习路线和技能都有所不同。</p><h2 id="需求-2"><a href="#需求-2" class="headerlink" title="需求"></a>需求</h2><p>没有Java那么卷，但是岗位也没有那么多。</p><h2 id="前景-4"><a href="#前景-4" class="headerlink" title="前景"></a>前景</h2><h2 id="特点-4"><a href="#特点-4" class="headerlink" title="特点"></a>特点</h2><ol><li>大数据开发需要学习的组件非常多。也比较难。</li><li>ETL/数仓的工作比较基础。</li><li>大数据分析和算法主要偏算法相关。</li></ol><h2 id="RoadMap-5"><a href="#RoadMap-5" class="headerlink" title="RoadMap."></a>RoadMap.</h2><p>学习可以从SQL入手。</p><p><a href="https://github.com/TeamStuQ/skill-map/blob/master/data/map-BigDataEngineer.md">https://github.com/TeamStuQ/skill-map/blob/master/data/map-BigDataEngineer.md</a></p><h2 id="一篇有用的文章"><a href="#一篇有用的文章" class="headerlink" title="一篇有用的文章"></a>一篇有用的文章</h2><p>想学大数据，大数据开发以后的前景怎么样，家里人对这方面了解不深，不太同意转行？ - 云原生研习社的回答 - 知乎 <a href="https://www.zhihu.com/question/509912345/answer/2664371834">https://www.zhihu.com/question/509912345/answer/2664371834</a></p><h1 id="UX-UI"><a href="#UX-UI" class="headerlink" title="UX/UI"></a>UX/UI</h1><p>UX是User Experience（用户体验）的缩写，指的是围绕用户，以用户在使用过程中的主观感受为出发点，力求更简单高效地满足用户需求。 UX设计师的职责简单来说就是为用户设计友好的产品体验，他更关注产品的易用性、实用性、高效性及价值体现。</p><p>UI的全名是User Interface，中文是「使用者介面」的意思。介面指的是APP、網頁等，可以與使用者互動的媒介。如同字面上的意思，UI著重的是使用者介面的呈現，如：視覺美感、設計美學、便利性、風格呈現，細節更包含了字型、字體大小、顏色、標誌、按鍵、動畫效果等。UI的呈現，會影響到使用者的使用感受，以及順暢性。</p><p>其他略。</p><h1 id="数据采集"><a href="#数据采集" class="headerlink" title="数据采集"></a>数据采集</h1><p>爬虫方向。不想说。。</p><h1 id="数据挖掘"><a href="#数据挖掘" class="headerlink" title="数据挖掘"></a>数据挖掘</h1><blockquote><p>广义上说，任何从数据库中挖掘信息的过程都叫做数据挖掘。从这点看来，数据挖掘就是BI（商业智能）。但从技术术语上说，数据挖掘(Data Mining)特指的是：源数据经过清洗和转换等成为适合于挖掘的数据集。数据挖掘在这种具有固定形式的数据集上完成知识的提炼，最后以合适的知识模式用于进一步分析决策工作。从这种狭义的观点上，我们可以定义：数据挖掘是从特定形式的数据集中提炼知识的过程。数据挖掘往往针对特定的数据、特定的问题，选择一种或者多种挖掘算法，找到数据下面隐藏的规律，这些规律往往被用来预测、支持决策。</p></blockquote><p>可以放到大数据的数据挖掘的相关岗位来看。</p><h2 id="应用领域-4"><a href="#应用领域-4" class="headerlink" title="应用领域"></a>应用领域</h2><p>情报检索、数据分析、模式识别</p><h1 id="存储"><a href="#存储" class="headerlink" title="存储"></a>存储</h1><p>可以放到大数据的数据存储的相关岗位来看。</p><p>主要研究各种数据库存储。</p><h2 id="有用的文章"><a href="#有用的文章" class="headerlink" title="有用的文章"></a>有用的文章</h2><p><a href="https://github.com/wx-chevalier/Database-Series">https://github.com/wx-chevalier/Database-Series</a></p><h1 id="区块链"><a href="#区块链" class="headerlink" title="区块链"></a>区块链</h1><h2 id="前景-5"><a href="#前景-5" class="headerlink" title="前景"></a>前景</h2><p>前景很好。</p><h2 id="有用的文章-1"><a href="#有用的文章-1" class="headerlink" title="有用的文章"></a>有用的文章</h2><p><a href="https://github.com/LiuBoyu/blockchain">https://github.com/LiuBoyu/blockchain</a></p><p><a href="https://github.com/xianfeng92/Love-Ethereum">https://github.com/xianfeng92/Love-Ethereum</a></p><h2 id="应用领域-5"><a href="#应用领域-5" class="headerlink" title="应用领域"></a>应用领域</h2><p>区块链+物联网</p><h1 id="安全"><a href="#安全" class="headerlink" title="安全"></a>安全</h1><p>略，不感兴趣。但是和区块链息息相关。</p><h1 id="游戏开发"><a href="#游戏开发" class="headerlink" title="游戏开发"></a>游戏开发</h1><h1 id="VR"><a href="#VR" class="headerlink" title="VR"></a>VR</h1><h1 id="其他"><a href="#其他" class="headerlink" title="其他"></a>其他</h1><h2 id="素质要求"><a href="#素质要求" class="headerlink" title="素质要求"></a>素质要求</h2><p>这部分是除了细分方向之外的，对软件行业从业者的共同要求：</p><ol><li>涉猎其它领域的专业知识，丰富自己的知识体系、提高自己的综合素质，争取在自己的专业领域有所积累，然后再做扩展。<strong>不要把自己的知识体系局限于自己的岗位上</strong></li><li><strong>终身学习</strong></li><li>技术观：不要排斥其他技术</li><li>产品观：有产品常识</li><li>数据观：对数据敏感</li><li>知其然知其所以然，会使用轮子，也要研究轮子。</li></ol><h2 id="美国硕士博士CS专业分类"><a href="#美国硕士博士CS专业分类" class="headerlink" title="美国硕士博士CS专业分类"></a>美国硕士博士CS专业分类</h2><p><img src="image-20230223090322289.png" alt="image-20230223090322289"></p><p><img src="image-20230223090346670.png" alt="image-20230223090346670"></p><h2 id="计算机科学的主要分支"><a href="#计算机科学的主要分支" class="headerlink" title="计算机科学的主要分支"></a>计算机科学的主要分支</h2><p><img src="815c0d5aed01530b7cf11d0c9061ec70.png" alt="815c0d5aed01530b7cf11d0c9061ec70.png"></p><h1 id="备注"><a href="#备注" class="headerlink" title="备注"></a>备注</h1><p>这篇文章非常浅薄，没有仔细分析各个行业的现状和情况。只是罗列了一些资料。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;摘要&quot;&gt;&lt;a href=&quot;#摘要&quot; class=&quot;headerlink&quot; title=&quot;摘要&quot;&gt;&lt;/a&gt;摘要&lt;/h1&gt;&lt;p&gt;本文调研了目前软件行业的就业方向。用于个人选择合适的就业岗位使用。主要调研了软件行业有哪些就业方向，针对这些方向又调研了&lt;/p&gt;
&lt;ol&gt;
</summary>
      
    
    
    
    <category term="软件行业" scheme="https://guoyujian.github.io/categories/%E8%BD%AF%E4%BB%B6%E8%A1%8C%E4%B8%9A/"/>
    
    
  </entry>
  
  <entry>
    <title>Visual Attention Network</title>
    <link href="https://guoyujian.github.io/2023/02/04/Visual-Attention-Network/"/>
    <id>https://guoyujian.github.io/2023/02/04/Visual-Attention-Network/</id>
    <published>2023-02-04T03:31:37.000Z</published>
    <updated>2023-02-04T03:55:16.229Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>本文是论文《Visual Attention Network》的学习笔记</p><p>我在该模型上执行一个分类任务，发现该模型的效果要优于我实验的其他模型（包括resnet50、densenet121、efficientNet-b0、swin-tiny）</p><p>所以在此记录一下，笔记大多是抄的，出处在Refs上表明，如有侵权请联系我。</p><p><a href="https://arxiv.org/abs/2202.09741">论文地址</a>   <a href="https://github.com/Visual-Attention-Network">代码地址</a></p></blockquote><p>‍</p><h1 id="基础"><a href="#基础" class="headerlink" title="基础"></a>基础</h1><h2 id="自注意力机制"><a href="#自注意力机制" class="headerlink" title="自注意力机制"></a>自注意力机制</h2><p><a href="https://zhuanlan.zhihu.com/p/265108616">Attention注意力机制与self-attention自注意力机制</a></p><p><a href="https://www.jiqizhixin.com/articles/100902">什么是自注意力机制？</a></p><h2 id="空间相关性和通道相关性1"><a href="#空间相关性和通道相关性1" class="headerlink" title="空间相关性和通道相关性1"></a>空间相关性和通道相关性<sup><a href="#fn_1" id="reffn_1">1</a></sup></h2><p>从维度的角度看，卷积核可以看成是一个空间维(宽和高)和通道维的组合，而<strong>卷积操作则可以视为空间相关性和通道相关性的联合映射</strong>。从inception的1x1卷积来看，<strong>卷积中的空间相关性和通道相关性是可以解耦的，将它们分开进行映射，可能会达到更好的效果。</strong></p><p>深度可分离卷积是在1x1卷积基础上的一种创新。主要包括两个部分：深度卷积和1x1卷积。深度卷积的目的在于对输入的每一个通道都单独使用一个卷积核对其进行卷积，也就是通道分离后再组合。1x1卷积的目的则在于加强深度。下面以一个例子来看一下深度可分离卷积。</p><p>假设我们用128个$3 \times3 \times3$的滤波器对一个 $7 \times7 \times3$的输入进行卷积，可得到$5 \times5 \times128$的输出,其计算量为$5 \times5 \times128 \times3 \times3 \times3=86400$。如下图所示：</p><p><img src="image-20230204110644-zz7yeyj.png" alt="image">​</p><p>现在看如何使用深度可分离卷积来实现同样的结果。深度可分离卷积的第一步是深度卷积。这里的深度卷积，就是分别用3个$3 \times3 \times1$的滤波器对输入的3个通道分别做卷积，也就是说要做3次卷积，每次卷积都有一个$5 \times5 \times1$的输出，组合在一起便是$5 \times5 \times3$的输出。现在为了拓展深度达到128，我们需要执行深度可分离卷积的第二步：1x1卷积。现在我们用128个$1 \times1 \times3$的滤波器对$5 \times5 \times3$进行卷积，就可以得到$5 \times5 \times128$的输出。完整过程如下图所示：</p><p><img src="image-20230204111234-3ia5cu3.png" alt="image">​</p><p>那么我们来看一下深度可分离卷积的计算量如何。第一步深度卷积的计算量：$5 \times5 \times1 \times3 \times3 \times1 \times3=675$。第二步1x1卷积的计算量：$5 \times5 \times128 \times1 \times1 \times3=9600$，合计计算量为10275次。可见，相同的卷积计算输出，深度可分离卷积要比常规卷积节省12倍的计算成本。</p><blockquote><p>典型的应用深度可分离卷积的网络模型包括xception和mobilenet等。本质上而言，xception就是应用了深度可分离卷积的inception网络。</p></blockquote><h1 id="正文2"><a href="#正文2" class="headerlink" title="正文2"></a>正文<sup><a href="#fn_2" id="reffn_2">2</a></sup></h1><h2 id="动机"><a href="#动机" class="headerlink" title="动机"></a>动机</h2><p>图像的二维性质给在计算机视觉中应用自注意力带来了三个挑战：</p><ol><li>将图像处理为一维序列，忽略了其二维结构。</li><li>二次复杂度对于高分辨率的图像来说太贵了。</li><li>它只捕捉了空间适应性，而忽略了通道适应性</li></ol><p>在本文中，作者提出了一种新的大核注意(LKA)模块，以使自注意的自适应和长程相关，同时避免了上述问题。作者进一步介绍了一种基于LKA的新的神经网络，即视觉注意网络(VAN)。VAN虽然非常简单和高效，但在包括图像分类、目标检测、语义分割、实例分割等广泛的实验中，它以很大的优势优于最先进的transfomer和卷积神经网络。</p><h2 id="方法"><a href="#方法" class="headerlink" title="方法"></a>方法</h2><h3 id="LCK"><a href="#LCK" class="headerlink" title="LCK"></a>LCK</h3><p>卷积神经网络(CNNs)利用局部上下文信息和平移不变性，大大提高了神经网络的效率。自AlexNet以来，cnn迅速成为计算机视觉的主要主流框架。为了进一步提高效率，研究人员投入了大量的精力，使cnn成为更深的和更轻的。作者的工作与MobileNet有相似之处，MobileNet将标准卷积解耦为两部分，即深度卷积和逐点卷积(也就是1×1Conv)。作者的方法将卷积分解为三个部分：深度卷积、深度空洞卷积和逐点卷积。得益于这种分解，作者的方法更适合于有效地分解大的核卷积。作者还在该方法中引入了注意机制来获得自适应特性。</p><p><img src="v2-467f001629900492069a79a14d2dc757_720w.webp" alt="img"></p><p>彩色网格表示卷积核的位置，黄色网格表示中心点。从图中可以看出，13×13卷积分解为5×5深度卷积，5×5深度空洞卷积，膨胀速率3和1×1卷积</p><p><img src="v2-d22b7728ed41dd3491530ad8a94fbe19_720w.webp" alt="img"></p><figure class="highlight text"><table><tr><td class="code"><pre><span class="line">class AttentionModule(nn.Module):</span><br><span class="line">    def __init__(self, dim):</span><br><span class="line">        super().__init__()</span><br><span class="line">        self.conv0 = nn.Conv2d(dim, dim, 5, padding=2, groups=dim)#深度卷积</span><br><span class="line">        self.conv_spatial = nn.Conv2d(dim, dim, 7, stride=1, padding=9, groups=dim, dilation=3)#深度空洞卷积</span><br><span class="line">        self.conv1 = nn.Conv2d(dim, dim, 1)#逐点卷积</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    def forward(self, x):</span><br><span class="line">        u = x.clone()        </span><br><span class="line">        attn = self.conv0(x)</span><br><span class="line">        attn = self.conv_spatial(attn)</span><br><span class="line">        attn = self.conv1(attn)</span><br><span class="line"></span><br><span class="line">        return u * attn   #注意力操作</span><br><span class="line">     </span><br><span class="line">class SpatialAttention(nn.Module):</span><br><span class="line">    def __init__(self, d_model):</span><br><span class="line">        super().__init__()</span><br><span class="line"></span><br><span class="line">        self.proj_1 = nn.Conv2d(d_model, d_model, 1)</span><br><span class="line">        self.activation = nn.GELU()</span><br><span class="line">        self.spatial_gating_unit = AttentionModule(d_model)  #注意力操作</span><br><span class="line">        self.proj_2 = nn.Conv2d(d_model, d_model, 1)</span><br><span class="line"></span><br><span class="line">    def forward(self, x):</span><br><span class="line">        shorcut = x.clone()</span><br><span class="line">        x = self.proj_1(x)</span><br><span class="line">        x = self.activation(x)</span><br><span class="line">        x = self.spatial_gating_unit(x)  #注意力操作</span><br><span class="line">        x = self.proj_2(x)</span><br><span class="line">        x = x + shorcut   #残差连接</span><br><span class="line">        return x</span><br><span class="line"></span><br><span class="line">class Block(nn.Module):</span><br><span class="line">    def __init__(self, dim, mlp_ratio=4., drop=0.,drop_path=0., act_layer=nn.GELU):</span><br><span class="line">        super().__init__()</span><br><span class="line">        self.norm1 = nn.BatchNorm2d(dim)</span><br><span class="line">        self.attn = SpatialAttention(dim)</span><br><span class="line">        self.drop_path = DropPath(drop_path) if drop_path &gt; 0. else nn.Identity()</span><br><span class="line"></span><br><span class="line">        self.norm2 = nn.BatchNorm2d(dim)</span><br><span class="line">        mlp_hidden_dim = int(dim * mlp_ratio)</span><br><span class="line">        self.mlp = Mlp(in_features=dim, hidden_features=mlp_hidden_dim, act_layer=act_layer, drop=drop)</span><br><span class="line">        layer_scale_init_value = 1e-2            </span><br><span class="line">        self.layer_scale_1 = nn.Parameter(</span><br><span class="line">            layer_scale_init_value * torch.ones((dim)), requires_grad=True)</span><br><span class="line">        self.layer_scale_2 = nn.Parameter(</span><br><span class="line">            layer_scale_init_value * torch.ones((dim)), requires_grad=True)</span><br><span class="line"></span><br><span class="line">        self.apply(self._init_weights)</span><br><span class="line"></span><br><span class="line">    def _init_weights(self, m):</span><br><span class="line">        if isinstance(m, nn.Linear):</span><br><span class="line">            trunc_normal_(m.weight, std=.02)</span><br><span class="line">            if isinstance(m, nn.Linear) and m.bias is not None:</span><br><span class="line">                nn.init.constant_(m.bias, 0)</span><br><span class="line">        elif isinstance(m, nn.LayerNorm):</span><br><span class="line">            nn.init.constant_(m.bias, 0)</span><br><span class="line">            nn.init.constant_(m.weight, 1.0)</span><br><span class="line">        elif isinstance(m, nn.Conv2d):</span><br><span class="line">            fan_out = m.kernel_size[0] * m.kernel_size[1] * m.out_channels</span><br><span class="line">            fan_out //= m.groups</span><br><span class="line">            m.weight.data.normal_(0, math.sqrt(2.0 / fan_out))</span><br><span class="line">            if m.bias is not None:</span><br><span class="line">                m.bias.data.zero_()</span><br><span class="line"></span><br><span class="line">    def forward(self, x):</span><br><span class="line">        x = x + self.drop_path(self.layer_scale_1.unsqueeze(-1).unsqueeze(-1) * self.attn(self.norm1(x)))#drop_path分支中，每个batch有概率使样本在self.attn或者mlp不会”执行“，会以0直接传递。</span><br><span class="line">        x = x + self.drop_path(self.layer_scale_2.unsqueeze(-1).unsqueeze(-1) * self.mlp(self.norm2(x)))</span><br><span class="line">        return </span><br></pre></td></tr></table></figure><p>作者提出对大核卷积操作进行分解来捕获长程关系。大核卷积可分为三个部分：空间局部卷积（深度卷积）、空间远程卷积（深度空洞卷积）和通道卷积（1×1卷积）。所以，可以将K×K卷积分解为K/d×K/d的深度空洞卷积，(2d−1)×(2d−1)的深度卷积和1×1卷积。通过上述分解，可以用轻微的计算代价和参数来捕获长程关系。在得到长程关系后，可以估计一个点的重要性并生成注意力图。</p><p><img src="v2-f2a083b057051de4ae3a87fd77138a8e_720w.webp" alt="img"></p><p><img src="v2-6109ccc0466efee70bf7ac2324513a09_720w.webp" alt="img"></p><p>作者提出的LKA结合了卷积和自注意力的优点。它考虑了局部上下文信息、大的感受野和动态过程。此外，LKA不仅实现了空间维度的自适应性，而且还实现了通道维度的自适应性。值得注意的是，在深度神经网络中，不同的通道往往代表不同的对象，而通道维度的适应性对视觉任务也很重要。</p><h3 id="VAN"><a href="#VAN" class="headerlink" title="VAN"></a>VAN</h3><p>VAN具有简单的层次结构，即输出空间分辨率降低的四个阶段序列，分别为H/4×W/4、H/8×W/8、H/16×W/16和H/32×W/32。H和W是输入图像的高度和宽度。随着分辨率的降低，输出通道的数量也在不断增加。输出通道Ci的变化如下表所示。 首先对输入值进行下采样，并使用步幅数来控制下采样率。下采样后，一个stage中的所有层保持相同的输出大小，即空间分辨率和通道数量。然后，批量归一化、GELU激活函数、大核注意和卷积前馈网络依次堆叠，提取特征。最后，在每个阶段结束时应用一个层归一化。根据参数和计算成本，设计了 VAN-Tiny, VAN-Small, VAN-Base and VAN-Large四种结构。</p><p><img src="v2-9c29743630133af223ffb0b9d3c592f0_720w.webp" alt="img"></p><p><img src="v2-f3d5e05ccc5b5d1691c26fc3d8daafcd_720w.webp" alt="img"></p><p>对21×21卷积的不同方式参数的比较。X，Y和our分别提供了标准卷积，mobilenet]和van的分解。输入和输出具有相同大小的H×W×C</p><p><img src="v2-f39da3202b78c90cd02669ff5039e8a9_720w.webp" alt="img"></p><p>默认情况下，本文的LKA采用5×5深度卷积，7×7深度卷积与膨胀率为3的空洞卷积和1×1卷积来近似21×21卷积。在这种设置下，VAN可以有效地获取局部信息和长程联系。作者分别使用7×7和3×3步幅卷积进行4×和2×的降采样。</p><h2 id="实验"><a href="#实验" class="headerlink" title="实验"></a>实验</h2><p>作者在ImageNet-1K图像分类数据集、COCO目标检测数据集和ADE20K语义分割数据集上进行了定量实验。此外，作者通过在ImageNet验证集上使用Grad-CAM来可视化类激活映射(CAM)。</p><h3 id="图像分类"><a href="#图像分类" class="headerlink" title="图像分类"></a>图像分类</h3><p><img src="https://pic2.zhimg.com/80/v2-2fefbe89e8e7da997c3683528fbb2535_720w.webp" alt="img"></p><p>VAN与其他mlp、cnn和ViTs的比较。VAN优于其他参数相似，计算成本相似的cnn(ResNet[29]，ResNeXt[90]，ConvNeXt[53]等)，ViTs(DeiT[74]、PVT[83]、Swin-Transformer[52]等)和MLPs(MLP-Mixer[72]，ResMLP[73]，gMLP[46]等)。作者在每个类别中选择了一个具有代表性的网络进行讨论。ConvNeXt[53]是一种特殊的CNN，它吸收了vit的一些优势，如大的感受野（7×7卷积）和先进的训练策略(300个epoch、数据增强等)。VAN和ConvNeXt[53]相比，VAN-base比CoNvNeXt-t多出0.7%(82.8%vs.82.1%)，因为VAN具有更大的感受域和自适应能力。Swin-Transformer是一种著名的ViT变体，采用局部注意力和移动窗口的方式。由于VAN对二维结构信息非常友好，具有较大的感受野，并在通道维度上实现了自适应性，VAN-Base超过Swin-T1.5%(82.8%vs.81.3%)。对于MLPs，选择gMLP[46]。VAN-Base超过gMLP-S[46]3.2%(82.8%vs.79.6%)。也可以看出，在小型模型上面VAN的表现更加出色。</p><h3 id="目标检测"><a href="#目标检测" class="headerlink" title="目标检测"></a>目标检测</h3><p><img src="v2-c04b7aef7af9212da50e947198ea0179_720w.webp" alt="img"></p><p><img src="v2-ac6fd9136c34fa6ebfce940f20b6a318_720w.webp" alt="img"></p><p><img src="v2-f0a76550ee33afe78ff4d4458f544c25_720w.webp" alt="img"></p><h3 id="语义分割"><a href="#语义分割" class="headerlink" title="语义分割"></a>语义分割</h3><p><img src="v2-5675289d453da40b8f33f28c1966aa44_720w.webp" alt="img"></p><h3 id="消融实验"><a href="#消融实验" class="headerlink" title="消融实验"></a>消融实验</h3><p><img src="v2-1f9970a60d196d053e6433e7bbcca814_720w.webp" alt="img"></p><p>DW-D-Conv提供了深度空洞卷积，这在捕获LKA中的长程依赖性中发挥了作用。</p><p>DW-Conv可以利用图像的局部上下文信息。</p><p>注意力机制的引入可以看作是使网络实现了自适应特性。受益于此，VAN-Tiny实现了约1.1%（74.3%对75.4%）的改善。</p><p>1×1Conv捕获了通道维度中的关系。结合注意机制，引入了通道维度的自适应性。提高了0.8%(74.1%vs.75.4%)，证明了通道维度自适应性的必要性。</p><h3 id="可视化"><a href="#可视化" class="headerlink" title="可视化"></a>可视化</h3><p><img src="v2-84a72be357178fade018043de0213190_720w.webp" alt="img"></p><p>可视化结果。所有的图像都来自于ImageNet验证集中的不同类别。CAM采用VAN-Base模型和Grad-CAM产生。左：原始图像，右：类激活图</p><p>结果显示，VAN-Base可以清晰地聚焦于目标对象。因此，可视化直观地证明了VAN的有效性。</p><p>‍</p><h1 id="Refs"><a href="#Refs" class="headerlink" title="Refs"></a>Refs</h1><blockquote id="fn_1"><sup>1</sup>. <a href="https://baidinghub.github.io/2020/04/03/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%9F%A5%E8%AF%86%E7%B3%BB%E5%88%97%28%E4%BA%8C%29%20%E5%90%84%E7%A7%8D%E5%8D%B7%E7%A7%AF%E5%BD%A2%E5%BC%8F/">深度学习知识系列(二) 各种卷积形式</a><a href="#reffn_1" title="Jump back to footnote [1] in the text."> &#8617;</a></blockquote><blockquote id="fn_2 "><sup>2 </sup>. <a href="https://zhuanlan.zhihu.com/p/474526444">【ARXIV2202】Visual Attention Network</a><a href="#reffn_2 " title="Jump back to footnote [2 ] in the text."> &#8617;</a></blockquote>]]></content>
    
    
      
      
    <summary type="html">&lt;blockquote&gt;
&lt;p&gt;本文是论文《Visual Attention Network》的学习笔记&lt;/p&gt;
&lt;p&gt;我在该模型上执行一个分类任务，发现该模型的效果要优于我实验的其他模型（包括resnet50、densenet121、efficientNet-b0、swin-t</summary>
      
    
    
    
    <category term="深度学习" scheme="https://guoyujian.github.io/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
    
    <category term="深度学习" scheme="https://guoyujian.github.io/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
    <category term="计算机视觉" scheme="https://guoyujian.github.io/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/"/>
    
  </entry>
  
  <entry>
    <title>Spring AOP Demo</title>
    <link href="https://guoyujian.github.io/2022/12/04/Spring-AOP-Demo/"/>
    <id>https://guoyujian.github.io/2022/12/04/Spring-AOP-Demo/</id>
    <published>2022-12-04T07:17:15.000Z</published>
    <updated>2022-12-04T07:21:08.814Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>本文不涉及Spring AOP原理</p></blockquote><h1 id="Spring-AOP-简介"><a href="#Spring-AOP-简介" class="headerlink" title="Spring AOP 简介"></a>Spring AOP 简介</h1><p>面向切面编程（AOP）是 Spring 最为重要的功能之一了，在数据库事务中切面编程被广泛使用。</p><h2 id="AOP-即-Aspect-Oriented-Program-面向切面编程"><a href="#AOP-即-Aspect-Oriented-Program-面向切面编程" class="headerlink" title="AOP 即 Aspect Oriented Program 面向切面编程"></a>AOP 即 Aspect Oriented Program 面向切面编程</h2><p>首先，在面向切面编程的思想里面，把功能分为核心业务功能，和周边功能。</p><ul><li><strong>所谓的核心业务</strong>​，比如登陆，增加数据，删除数据都叫核心业务</li><li><strong>所谓的周边功能</strong>​，比如性能统计，日志，事务管理等等</li></ul><p>周边功能在 Spring 的面向切面编程AOP思想里，即被定义为切面</p><p>在面向切面编程AOP的思想里面，核心业务功能和切面功能分别独立进行开发，然后把切面功能和核心业务功能 “编织” 在一起，这就叫AOP</p><h2 id="AOP-的目的"><a href="#AOP-的目的" class="headerlink" title="AOP 的目的"></a>AOP 的目的</h2><p>AOP能够将那些与业务无关，​<strong>却为业务模块所共同调用的逻辑或责任（例如事务处理、日志管理、权限控制等）封装起来</strong>​，便于​<strong>减少系统的重复代码</strong>​，​<strong>降低模块间的耦合度</strong>​，并​<strong>有利于未来的可拓展性和可维护性</strong>​。</p><h2 id="AOP-当中的概念："><a href="#AOP-当中的概念：" class="headerlink" title="AOP 当中的概念："></a>AOP 当中的概念：</h2><ul><li>切入点（Pointcut）<br>在哪些类，哪些方法上切入（​<strong>where</strong>​）</li><li>通知（Advice）<br>在方法执行的什么实际（<strong>when:</strong>方法前/方法后/方法前后）做什么（<strong>what:</strong>增强的功能）</li><li>切面（Aspect）<br>切面 = 切入点 + 通知，通俗点就是：<strong>在什么时机，什么地方，做什么增强！</strong></li><li>织入（Weaving）<br>把切面加入到对象，并创建出代理对象的过程。（由 Spring 来完成）</li></ul><h1 id="Demo"><a href="#Demo" class="headerlink" title="Demo"></a>Demo</h1><h2 id="需求说明"><a href="#需求说明" class="headerlink" title="需求说明"></a>需求说明</h2><p>为了更好的说明 AOP 的概念，我们来举一个实际中的例子来说明：</p><p><img src="image-20221204123653-p1e00ow.png" alt="image">​</p><p>在上面的例子中，包租婆的核心业务就是签合同，收房租，那么这就够了，灰色框起来的部分都是重复且边缘的事，交给中介商就好了，这就是 <strong>AOP 的一个思想：让关注点代码与业务代码分离！</strong></p><h2 id="代码实现（使用注解）"><a href="#代码实现（使用注解）" class="headerlink" title="代码实现（使用注解）"></a>代码实现（使用注解）</h2><h3 id="引入依赖"><a href="#引入依赖" class="headerlink" title="引入依赖"></a>引入依赖</h3><p>Spring Boot使用AOP需要添加spring-boot-starter-aop依赖，如下：</p><figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.springframework.boot<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>spring-boot-starter-aop<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure><p>不需要再添加aspectjweaver的依赖了，因为spring-boot-starter-aop包含了aspectjweaver，并且版本是较新的版本，如果在添加老版本（如1.5.4）启动会报错。</p><h3 id="编写核心业务Bean"><a href="#编写核心业务Bean" class="headerlink" title="编写核心业务Bean"></a>编写核心业务Bean</h3><p>也就是连接点</p><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> com.example.test_spring.service;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.springframework.stereotype.Service;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="meta">@Service</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">LandlordService</span> &#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">rent</span><span class="params">()</span> &#123;</span><br><span class="line">        System.out.println(<span class="string">&quot;房东：谈合同&quot;</span>);</span><br><span class="line">        System.out.println(<span class="string">&quot;房东：收房租&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure><h3 id="创建切面"><a href="#创建切面" class="headerlink" title="创建切面"></a>创建切面</h3><p>Spring采用@AspectJ注解对POJO进行标注，该注解表明该类不仅仅是一个POJO，还是一个切面。切面是切点和通知的结合，那么定义一个切面就需要编写切点和通知。在代码中，只需要添加@Aspect注解即可。</p><h3 id="定义切点"><a href="#定义切点" class="headerlink" title="定义切点"></a>定义切点</h3><p>切点是通过<strong>@Pointcut</strong>注解和切点表达式定义的。</p><p>@Pointcut注解可以在一个切面内定义<strong>可重用</strong>的切点。</p><p>由于Spring切面粒度最小是达到方法级别，而execution表达式可以用于明确指定方法返回类型，类名，方法名和参数名等与方法相关的部件，并且实际中，大部分需要使用AOP的业务场景也只需要达到方法级别即可，因而execution表达式的使用是最为广泛的。如图是execution表达式的语法：</p><p>execution表示在方法执行的时候触发。以“​<em>”开头，表明方法返回值类型为任意类型。然后是全限定的类名和方法名，“</em>​”可以表示任意类和任意方法。对于方法参数列表，可以使用“..”表示参数为任意类型。如果需要多个表达式，可以使用“&amp;&amp;”、“||”和“!”完成与、或、非的操作。</p><p><img src="image-20221204150048-bd0mj1f.png" alt="image">​</p><h3 id="定义通知"><a href="#定义通知" class="headerlink" title="定义通知"></a>定义通知</h3><blockquote><p>通知有五种类型，分别是：</p><p>前置通知（@Before）：在目标方法调用之前调用通知</p><p>后置通知（@After）：在目标方法完成之后调用通知</p><p>环绕通知（@Around）：在被通知的方法调用之前和调用之后执行自定义的方法</p><p>返回通知（@AfterReturning）：在目标方法成功执行之后调用通知</p><p>异常通知（@AfterThrowing）：在目标方法抛出异常之后调用通知</p></blockquote><p>本例中，分别使用前置通知实现“看房”和“谈价格”功能，使用后置通知实现“交钥匙”功能。这样一个切面就定义完成，下面是代码</p><h3 id="code"><a href="#code" class="headerlink" title="code"></a>code</h3><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> com.example.test_spring.aspect;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.aspectj.lang.annotation.After;</span><br><span class="line"><span class="keyword">import</span> org.aspectj.lang.annotation.Aspect;</span><br><span class="line"><span class="keyword">import</span> org.aspectj.lang.annotation.Before;</span><br><span class="line"><span class="keyword">import</span> org.aspectj.lang.annotation.Pointcut;</span><br><span class="line"><span class="keyword">import</span> org.springframework.stereotype.Component;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="meta">@Component</span></span><br><span class="line"><span class="meta">@Aspect</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">Broker</span> &#123;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="meta">@Pointcut(&quot;execution(* com.example.test_spring.service.LandlordService.rent())&quot;)</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">pointCut</span><span class="params">()</span> &#123;</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Before(&quot;pointCut()&quot;)</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">beforeRent</span><span class="params">()</span> &#123;</span><br><span class="line">        System.out.println(<span class="string">&quot;中间商：带租客看房&quot;</span>);</span><br><span class="line">        System.out.println(<span class="string">&quot;中间商：谈价格&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@After(&quot;pointCut()&quot;)</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">afterRent</span><span class="params">()</span> &#123;</span><br><span class="line">        System.out.println(<span class="string">&quot;中间商：交钥匙&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="测试"><a href="#测试" class="headerlink" title="测试"></a>测试</h2><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="meta">@SpringBootApplication</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">TestSpringApplication</span> &#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> &#123;</span><br><span class="line">        <span class="type">ConfigurableApplicationContext</span> <span class="variable">context</span> <span class="operator">=</span> SpringApplication.run(TestSpringApplication.class, args);</span><br><span class="line">        <span class="type">LandlordService</span> <span class="variable">bean</span> <span class="operator">=</span> context.getBean(LandlordService.class);</span><br><span class="line">        bean.rent();</span><br><span class="line">        System.exit(<span class="number">0</span>);</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><img src="image-20221204150759-y1b4f1u.png" alt="image">​</p><h2 id="环绕通知"><a href="#环绕通知" class="headerlink" title="环绕通知"></a>环绕通知</h2><p>看到上述的需求也可以使用环绕通知，他会在方法执行前后执行。</p><p>改写<code>Broker.java</code>​代码如下：</p><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> com.example.test_spring.aspect;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.aspectj.lang.JoinPoint;</span><br><span class="line"><span class="keyword">import</span> org.aspectj.lang.ProceedingJoinPoint;</span><br><span class="line"><span class="keyword">import</span> org.aspectj.lang.annotation.*;</span><br><span class="line"><span class="keyword">import</span> org.springframework.stereotype.Component;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="meta">@Component</span></span><br><span class="line"><span class="meta">@Aspect</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">Broker</span> &#123;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="meta">@Pointcut(&quot;execution(* com.example.test_spring.service.LandlordService.rent())&quot;)</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">pointCut</span><span class="params">()</span> &#123;</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">//    @Before(&quot;pointCut()&quot;)</span></span><br><span class="line"><span class="comment">//    public void beforeRent() &#123;</span></span><br><span class="line"><span class="comment">//        System.out.println(&quot;中间商：带租客看房&quot;);</span></span><br><span class="line"><span class="comment">//        System.out.println(&quot;中间商：谈价格&quot;);</span></span><br><span class="line"><span class="comment">//    &#125;</span></span><br><span class="line"><span class="comment">//</span></span><br><span class="line"><span class="comment">//    @After(&quot;pointCut()&quot;)</span></span><br><span class="line"><span class="comment">//    public void afterRent() &#123;</span></span><br><span class="line"><span class="comment">//        System.out.println(&quot;中间商：交钥匙&quot;);</span></span><br><span class="line"><span class="comment">//    &#125;</span></span><br><span class="line"></span><br><span class="line">    <span class="meta">@Around(&quot;pointCut()&quot;)</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">aroundRent</span><span class="params">(ProceedingJoinPoint point)</span> &#123;</span><br><span class="line">        System.out.println(<span class="string">&quot;中间商：带租客看房&quot;</span>);</span><br><span class="line">        System.out.println(<span class="string">&quot;中间商：谈价格&quot;</span>);</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            point.proceed();</span><br><span class="line">        &#125; <span class="keyword">catch</span> (Throwable throwable) &#123;</span><br><span class="line">            throwable.printStackTrace();</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        System.out.println(<span class="string">&quot;中间商：交钥匙&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>运行测试代码，结果依然正确</p><h1 id="Ref"><a href="#Ref" class="headerlink" title="Ref"></a>Ref</h1><ol><li><a href="https://www.jianshu.com/p/994027425b44">Spring(4)——面向切面编程（AOP模块）</a></li><li><a href="https://www.cnblogs.com/sgh1023/p/13363679.html">Spring Boot使用AOP的正确姿势</a>​</li></ol><p>‍</p>]]></content>
    
    
      
      
    <summary type="html">&lt;blockquote&gt;
&lt;p&gt;本文不涉及Spring AOP原理&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h1 id=&quot;Spring-AOP-简介&quot;&gt;&lt;a href=&quot;#Spring-AOP-简介&quot; class=&quot;headerlink&quot; title=&quot;Spring AOP 简介&quot;</summary>
      
    
    
    
    <category term="Java" scheme="https://guoyujian.github.io/categories/Java/"/>
    
    <category term="Spring" scheme="https://guoyujian.github.io/categories/Java/Spring/"/>
    
    
    <category term="Java" scheme="https://guoyujian.github.io/tags/Java/"/>
    
    <category term="Spring" scheme="https://guoyujian.github.io/tags/Spring/"/>
    
    <category term="面向切面编程" scheme="https://guoyujian.github.io/tags/%E9%9D%A2%E5%90%91%E5%88%87%E9%9D%A2%E7%BC%96%E7%A8%8B/"/>
    
    <category term="AOP" scheme="https://guoyujian.github.io/tags/AOP/"/>
    
  </entry>
  
  <entry>
    <title>使用docker部署redis并实现外部访问</title>
    <link href="https://guoyujian.github.io/2022/11/23/%E4%BD%BF%E7%94%A8docker%E9%83%A8%E7%BD%B2redis%E5%B9%B6%E5%AE%9E%E7%8E%B0%E5%A4%96%E9%83%A8%E8%AE%BF%E9%97%AE/"/>
    <id>https://guoyujian.github.io/2022/11/23/%E4%BD%BF%E7%94%A8docker%E9%83%A8%E7%BD%B2redis%E5%B9%B6%E5%AE%9E%E7%8E%B0%E5%A4%96%E9%83%A8%E8%AE%BF%E9%97%AE/</id>
    <published>2022-11-23T14:13:11.000Z</published>
    <updated>2022-11-23T14:26:33.656Z</updated>
    
    <content type="html"><![CDATA[<h1 id="安装之前环境部署"><a href="#安装之前环境部署" class="headerlink" title="安装之前环境部署"></a>安装之前环境部署</h1><p>关闭linux防火墙</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">systemctl stop firewalld</span><br></pre></td></tr></table></figure><p>如果你使用的是云服务器，务必进入云服务器,给6379端口放行</p><h1 id="安装部署"><a href="#安装部署" class="headerlink" title="安装部署"></a>安装部署</h1><h2 id="拉取镜像"><a href="#拉取镜像" class="headerlink" title="拉取镜像"></a>拉取镜像</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">docker pull redis:latest</span><br></pre></td></tr></table></figure><h2 id="从官网下载redis配置文件"><a href="#从官网下载redis配置文件" class="headerlink" title="从官网下载redis配置文件"></a>从官网下载redis配置文件</h2><p><code>wget http://download.redis.io/redis-stable/redis.conf</code></p><h2 id="创建一个文件夹用于保存此文件"><a href="#创建一个文件夹用于保存此文件" class="headerlink" title="创建一个文件夹用于保存此文件"></a>创建一个文件夹用于保存此文件</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">mkdir</span> /root/redis</span><br><span class="line"><span class="built_in">mv</span> /root/redis.conf  /root/redis</span><br></pre></td></tr></table></figure><h2 id="更改redis-conf的配置"><a href="#更改redis-conf的配置" class="headerlink" title="更改redis.conf的配置"></a>更改redis.conf的配置</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">vi /root/redis/redis.conf</span><br></pre></td></tr></table></figure><p>将redis.conf文件下列参数更改</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">#bind 127.0.0.1 #允许远程连接(注释或者改为bind 0.0.0.0) </span></span><br><span class="line">protected-mode no    <span class="comment">#保护模式</span></span><br><span class="line">appendonly <span class="built_in">yes</span> <span class="comment">#持久化</span></span><br></pre></td></tr></table></figure><h2 id="启动容器"><a href="#启动容器" class="headerlink" title="启动容器"></a>启动容器</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">docker run -p 6379:6379 --name redis -v /root/redis/redis.conf:/etc/redis/redis.conf -v /root/redis/data:/data -d redis redis-server /etc/redis/redis.conf </span><br></pre></td></tr></table></figure><p>参数说明:</p><ul><li>-p 6379:6379：把容器内的6379端口映射到宿主机6379端口</li><li>–name redis：设置容器名称为redis</li><li>-v /root/redis/redis.conf:/etc/redis/redis.conf：把主机配置好的redis.conf放到容器内的这个位置中</li><li>-v /root/redis/data:/data：把redis持久化的数据在宿主机内显示，做数据备份</li><li>-d：redis后台运行</li><li>redis-server /etc/redis/redis.conf：这个是关键配置，让redis不是无配置启动，而是按照这个redis.conf的配置启动</li></ul><h2 id="完成测试"><a href="#完成测试" class="headerlink" title="完成测试"></a>完成测试</h2><p>查看容器是否启动：</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">docker ps</span><br></pre></td></tr></table></figure><p>进入容器，检查是否可以启动redis-cli</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">root@Met-Guo:~<span class="comment"># docker exec -it 56 bash # 56为容器id</span></span><br><span class="line">root@5601af5f1f67:/data<span class="comment"># redis-cli</span></span><br><span class="line">127.0.0.1:6379&gt; <span class="built_in">set</span> name 50</span><br><span class="line">OK</span><br><span class="line">127.0.0.1:6379&gt; get name</span><br><span class="line"><span class="string">&quot;50&quot;</span></span><br><span class="line">127.0.0.1:6379&gt; <span class="built_in">exit</span></span><br><span class="line"></span><br></pre></td></tr></table></figure><p>在宿主机安装Redis Desktop Manager客户端，并配置</p><p><img src="image-20221123222544338.png" alt="截图"></p><p>成功。</p><h1 id="Refs"><a href="#Refs" class="headerlink" title="Refs"></a>Refs</h1><ol><li><a href="https://blog.csdn.net/weixin_46186045/article/details/117387772">docker 部署redis外部访问该注意的地方你都知道吗</a></li></ol>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;安装之前环境部署&quot;&gt;&lt;a href=&quot;#安装之前环境部署&quot; class=&quot;headerlink&quot; title=&quot;安装之前环境部署&quot;&gt;&lt;/a&gt;安装之前环境部署&lt;/h1&gt;&lt;p&gt;关闭linux防火墙&lt;/p&gt;
&lt;figure class=&quot;highlight bash&quot;&gt;</summary>
      
    
    
    
    <category term="redis" scheme="https://guoyujian.github.io/categories/redis/"/>
    
    
    <category term="redis安装" scheme="https://guoyujian.github.io/tags/redis%E5%AE%89%E8%A3%85/"/>
    
    <category term="docker" scheme="https://guoyujian.github.io/tags/docker/"/>
    
  </entry>
  
  <entry>
    <title>SSH三步解决免密登录</title>
    <link href="https://guoyujian.github.io/2022/11/07/SSH%E4%B8%89%E6%AD%A5%E8%A7%A3%E5%86%B3%E5%85%8D%E5%AF%86%E7%99%BB%E5%BD%95/"/>
    <id>https://guoyujian.github.io/2022/11/07/SSH%E4%B8%89%E6%AD%A5%E8%A7%A3%E5%86%B3%E5%85%8D%E5%AF%86%E7%99%BB%E5%BD%95/</id>
    <published>2022-11-07T14:29:07.000Z</published>
    <updated>2022-11-07T14:33:39.446Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Refs"><a href="#Refs" class="headerlink" title="Refs"></a>Refs</h1><ol><li><a href="https://blog.csdn.net/jeikerxiao/article/details/84105529">SSH 三步解决免密登录</a></li></ol>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;Refs&quot;&gt;&lt;a href=&quot;#Refs&quot; class=&quot;headerlink&quot; title=&quot;Refs&quot;&gt;&lt;/a&gt;Refs&lt;/h1&gt;&lt;ol&gt;
&lt;li&gt;&lt;a href=&quot;https://blog.csdn.net/jeikerxiao/article/detail</summary>
      
    
    
    
    <category term="Linux" scheme="https://guoyujian.github.io/categories/Linux/"/>
    
    <category term="开发工具" scheme="https://guoyujian.github.io/categories/Linux/%E5%BC%80%E5%8F%91%E5%B7%A5%E5%85%B7/"/>
    
    
    <category term="开发工具" scheme="https://guoyujian.github.io/tags/%E5%BC%80%E5%8F%91%E5%B7%A5%E5%85%B7/"/>
    
  </entry>
  
  <entry>
    <title>FATE使用遇到的问题汇总</title>
    <link href="https://guoyujian.github.io/2022/11/04/FATE%E4%BD%BF%E7%94%A8%E9%81%87%E5%88%B0%E7%9A%84%E9%97%AE%E9%A2%98%E6%B1%87%E6%80%BB/"/>
    <id>https://guoyujian.github.io/2022/11/04/FATE%E4%BD%BF%E7%94%A8%E9%81%87%E5%88%B0%E7%9A%84%E9%97%AE%E9%A2%98%E6%B1%87%E6%80%BB/</id>
    <published>2022-11-03T16:11:41.000Z</published>
    <updated>2022-11-03T16:13:55.018Z</updated>
    
    <content type="html"><![CDATA[<p>本文汇总在使用和开发FATE时遇到的各类问题，以及给出可能的解决方案。</p><h1 id="flow-init"><a href="#flow-init" class="headerlink" title="flow init"></a>flow init</h1><h2 id="问题状态"><a href="#问题状态" class="headerlink" title="问题状态"></a>问题状态</h2><p>已解决</p><h2 id="问题描述"><a href="#问题描述" class="headerlink" title="问题描述"></a>问题描述</h2><p>首次进入fate-client时，提示需要执行flow init，否则有关flow的命令都执行不了。</p><h2 id="解决方案"><a href="#解决方案" class="headerlink" title="解决方案"></a>解决方案</h2><p><code>flow init --ip &lt;docker容器宿主机ip&gt; --port 9380</code></p><p>‍</p><h1 id="ModuleNotFoundError-No-module-named-‘-lzma’"><a href="#ModuleNotFoundError-No-module-named-‘-lzma’" class="headerlink" title="ModuleNotFoundError: No module named ‘_lzma’"></a>ModuleNotFoundError: No module named ‘_lzma’</h1><h2 id="问题描述-1"><a href="#问题描述-1" class="headerlink" title="问题描述"></a>问题描述</h2><p>执行任务时，nn模块报错：ModuleNotFoundError: No module named ‘_lzma’</p><p><img src="image-20220927210914-c8pbaiz.png" alt="image.png"></p><h2 id="解决方案-1"><a href="#解决方案-1" class="headerlink" title="解决方案"></a>解决方案</h2><p>在fate-flow container安装相关的包即可（guest、host和arbiter都要安装）。安装教程：<a href="https://github.com/ultralytics/yolov5/issues/1298">https://github.com/ultralytics/yolov5/issues/1298</a></p><p>这里需要修改路径</p><p><img src="image-20220928115429-n9l4hgw.png" alt="image.png"></p><h1 id="找不到文件：No-such-file-or-directory-‘-data-projects-fate-work-mnist-fed-mnist-train-part2-config-yaml’"><a href="#找不到文件：No-such-file-or-directory-‘-data-projects-fate-work-mnist-fed-mnist-train-part2-config-yaml’" class="headerlink" title="找不到文件：No such file or directory: ‘/data/projects/fate/work/mnist_fed/mnist_train_part2/config.yaml’"></a>找不到文件：<strong>No such file or directory: ‘/data/projects/fate/work/mnist_fed/mnist_train_part2/config.yaml’</strong></h1><h2 id="问题状态-1"><a href="#问题状态-1" class="headerlink" title="问题状态"></a>问题状态</h2><p>已解决</p><h2 id="问题描述-2"><a href="#问题描述-2" class="headerlink" title="问题描述"></a>问题描述</h2><p>在执行任务时，reader组件报错：</p><p><img src="image-20220927205925-34fvaot.png" alt="image.png"></p><p>这是由于我把数据保存在了fate-client，而fate读取数据是在fate-flow container导致的。</p><h2 id="解决方案-2"><a href="#解决方案-2" class="headerlink" title="解决方案"></a>解决方案</h2><p>由于fate-client和fate-flow两个容器中的examples文件夹挂载到docker底层同一处存储。所以把数据放到examples下，把配置修改为新的文件路径即可。</p><h1 id="开发新的FATE-FLOW-API"><a href="#开发新的FATE-FLOW-API" class="headerlink" title="开发新的FATE-FLOW API"></a>开发新的FATE-FLOW API</h1><p>这里是已有的API：<a href="https://federatedai.github.io/FATE-Flow/latest/zh/swagger/">https://federatedai.github.io/FATE-Flow/latest/zh/swagger/</a></p><p>FATE的HTTP接口都是基于flask框架编写的。</p><p>开发步骤如下：</p><ol><li>进入FATE-FLOW容器</li><li>cd /data/projects/fate/fateflow/python/fate_flow/apps</li><li>新建python文件，命名为xxx_app.py，编写新的接口。</li><li>重启FLOW容器</li></ol><h1 id="修改代码导致docker-container没起来"><a href="#修改代码导致docker-container没起来" class="headerlink" title="修改代码导致docker container没起来"></a>修改代码导致docker container没起来</h1><p>修改FATE-FLOW的代码后，由于代码有bug，导致容器起不来，又导致不能进入容器修改代码的死循环，怎么办？</p><p>查看docker容器的启动日志，确定出错的代码，docker cp拷贝出来需要修改的代码，再拷贝回去。</p><p>‍</p><h1 id="实际训练的epoch小于配置的max-iter"><a href="#实际训练的epoch小于配置的max-iter" class="headerlink" title="实际训练的epoch小于配置的max_iter"></a>实际训练的epoch小于配置的max_iter</h1><p>查看自己是否在配置文件中配置了：</p><figure class="highlight json"><table><tr><td class="code"><pre><span class="line"><span class="attr">&quot;early_stop&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">    <span class="attr">&quot;early_stop&quot;</span><span class="punctuation">:</span> <span class="string">&quot;diff&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;eps&quot;</span><span class="punctuation">:</span> <span class="number">0.0001</span></span><br><span class="line"><span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br></pre></td></tr></table></figure><p>这里的意思是，如果两个epoch得到的loss之差小于0.0001时则停止训练。</p><h1 id="memory-error"><a href="#memory-error" class="headerlink" title="memory error"></a>memory error</h1><p>根据实践经验，memory error 还有dataloader worker pid之类的错误，均是由于内存不够引起的。调小batch size，或者增加硬件配置</p><p>‍</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;本文汇总在使用和开发FATE时遇到的各类问题，以及给出可能的解决方案。&lt;/p&gt;
&lt;h1 id=&quot;flow-init&quot;&gt;&lt;a href=&quot;#flow-init&quot; class=&quot;headerlink&quot; title=&quot;flow init&quot;&gt;&lt;/a&gt;flow init&lt;/h1&gt;&lt;h</summary>
      
    
    
    
    <category term="联邦学习" scheme="https://guoyujian.github.io/categories/%E8%81%94%E9%82%A6%E5%AD%A6%E4%B9%A0/"/>
    
    
    <category term="联邦学习" scheme="https://guoyujian.github.io/tags/%E8%81%94%E9%82%A6%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>FATE横向联邦学习：肺炎的多模态任务的联邦学习</title>
    <link href="https://guoyujian.github.io/2022/11/04/FATE%E6%A8%AA%E5%90%91%E8%81%94%E9%82%A6%E5%AD%A6%E4%B9%A0%EF%BC%9A%E8%82%BA%E7%82%8E%E7%9A%84%E5%A4%9A%E6%A8%A1%E6%80%81%E4%BB%BB%E5%8A%A1%E7%9A%84%E8%81%94%E9%82%A6%E5%AD%A6%E4%B9%A0/"/>
    <id>https://guoyujian.github.io/2022/11/04/FATE%E6%A8%AA%E5%90%91%E8%81%94%E9%82%A6%E5%AD%A6%E4%B9%A0%EF%BC%9A%E8%82%BA%E7%82%8E%E7%9A%84%E5%A4%9A%E6%A8%A1%E6%80%81%E4%BB%BB%E5%8A%A1%E7%9A%84%E8%81%94%E9%82%A6%E5%AD%A6%E4%B9%A0/</id>
    <published>2022-11-03T16:10:23.000Z</published>
    <updated>2022-11-03T16:11:17.397Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>多模态最近比较火</p><p>多模态任务的input和算法FATE不支持，因此需要开发新的dataloader和算法组件。</p><p>本篇就以肺炎多模态任务为例，介绍如何开发新的FATE机器学习组件</p><p>官方文档在这里：<a href="https://fate.readthedocs.io/en/latest/develop/develop_guide/#develop-an-algorithm-component-of-fate">https://fate.readthedocs.io/en/latest/develop/develop_guide/#develop-an-algorithm-component-of-fate</a></p></blockquote><h1 id="baseline"><a href="#baseline" class="headerlink" title="baseline"></a>baseline</h1><p>本任务将开发基于肺部X光图像和描述文字正确判断是否患有肺炎的二分类算法。</p><p>数据集输入由两部分组成。一部分为肺部X光扫描图像，另一部分为对图像的描述文字。数据标签分为0和1，分别对应正常和患有肺炎两类标签。</p><h2 id="本地代码复现"><a href="#本地代码复现" class="headerlink" title="本地代码复现"></a>本地代码复现</h2><ol><li>baseline 代码在这里：<a href="https://github.com/AxelAllen/Multimodal-BERT-in-Medical-Image-and-Text-Classification">https://github.com/AxelAllen/Multimodal-BERT-in-Medical-Image-and-Text-Classification</a></li><li>将其clone到本地，按照README.md的提示，将NLMCXR_png_frontal图像文件夹放到data目录下。执行data/preparations.ipynb生成元数据。</li><li>执行run_mmbt.ipynb</li><li>执行完毕后，会在根目录下生成mmbt_output_findings_10epochs_n文件夹，里面保存有模型拟合后的梯度和评估结果。</li></ol><h2 id="阅读代码"><a href="#阅读代码" class="headerlink" title="阅读代码"></a>阅读代码</h2><p>这里要弄清楚代码的整套流程，主要是超参、使用的算法、训练、数据处理和加载，模型如何评估这几步。这里只展示核心代码</p><h3 id="超参"><a href="#超参" class="headerlink" title="超参"></a>超参</h3><div class="table-container"><table><thead><tr><th>参数</th><th>值</th></tr></thead><tbody><tr><td>Epoch</td><td>10</td></tr><tr><td>Bacth_size</td><td>16/32</td></tr><tr><td>Optimizer</td><td>AdamW</td></tr><tr><td>LR</td><td>5e-5</td></tr><tr><td>Loss</td><td>CrossEntropyLoss</td></tr><tr><td>Metrics</td><td>Accuracy</td></tr></tbody></table></div><blockquote><p>有趣的是，如果batch size = 4，模型无法训练处任何结果。</p></blockquote><h3 id="算法"><a href="#算法" class="headerlink" title="算法"></a>算法</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 部分code</span></span><br><span class="line"></span><br><span class="line">transformer_config = AutoConfig.from_pretrained(args.config_name <span class="keyword">if</span> args.config_name <span class="keyword">else</span> args.model_name, num_labels=num_labels)</span><br><span class="line">tokenizer = AutoTokenizer.from_pretrained(</span><br><span class="line">        args.tokenizer_name <span class="keyword">if</span> args.tokenizer_name <span class="keyword">else</span> args.model_name,</span><br><span class="line">        do_lower_case=<span class="literal">True</span>,</span><br><span class="line">        cache_dir=<span class="literal">None</span>,</span><br><span class="line">    )</span><br><span class="line">transformer = AutoModel.from_pretrained(args.model_name, config=transformer_config, cache_dir=<span class="literal">None</span>)</span><br><span class="line">img_encoder = ImageEncoderDenseNet(num_image_embeds=args.num_image_embeds)</span><br><span class="line">multimodal_config = MMBTConfig(transformer, img_encoder, num_labels=num_labels, modal_hidden_size=<span class="number">1024</span>)</span><br><span class="line">model = MMBTForClassification(transformer_config, multimodal_config)</span><br></pre></td></tr></table></figure><p>使用MMBT模型: 用于图像和文本分类的有监督多模态双向Transformer。</p><ul><li>图像编码器使用的ChexNet，这是一个针对X光胸片肺炎检测的模型；</li><li>文本编码器使用的预训练的BERT模型：bert-base-uncased。</li></ul><p>整体网络结构如图</p><p><img src="image-20221102150400-2suo5cw.png" alt="image">​</p><p>‍</p><h3 id="data-loader"><a href="#data-loader" class="headerlink" title="data loader"></a>data loader</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 部分code</span></span><br><span class="line">dataset = JsonlDataset(path, img_dir, tokenizer, img_transforms, labels, wandb_config.max_seq_length -</span><br><span class="line">                       wandb_config.num_image_embeds - <span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">...</span><br><span class="line">train_dataloader = DataLoader(</span><br><span class="line">    train_dataset,</span><br><span class="line">    sampler=train_sampler,</span><br><span class="line">    batch_size=args.train_batch_size,</span><br><span class="line">    collate_fn=collate_fn</span><br><span class="line">)</span><br></pre></td></tr></table></figure><h3 id="train"><a href="#train" class="headerlink" title="train"></a>train</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 部分code</span></span><br><span class="line"><span class="keyword">for</span> _ <span class="keyword">in</span> train_iterator:</span><br><span class="line">    epoch_iterator = tqdm(train_dataloader, desc=<span class="string">&quot;Training Batch Iteration&quot;</span>)</span><br><span class="line">    <span class="keyword">for</span> step, batch <span class="keyword">in</span> <span class="built_in">enumerate</span>(epoch_iterator):</span><br><span class="line"></span><br><span class="line">        batch = <span class="built_in">tuple</span>(t.to(args.device) <span class="keyword">for</span> t <span class="keyword">in</span> batch)</span><br><span class="line">        labels = batch[<span class="number">5</span>]</span><br><span class="line">        input_ids = batch[<span class="number">0</span>]</span><br><span class="line">        input_modal = batch[<span class="number">2</span>]</span><br><span class="line">        attention_mask = batch[<span class="number">1</span>]</span><br><span class="line">        modal_start_tokens = batch[<span class="number">3</span>]</span><br><span class="line">        modal_end_tokens = batch[<span class="number">4</span>]</span><br><span class="line"></span><br><span class="line">        outputs = model(</span><br><span class="line">            input_modal,</span><br><span class="line">            input_ids=input_ids,</span><br><span class="line">            modal_start_tokens=modal_start_tokens,</span><br><span class="line">            modal_end_tokens=modal_end_tokens,</span><br><span class="line">            attention_mask=attention_mask,</span><br><span class="line">            token_type_ids=<span class="literal">None</span>,</span><br><span class="line">            modal_token_type_ids=<span class="literal">None</span>,</span><br><span class="line">            position_ids=<span class="literal">None</span>,</span><br><span class="line">            modal_position_ids=<span class="literal">None</span>,</span><br><span class="line">            head_mask=<span class="literal">None</span>,</span><br><span class="line">            inputs_embeds=<span class="literal">None</span>,</span><br><span class="line">            labels=labels,</span><br><span class="line">            return_dict=<span class="literal">True</span></span><br><span class="line">        )</span><br><span class="line">        logits = outputs.logits</span><br><span class="line">        loss = outputs.loss</span><br><span class="line">        loss.backward()</span><br></pre></td></tr></table></figure><h3 id="评估"><a href="#评估" class="headerlink" title="评估"></a>评估</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 部分代码</span></span><br><span class="line">result = evaluate(args, model, tokenizer, evaluate=<span class="literal">True</span>, test=<span class="literal">True</span>, prefix=prefix)</span><br></pre></td></tr></table></figure><h1 id="开发新组件"><a href="#开发新组件" class="headerlink" title="开发新组件"></a>开发新组件</h1><p>当我们已经在本地跑通代码，并明确算法之后，就可以开发新的组件，将算法联邦化。</p><p>这里官方文档写的很清楚，我大概复述一下</p><h3 id="Step-1-Define-the-python-parameter-object-to-be-used-by-this-component"><a href="#Step-1-Define-the-python-parameter-object-to-be-used-by-this-component" class="headerlink" title="Step 1. Define the python parameter object to be used by this component"></a>Step 1. Define the python parameter object to be used by this component</h3><ol><li>Open a new python file called <code>xxx_param.py</code>​, where xxx stands for your component’s name. Place this file in the folder <code>python/federatedm/param/</code>​. The class object defined in <code>xxx_param.py</code>​ should inherit the <code>BaseParam</code>​ class declared in <code>python/federatedml/param/base_param.py</code>​</li><li>The <code>__init__</code>​ method of your parameter class should specify all parameters that the component uses.</li><li>Override and implement the <code>check</code>​ interface method of BaseParam. The <code>check</code>​ method is used to validate the parameter variables.</li><li><code>python/federatedml/param/__init__.py</code>​列表<code>__all__</code>​增加你的组件名称，并导入。</li></ol><p>我这里组件名称叫homo_mm，所以创建的python文件名为homo_mm_param.py。由于和homo_nn很像，所以直接讲homo_nn_param.py复制过来，将里面的“nn”改成“mm”。</p><p>第四步增加了</p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> federatedml.param.homo_mm_param <span class="keyword">import</span> HomoMMParam</span><br><span class="line">...</span><br><span class="line">__all__ = [... <span class="string">&quot;HomoMMParam&quot;</span>, ...]</span><br></pre></td></tr></table></figure><p>python/federatedml/param/<strong>init</strong>.py</p><h3 id="Step-2-Define-the-meta-file-of-the-new-component"><a href="#Step-2-Define-the-meta-file-of-the-new-component" class="headerlink" title="Step 2. Define the meta file of the new component"></a>Step 2. Define the meta file of the new component</h3><ol><li>Define component meta python file under <code>python/federatedml/components/</code>​, name it as <code>xxx.py</code>​, where xxx stands for the algorithm component being developed.</li><li>Implement the meta file.</li></ol><p>我这里组件名称叫homo_mm，所以创建的python文件名为homo_mm.py。由于和homo_nn很像，所以直接讲homo_nn.py复制过来，将里面的“nn”改成“mm”。</p><h3 id="Step-3-Define-the-transfer-variable-object-of-this-module-Optional"><a href="#Step-3-Define-the-transfer-variable-object-of-this-module-Optional" class="headerlink" title="Step 3. Define the transfer variable object of this module. (Optional)"></a>Step 3. Define the transfer variable object of this module. (Optional)</h3><p>这里不需要</p><h3 id="Step-4-Create-the-component-which-inherits-the-class-model-base​"><a href="#Step-4-Create-the-component-which-inherits-the-class-model-base​" class="headerlink" title="Step 4. Create the component which inherits the class model_base​"></a>Step 4. Create the component which inherits the class <code>model_base</code>​</h3><p>现在就可以将<code>python/federatedml/nn/homo_nn</code>​复制一份，修改为homo_mm，修改_torch.py文件</p><p>详略。</p><h3 id="additional"><a href="#additional" class="headerlink" title="additional"></a>additional</h3><p>需要注意在<code>python/federatedml/nn/backend/pytorch/data.py</code>​新建新的dataset。并在_torch中的make_dataset创建，这里可以参照VisionDataSet</p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">MMDataSet</span>(<span class="title class_ inherited__">DatasetMixIn</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">get_num_labels</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">None</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">get_num_features</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">None</span></span><br><span class="line">  </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">get_keys</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">return</span> self._keys</span><br><span class="line">  </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">as_data_instance</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">from</span> federatedml.feature.instance <span class="keyword">import</span> Instance</span><br><span class="line"></span><br><span class="line">        <span class="keyword">def</span> <span class="title function_">_as_instance</span>(<span class="params">x</span>):</span><br><span class="line">            <span class="keyword">if</span> <span class="built_in">isinstance</span>(x, np.number):</span><br><span class="line">                <span class="keyword">return</span> Instance(label=x.tolist())</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                <span class="keyword">return</span> Instance(label=x)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> computing_session.parallelize(</span><br><span class="line">            data=<span class="built_in">zip</span>(self._keys, <span class="built_in">map</span>(_as_instance, self.targets)),</span><br><span class="line">            include_key=<span class="literal">True</span>,</span><br><span class="line">            partition=<span class="number">1</span>,</span><br><span class="line">        )</span><br><span class="line">  </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self,train_data_path, is_train=<span class="literal">True</span>, expected_label_type=np.float32,**kwargs</span>):</span><br><span class="line"><span class="comment"># 这里必须加上，否则会卡在标签对齐且不报错</span></span><br><span class="line">        <span class="keyword">if</span> is_train:</span><br><span class="line">            HomoLabelEncoderClient().label_alignment([<span class="string">&quot;fake&quot;</span>])</span><br><span class="line"></span><br><span class="line">        tokenizer = AutoTokenizer.from_pretrained(</span><br><span class="line">            <span class="string">&quot;bert-base-uncased&quot;</span>,</span><br><span class="line">            do_lower_case=<span class="literal">True</span>,</span><br><span class="line">            cache_dir=<span class="literal">None</span>,</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">        labels = [<span class="number">0</span>,<span class="number">1</span>]</span><br><span class="line">        labels2id = &#123;<span class="string">&#x27;0&#x27;</span>: <span class="number">0</span>, <span class="string">&#x27;1&#x27;</span>: <span class="number">1</span>&#125;</span><br><span class="line">        self.labels2id = labels2id</span><br><span class="line">        self.data = [json.loads(line) <span class="keyword">for</span> line <span class="keyword">in</span> <span class="built_in">open</span>(os.path.join(train_data_path, <span class="string">&quot;meta.jsonl&quot;</span>))]</span><br><span class="line"></span><br><span class="line">        self.targets = [ item[<span class="string">&#x27;label&#x27;</span>] <span class="keyword">for</span> item <span class="keyword">in</span> self.data]</span><br><span class="line">        self.img_data_dir = os.path.join(train_data_path, <span class="string">&#x27;images&#x27;</span>)</span><br><span class="line">        self.tokenizer = tokenizer</span><br><span class="line">        self.labels = labels</span><br><span class="line">        self.n_classes = <span class="built_in">len</span>(labels)</span><br><span class="line">        self.max_seq_length = <span class="number">300</span> - <span class="number">3</span> - <span class="number">2</span></span><br><span class="line">        self.transforms = torchvision.transforms.Compose(</span><br><span class="line">            [</span><br><span class="line">                torchvision.transforms.Resize(<span class="number">256</span>),</span><br><span class="line">                torchvision.transforms.CenterCrop(<span class="number">224</span>),</span><br><span class="line">                torchvision.transforms.ToTensor(),</span><br><span class="line">                torchvision.transforms.Normalize(</span><br><span class="line">                    mean=[<span class="number">0.485</span>, <span class="number">0.456</span>, <span class="number">0.406</span>],</span><br><span class="line">                    std=[<span class="number">0.229</span>, <span class="number">0.224</span>, <span class="number">0.225</span>]</span><br><span class="line">                )</span><br><span class="line">            ]</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">        key_dic = []</span><br><span class="line">        <span class="keyword">for</span> <span class="built_in">id</span> <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(self.data)):</span><br><span class="line">            key_dic.append(<span class="built_in">id</span>)</span><br><span class="line">        self._keys = key_dic</span><br><span class="line">        <span class="keyword">pass</span></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__getitem__</span>(<span class="params">self, index</span>):</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        sentence = torch.LongTensor(self.tokenizer.encode(self.data[index][<span class="string">&quot;text&quot;</span>], add_special_tokens=<span class="literal">True</span>))</span><br><span class="line">        start_token, sentence, end_token = sentence[<span class="number">0</span>], sentence[<span class="number">1</span>:-<span class="number">1</span>], sentence[-<span class="number">1</span>]</span><br><span class="line">        sentence = sentence[:self.max_seq_length]</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> self.n_classes &gt; <span class="number">2</span>:</span><br><span class="line">            <span class="comment"># multiclass</span></span><br><span class="line">            label = torch.zeros(self.n_classes)</span><br><span class="line">            label[self.labels.index(self.data[index][<span class="string">&quot;label&quot;</span>])] = <span class="number">1</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            label = torch.LongTensor([self.labels.index(self.data[index][<span class="string">&quot;label&quot;</span>])])</span><br><span class="line"></span><br><span class="line">        image = Image.<span class="built_in">open</span>(os.path.join(self.img_data_dir, self.data[index][<span class="string">&quot;img&quot;</span>])).convert(<span class="string">&quot;RGB&quot;</span>)</span><br><span class="line">        image = self.transforms(image)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> &#123;</span><br><span class="line">            <span class="string">&quot;image_start_token&quot;</span>: start_token,</span><br><span class="line">            <span class="string">&quot;image_end_token&quot;</span>: end_token,</span><br><span class="line">            <span class="string">&quot;sentence&quot;</span>: sentence,</span><br><span class="line">            <span class="string">&quot;image&quot;</span>: image,</span><br><span class="line">            <span class="string">&quot;label&quot;</span>: label,</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__len__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">len</span>(self.data)</span><br><span class="line">    <span class="comment"># 标签名称和标签index的对应，例如&#123;&quot;阴性&quot;:0, &quot;阳性&quot;:1&#125;</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">get_label_align_mapping</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">return</span> self.labels2id</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>如果Job仍然跑不起来，可以通过FATE-BOARD日志排错。</p><p>‍</p>]]></content>
    
    
      
      
    <summary type="html">&lt;blockquote&gt;
&lt;p&gt;多模态最近比较火&lt;/p&gt;
&lt;p&gt;多模态任务的input和算法FATE不支持，因此需要开发新的dataloader和算法组件。&lt;/p&gt;
&lt;p&gt;本篇就以肺炎多模态任务为例，介绍如何开发新的FATE机器学习组件&lt;/p&gt;
&lt;p&gt;官方文档在这里：&lt;a hre</summary>
      
    
    
    
    <category term="联邦学习" scheme="https://guoyujian.github.io/categories/%E8%81%94%E9%82%A6%E5%AD%A6%E4%B9%A0/"/>
    
    
    <category term="联邦学习" scheme="https://guoyujian.github.io/tags/%E8%81%94%E9%82%A6%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>FATE横向联邦学习：肠癌图像分类任务（下）——联邦化</title>
    <link href="https://guoyujian.github.io/2022/11/04/FATE%E6%A8%AA%E5%90%91%E8%81%94%E9%82%A6%E5%AD%A6%E4%B9%A0%EF%BC%9A%E8%82%A0%E7%99%8C%E5%9B%BE%E5%83%8F%E5%88%86%E7%B1%BB%E4%BB%BB%E5%8A%A1%EF%BC%88%E4%B8%8B%EF%BC%89%E2%80%94%E2%80%94%E8%81%94%E9%82%A6%E5%8C%96/"/>
    <id>https://guoyujian.github.io/2022/11/04/FATE%E6%A8%AA%E5%90%91%E8%81%94%E9%82%A6%E5%AD%A6%E4%B9%A0%EF%BC%9A%E8%82%A0%E7%99%8C%E5%9B%BE%E5%83%8F%E5%88%86%E7%B1%BB%E4%BB%BB%E5%8A%A1%EF%BC%88%E4%B8%8B%EF%BC%89%E2%80%94%E2%80%94%E8%81%94%E9%82%A6%E5%8C%96/</id>
    <published>2022-11-03T16:08:29.000Z</published>
    <updated>2022-11-03T16:10:04.862Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>在上一篇已经在本地跑通了肠癌图像分类的整个流程，现在我们将它移植到FATE上，实现联邦学习。</p></blockquote><h1 id="数据预处理"><a href="#数据预处理" class="headerlink" title="数据预处理"></a>数据预处理</h1><p>仿照“手写数字识别”任务，将三份训练数据进行预处理。并新建配置文件，处理后的格式如图。</p><p><img src="image-20221101234910-nivm8sx.png" alt="image.png"></p><ul><li>code/： bind开头的文件是用于数据绑定；colon_conf是conf文件，colon_dsl是dsl文件</li><li>test/：500张测试数据</li><li>val/：500张验证集</li><li><p>train_pX/：第X份训练数据，每一份3000张</p><ul><li>images/：图片文件夹，存放所有图像</li><li>config.yaml：图片文件夹配置：通道数，格式等。</li><li>filenames：images目录下的所有文件名（去掉后缀），每个文件名占一行</li><li>targets：images目录下的所有文件名（去掉后缀）和label，逗号区分，每个文件名和类别占一行。</li></ul></li></ul><h1 id="修改源代码"><a href="#修改源代码" class="headerlink" title="修改源代码"></a>修改源代码</h1><p>之前在分析源码时，可以看到homo_nn的模型配置比较定制化，不够灵活，因此我们修改源码实现：</p><ol><li>修改数据加载</li><li>使用预训练的vgg16算法模型；</li><li>使用GPU</li><li>实现模型评估</li></ol><h2 id="修改数据加载"><a href="#修改数据加载" class="headerlink" title="修改数据加载"></a>修改数据加载</h2><p>我们知道vgg16传入的图像尺寸为$224<em>224</em>3$，而肠癌数据集的图像格式大小为$768<em>768</em>3$，所以需要先对数据加载进行修改：</p><p>修改FATE/python/federatedml/nn/backend/pytorch/data.py的<code>VisionDataSet</code>类的<strong>get_item</strong>方法：</p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">__getitem__</span>(<span class="params">self, index</span>):</span><br><span class="line"></span><br><span class="line">    img = Image.<span class="built_in">open</span>(self.images[index]).convert(self._PIL_mode)</span><br><span class="line">    <span class="keyword">if</span> img.size[<span class="number">0</span>] &gt; <span class="number">224</span>:</span><br><span class="line">        resize_transform = torchvision.transforms.Compose(</span><br><span class="line">            [</span><br><span class="line">                torchvision.transforms.Resize(<span class="number">256</span>),</span><br><span class="line">                torchvision.transforms.CenterCrop(<span class="number">224</span>),</span><br><span class="line">            ]</span><br><span class="line">        )</span><br><span class="line">        img = resize_transform(img)</span><br><span class="line">    <span class="keyword">if</span> self.targets_is_image:</span><br><span class="line">        target = Image.<span class="built_in">open</span>(self.targets[index])</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        target = self.targets[index]</span><br><span class="line">    <span class="keyword">return</span> self.transforms(img, target)</span><br></pre></td></tr></table></figure><h2 id="修改算法模型"><a href="#修改算法模型" class="headerlink" title="修改算法模型"></a>修改算法模型</h2><p>我们需要修改homo<em>nn组件下的<em>torch.py文件，<code>FedLightModule</code>类的__init</em></em>方法</p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># --------- 修改前 ----------</span></span><br><span class="line"><span class="comment"># self.model = nn.Sequential(*layers)</span></span><br><span class="line"><span class="comment"># --------- 修改后 ----------</span></span><br><span class="line"><span class="comment"># 这里非常定制化，out_features=2是针对本二分类任务，如果需要更灵活的传参，可以读取配置文件的配置</span></span><br><span class="line">LOGGER.info(<span class="string">&quot;define vgg16&quot;</span>)</span><br><span class="line">self.model = models.vgg16(pretrained=<span class="literal">True</span>)</span><br><span class="line">self.model.classifier[<span class="number">6</span>] = nn.Linear(in_features=<span class="number">4096</span>, out_features=<span class="number">2</span>, bias=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure><h2 id="使用GPU"><a href="#使用GPU" class="headerlink" title="使用GPU"></a>使用GPU</h2><p>需要修改homo_nn组件下的_torch.py文件，<code>FedLightModule</code>类的training_step、validation_step以及do_convergence_check和encrypt方法。改动如下。</p><blockquote><p>do_convergence_check和encrypt要改动的原因并不清楚，大致来看，应该是在model聚合和加密的时候需要将其从GPU中取出。。不过可以肯定，如此改动就会生效。</p></blockquote><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">validation_step</span>(<span class="params">self, batch, batch_idx</span>):</span><br><span class="line">    x, y = batch</span><br><span class="line">    <span class="comment"># -------------- add start ------------------</span></span><br><span class="line">    device = torch.device(<span class="string">&#x27;cuda&#x27;</span> <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> <span class="string">&#x27;cpu&#x27;</span>)</span><br><span class="line">    <span class="comment"># LOGGER.info(f&#x27;device:&#123;device&#125;&#x27;)</span></span><br><span class="line">    x, y = x.to(device), y.to(device)</span><br><span class="line">    <span class="comment"># -------------- add end ------------------</span></span><br><span class="line">    y_hat = self.forward(x)</span><br><span class="line">    loss = self.loss_fn(y_hat, y)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> y_hat.shape[<span class="number">1</span>] &gt; <span class="number">1</span>:</span><br><span class="line">        accuracy = (y_hat.argmax(dim=<span class="number">1</span>) == y).<span class="built_in">sum</span>().<span class="built_in">float</span>() / <span class="built_in">float</span>(y.size(<span class="number">0</span>))</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        y_prob = y_hat[:, <span class="number">0</span>] &gt; <span class="number">0.5</span></span><br><span class="line">        accuracy = (y == y_prob).<span class="built_in">sum</span>().<span class="built_in">float</span>() / y.size(<span class="number">0</span>)</span><br><span class="line">    <span class="keyword">return</span> &#123;<span class="string">&quot;val_loss&quot;</span>: loss, <span class="string">&quot;val_accuracy&quot;</span>: accuracy&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">training_step</span>(<span class="params">self, batch, batch_idx</span>):</span><br><span class="line">    x, y = batch</span><br><span class="line">    <span class="comment"># -------------- add start ------------------</span></span><br><span class="line">    device = torch.device(<span class="string">&#x27;cuda&#x27;</span> <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> <span class="string">&#x27;cpu&#x27;</span>)</span><br><span class="line">    x, y = x.to(device), y.to(device)</span><br><span class="line">    self.model = self.model.to(device)</span><br><span class="line">    <span class="comment"># -------------- add end ------------------</span></span><br><span class="line">    y_hat = self.model(x)</span><br><span class="line">    <span class="comment"># LOGGER.info(&#x27;y_hat: &#123;&#125;&#x27;.format(y_hat.detach().numpy()))</span></span><br><span class="line">    loss = self.loss_fn(y_hat, y)</span><br><span class="line">    self.log(<span class="string">&quot;train_loss&quot;</span>, loss)</span><br><span class="line">    <span class="keyword">return</span> loss</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">do_convergence_check</span>(<span class="params">self, weight, loss</span>):</span><br><span class="line">    <span class="comment"># loss_value = loss.detach().numpy().tolist()</span></span><br><span class="line">    loss_value = loss.detach().cpu().numpy().tolist()</span><br><span class="line"></span><br><span class="line">    self.loss_summary.append(loss_value)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># send loss to server</span></span><br><span class="line">    self.send_loss(loss_value, weight)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># recv convergence status</span></span><br><span class="line">    status = self.recv_loss()</span><br><span class="line">    <span class="keyword">return</span> status</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">encrypt</span>(<span class="params">self, tensor: torch.Tensor, weight</span>):</span><br><span class="line">    <span class="keyword">return</span> self.random_padding_cipher.encrypt(</span><br><span class="line"><span class="comment"># torch.clone(tensor).detach().mul_(weight)</span></span><br><span class="line">        torch.clone(tensor).detach().mul_(weight).cpu()</span><br><span class="line">    ).numpy()</span><br></pre></td></tr></table></figure><h2 id="模型评估"><a href="#模型评估" class="headerlink" title="模型评估"></a>模型评估</h2><p>以下是一个简单的模型评估代码，在homo_nn文件夹下新建evaluation.py，代码及注释如下</p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 导入必要的库，注意这里需要导入homo_nn下的FedLightModule类</span></span><br><span class="line"><span class="comment"># 如果库不存在，需要在fate-flow容器下pip安装</span></span><br><span class="line"><span class="keyword">from</span> federatedml.nn.homo_nn._torch <span class="keyword">import</span> FedLightModule</span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> DataLoader, Dataset, random_split</span><br><span class="line"><span class="keyword">from</span> torchvision <span class="keyword">import</span> datasets, models, transforms</span><br><span class="line"><span class="keyword">from</span> tqdm <span class="keyword">import</span> tqdm</span><br><span class="line"><span class="keyword">import</span> os </span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> nn</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> base64</span><br><span class="line"><span class="comment"># import cv2</span></span><br><span class="line"><span class="keyword">from</span> io <span class="keyword">import</span> BytesIO</span><br><span class="line"></span><br><span class="line"><span class="comment"># dataset</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">My_Dataset</span>(<span class="title class_ inherited__">Dataset</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, image_path, target</span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        self.image_path = image_path</span><br><span class="line">        self.target = target</span><br><span class="line">  </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__len__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">len</span>(self.image_path)</span><br><span class="line">  </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__getitem__</span>(<span class="params">self, index</span>):</span><br><span class="line">        path = self.image_path[index]</span><br><span class="line">        img = Image.<span class="built_in">open</span>(path).convert(<span class="string">&#x27;RGB&#x27;</span>)</span><br><span class="line">        resize_transform = transforms.Compose([</span><br><span class="line">            transforms.Resize(<span class="number">256</span>),</span><br><span class="line">            transforms.CenterCrop(<span class="number">224</span>),</span><br><span class="line">        ])</span><br><span class="line"></span><br><span class="line">        toTensor_transform = transforms.Compose([</span><br><span class="line">            transforms.ToTensor()</span><br><span class="line">        ])</span><br><span class="line">        label = self.target[index]</span><br><span class="line">        <span class="keyword">if</span> img.size[<span class="number">0</span>] &gt; <span class="number">224</span>:</span><br><span class="line">            img = resize_transform(img)</span><br><span class="line">        img = toTensor_transform(img)</span><br><span class="line">        <span class="keyword">return</span> img, label</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># test</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">test_model</span>(<span class="params">test_loader, model, criterion, device</span>):</span><br><span class="line">    model.<span class="built_in">eval</span>()</span><br><span class="line">  </span><br><span class="line">    true_labels = []</span><br><span class="line">    pred_labels = []</span><br><span class="line">    scores = []</span><br><span class="line"></span><br><span class="line">    size = <span class="built_in">len</span>(test_loader.dataset)</span><br><span class="line">    num_batches = <span class="built_in">len</span>(test_loader)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&#x27;size:<span class="subst">&#123;size&#125;</span>; num_batches:<span class="subst">&#123;num_batches&#125;</span>&#x27;</span>)</span><br><span class="line">    losses, correct = <span class="number">0</span>, <span class="number">0</span></span><br><span class="line">    <span class="comment"># log_loss = 0</span></span><br><span class="line">    <span class="comment">################################# validation #################################</span></span><br><span class="line">    <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">        <span class="keyword">for</span> batch, (x, y) <span class="keyword">in</span> <span class="built_in">enumerate</span>(tqdm(test_loader)):</span><br><span class="line">            device = torch.device(device)</span><br><span class="line">            x, y = x.to(device), y.to(device)</span><br><span class="line">            pred = model(x)</span><br><span class="line">            loss = criterion(pred, y.long().squeeze()) </span><br><span class="line">            current = batch * <span class="built_in">len</span>(x)</span><br><span class="line">            scores += pred.tolist()</span><br><span class="line">            y_pred, y_true = torch.argmax(pred, axis=<span class="number">1</span>), y.long().squeeze()</span><br><span class="line">            correct += (y_pred == y_true).<span class="built_in">type</span>(torch.<span class="built_in">float</span>).<span class="built_in">sum</span>().item()</span><br><span class="line">            loss, current = np.<span class="built_in">round</span>(loss.item(), <span class="number">5</span>), batch * <span class="built_in">len</span>(x)</span><br><span class="line">            true_labels += y_true.detach().cpu().tolist()</span><br><span class="line">            pred_labels += y_pred.detach().cpu().tolist()</span><br><span class="line">            losses += loss</span><br><span class="line">    correct /= size</span><br><span class="line">    losses /= num_batches</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&#x27;losses:<span class="subst">&#123;losses&#125;</span>\n&#x27;</span>)</span><br><span class="line">    metrics = <span class="string">f&quot;Test: Accuracy: <span class="subst">&#123;(<span class="number">100</span>*correct):&gt;<span class="number">0.2</span>f&#125;</span>%, Avg loss: <span class="subst">&#123;losses:&gt;5f&#125;</span> \n&quot;</span></span><br><span class="line">    <span class="keyword">return</span> np.array(true_labels), np.array(pred_labels), np.array(scores), metrics</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">model_path: model path</span></span><br><span class="line"><span class="string">res_path: save csv path，保存预测的数据结果</span></span><br><span class="line"><span class="string">metric_path: mertic path，保存模型评估结果</span></span><br><span class="line"><span class="string">typ : predict or test，test是评估模型，需要输出模型的评估指标，predict是单纯的对未知label数据进行预测</span></span><br><span class="line"><span class="string">test_path: test data path，测试数据集path，默认和train是相同的组织形式</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">evaluation</span>(<span class="params">model_path, res_path, metric_path,  typ, test_path</span>):</span><br><span class="line">    model = FedLightModule.load_from_checkpoint(model_path)</span><br><span class="line">    test_images_over = []</span><br><span class="line">    test_labels_over = []</span><br><span class="line">    <span class="keyword">if</span> typ == <span class="string">&#x27;test&#x27;</span>:</span><br><span class="line">        <span class="keyword">with</span> <span class="built_in">open</span>(os.path.join(test_path, <span class="string">&#x27;targets&#x27;</span>), <span class="string">&#x27;r&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">            line = f.readline()</span><br><span class="line">            <span class="keyword">while</span> line:</span><br><span class="line">                filename = line.split(<span class="string">&#x27;,&#x27;</span>)[<span class="number">0</span>] + <span class="string">&#x27;.jpg&#x27;</span></span><br><span class="line">                target = <span class="built_in">int</span>(line.split(<span class="string">&#x27;,&#x27;</span>)[-<span class="number">1</span>].replace(<span class="string">&#x27;\n&#x27;</span>,<span class="string">&#x27;&#x27;</span>))</span><br><span class="line">                test_images_over.append(os.path.join(test_path, <span class="string">&#x27;images&#x27;</span>, filename))</span><br><span class="line">                test_labels_over.append(target)</span><br><span class="line">                line = f.readline()</span><br><span class="line">    <span class="keyword">elif</span> typ == <span class="string">&#x27;predict&#x27;</span>:</span><br><span class="line">        <span class="keyword">with</span> <span class="built_in">open</span>(os.path.join(test_path, <span class="string">&#x27;filenames&#x27;</span>), <span class="string">&#x27;r&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">            line = f.readline()</span><br><span class="line">            <span class="keyword">while</span> line:</span><br><span class="line">                filename = line.replace(<span class="string">&#x27;\n&#x27;</span>, <span class="string">&#x27;&#x27;</span>) + <span class="string">&#x27;.jpg&#x27;</span></span><br><span class="line">                target = <span class="number">0</span></span><br><span class="line">                test_images_over.append(os.path.join(test_path, <span class="string">&#x27;images&#x27;</span>, filename))</span><br><span class="line">                test_labels_over.append(target)</span><br><span class="line">                line = f.readline()</span><br><span class="line">    test_dataset = My_Dataset(test_images_over, test_labels_over)</span><br><span class="line">    test_loader = DataLoader(test_dataset, batch_size=<span class="number">32</span>)</span><br><span class="line">    loss_fn = nn.CrossEntropyLoss()</span><br><span class="line">    <span class="comment"># device = torch.device(&#x27;cuda&#x27; if torch.cuda.is_available() else &#x27;cpu&#x27;)</span></span><br><span class="line">    device = <span class="string">&#x27;cpu&#x27;</span></span><br><span class="line">    true_labels, pred_labels, scores, metrics = test_model(test_loader, model, loss_fn, device)</span><br><span class="line"></span><br><span class="line">    l = <span class="built_in">len</span>(true_labels)</span><br><span class="line">    <span class="keyword">if</span> typ == <span class="string">&#x27;test&#x27;</span>:</span><br><span class="line">        <span class="keyword">with</span> <span class="built_in">open</span>(metric_path, <span class="string">&#x27;w&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">            f.write(<span class="string">f&#x27;<span class="subst">&#123;metrics&#125;</span>\n&#x27;</span>)</span><br><span class="line">        <span class="keyword">with</span> <span class="built_in">open</span>(res_path, <span class="string">&#x27;w&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">            f.write(<span class="string">&#x27;true_label,pred_label,score\n&#x27;</span>)</span><br><span class="line">            <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(l):</span><br><span class="line">                true_label, pred_label, score = true_labels[i], pred_labels[i], scores[i]</span><br><span class="line">                f.write(<span class="string">f&#x27;<span class="subst">&#123;true_label&#125;</span>,<span class="subst">&#123;pred_label&#125;</span>,<span class="subst">&#123;score&#125;</span>\n&#x27;</span>)</span><br><span class="line">    <span class="keyword">elif</span> typ == <span class="string">&#x27;predict&#x27;</span>:</span><br><span class="line">        <span class="keyword">with</span> <span class="built_in">open</span>(res_path, <span class="string">&#x27;w&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">            f.write(<span class="string">&#x27;pred_label,score\n&#x27;</span>)</span><br><span class="line">            <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(l):</span><br><span class="line">                true_label, pred_label, score = true_labels[i], pred_labels[i], scores[i]</span><br><span class="line">                f.write(<span class="string">f&#x27;<span class="subst">&#123;pred_label&#125;</span>,<span class="subst">&#123;score&#125;</span>\n&#x27;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    res_path = <span class="string">&quot;./123.csv&quot;</span></span><br><span class="line">    metric_path = <span class="string">&quot;./123.txt&quot;</span></span><br><span class="line">    typ = <span class="string">&quot;test&quot;</span></span><br><span class="line">    path = <span class="string">&quot;/data/projects/fate/examples/gwork/colon/test&quot;</span></span><br><span class="line">    model_path = <span class="string">&#x27;&#x27;</span></span><br><span class="line">    evaluation(model_path, res_path, metric_path,  typ, path)</span><br></pre></td></tr></table></figure><p>代码修改完毕。下面进行训练。</p><h1 id="联邦学习"><a href="#联邦学习" class="headerlink" title="联邦学习"></a>联邦学习</h1><p>分别修改CONF和DSL配置</p><h2 id="colon-conf-json"><a href="#colon-conf-json" class="headerlink" title="colon_conf.json"></a>colon_conf.json</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">&#123;</span><br><span class="line">    <span class="string">&quot;dsl_version&quot;</span>: <span class="number">2</span>,</span><br><span class="line">    <span class="string">&quot;initiator&quot;</span>: &#123;</span><br><span class="line">        <span class="string">&quot;role&quot;</span>: <span class="string">&quot;guest&quot;</span>,</span><br><span class="line">        <span class="string">&quot;party_id&quot;</span>: <span class="number">9999</span></span><br><span class="line">    &#125;,</span><br><span class="line">    <span class="string">&quot;role&quot;</span>: &#123;</span><br><span class="line">        <span class="string">&quot;arbiter&quot;</span>: [</span><br><span class="line">            <span class="number">10000</span></span><br><span class="line">        ],</span><br><span class="line">        <span class="string">&quot;host&quot;</span>: [</span><br><span class="line">            <span class="number">9998</span>,<span class="number">9997</span></span><br><span class="line">        ],</span><br><span class="line">        <span class="string">&quot;guest&quot;</span>: [</span><br><span class="line">            <span class="number">9999</span></span><br><span class="line">        ]</span><br><span class="line">    &#125;,</span><br><span class="line">    <span class="string">&quot;component_parameters&quot;</span>: &#123;</span><br><span class="line">        <span class="string">&quot;common&quot;</span>: &#123;</span><br><span class="line">            <span class="string">&quot;homo_nn_0&quot;</span>: &#123;</span><br><span class="line">                <span class="string">&quot;api_version&quot;</span>: <span class="number">2</span>,</span><br><span class="line">                <span class="string">&quot;encode_label&quot;</span>: true,</span><br><span class="line">                <span class="string">&quot;max_iter&quot;</span>: <span class="number">2</span>,</span><br><span class="line">                <span class="string">&quot;batch_size&quot;</span>: <span class="number">32</span>,</span><br><span class="line">                <span class="string">&quot;optimizer&quot;</span>: &#123;</span><br><span class="line">                    <span class="string">&quot;lr&quot;</span>: <span class="number">0.000001</span>,</span><br><span class="line">                    <span class="string">&quot;optimizer&quot;</span>: <span class="string">&quot;Adam&quot;</span></span><br><span class="line">                &#125;,</span><br><span class="line">                <span class="string">&quot;loss&quot;</span>: <span class="string">&quot;CrossEntropyLoss&quot;</span>,</span><br><span class="line">                <span class="string">&quot;metrics&quot;</span>: [</span><br><span class="line">                    <span class="string">&quot;accuracy&quot;</span></span><br><span class="line">                ],</span><br><span class="line">                <span class="string">&quot;nn_define&quot;</span>: [</span><br><span class="line">                ],</span><br><span class="line">                <span class="string">&quot;config_type&quot;</span>: <span class="string">&quot;pytorch&quot;</span></span><br><span class="line">            &#125;</span><br><span class="line">        &#125;,</span><br><span class="line">        <span class="string">&quot;role&quot;</span>: &#123;</span><br><span class="line">            <span class="string">&quot;host&quot;</span>: &#123;</span><br><span class="line">                <span class="string">&quot;0&quot;</span>: &#123;</span><br><span class="line">                    <span class="string">&quot;reader_0&quot;</span>: &#123;</span><br><span class="line">                        <span class="string">&quot;table&quot;</span>: &#123;</span><br><span class="line">                            <span class="string">&quot;name&quot;</span>: <span class="string">&quot;colon_images_0&quot;</span>,</span><br><span class="line">                            <span class="string">&quot;namespace&quot;</span>: <span class="string">&quot;experiment&quot;</span></span><br><span class="line">                        &#125;</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;,</span><br><span class="line">      <span class="string">&quot;1&quot;</span>: &#123;</span><br><span class="line">                    <span class="string">&quot;reader_0&quot;</span>: &#123;</span><br><span class="line">                        <span class="string">&quot;table&quot;</span>: &#123;</span><br><span class="line">                            <span class="string">&quot;name&quot;</span>: <span class="string">&quot;colon_images_1&quot;</span>,</span><br><span class="line">                            <span class="string">&quot;namespace&quot;</span>: <span class="string">&quot;experiment&quot;</span></span><br><span class="line">                        &#125;</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;,</span><br><span class="line">            <span class="string">&quot;guest&quot;</span>: &#123;</span><br><span class="line">                <span class="string">&quot;0&quot;</span>: &#123;</span><br><span class="line">                    <span class="string">&quot;reader_0&quot;</span>: &#123;</span><br><span class="line">                        <span class="string">&quot;table&quot;</span>: &#123;</span><br><span class="line">                            <span class="string">&quot;name&quot;</span>: <span class="string">&quot;colon_images_2&quot;</span>,</span><br><span class="line">                            <span class="string">&quot;namespace&quot;</span>: <span class="string">&quot;experiment&quot;</span></span><br><span class="line">                        &#125;</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure><h2 id="colon-dsl-json"><a href="#colon-dsl-json" class="headerlink" title="colon_dsl.json"></a>colon_dsl.json</h2><p>略</p><p>首先数据已经处理成FATE可以读取的格式。</p><p>然后将三份数据分发到集群的三台不同的机器上，分别是fate9999，fate9998，以及fate9997</p><p>进入三台机器的fate-client container，使用flow table bind -c 命令将文件夹绑定到table。</p><p>在发起方FATE9999的client容器中，进入code文件夹，执行<code>flow job submit -c colon_conf.json -d colon_dsl.json</code>启动任务</p><p>查看FATE-BOARD Job</p><p>他的homo_nn组件输出的日志如下：</p><p><img src="image-20221014121445-6gzta7m.png" alt="image.png"></p><h1 id="模型评估-1"><a href="#模型评估-1" class="headerlink" title="模型评估"></a>模型评估</h1><p>在job结束后，会保存check point，保存的容器为fate-flow container。</p><p>以fate9999为例，保存路径为：</p><p>/data/projects/fate/fateflow/jobs/202210131350059277200/guest/9999/homo_cv_0/202210131350059277200_homo_cv_0/0/task_executor/7f86f6064aff11edbd540242c0a70064/model.ckpt</p><blockquote><p>不同角色（guset、host）、不同party_id的机器上路径可能有所差异。</p></blockquote><p>将该路径复制到刚才的evaluation.py的model_path中，执行<code>python evaluation.py</code>，查看输出结果：</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">Accuracy: 99.20%, Avg loss: 0.022641</span><br></pre></td></tr></table></figure><h1 id="实验结果"><a href="#实验结果" class="headerlink" title="实验结果"></a>实验结果</h1><p>结合baseline的实验结果，可以得到下表。</p><div class="table-container"><table><thead><tr><th>使用的数据</th><th>训练类型</th><th>模型评估</th></tr></thead><tbody><tr><td>全部训练数据（Train_1+Train_2+Train_3）</td><td>本地（GPU）</td><td>Accuracy: 99.60%, Avg loss: 0.011775</td></tr><tr><td>Train_1</td><td>本地（GPU）</td><td>Accuracy: 73.20%, Avg loss: 0.641481</td></tr><tr><td>Train_2</td><td>本地（GPU）</td><td>Accuracy: 71.40%, Avg loss: 0.649055</td></tr><tr><td>Train_3</td><td>本地（GPU）</td><td>Accuracy: 56.80%, Avg loss: 0.654335</td></tr><tr><td>全部训练数据（Train_1+Train_2+Train_3）</td><td>联邦（GPU）</td><td>Accuracy: 99.20%, Avg loss: 0.022641</td></tr></tbody></table></div><p>在增加了部分读写日志，并加以分析可以得到训练的时间分布：</p><p><img src="image-20221102004157-5zhbj13.png" alt="image.png"></p><h1 id="实验分析"><a href="#实验分析" class="headerlink" title="实验分析"></a>实验分析</h1><ol><li><p>使用联邦学习的效果要优于分开训练的模型效果，证明了联邦学习的有效性。</p></li><li><p>做实验发现，使用CPU进行训练，每个epoch需要大约15分钟，而使用GPU之后，每个epoch仅需要29s左右。使用GPU的计算效率要远远大于使用CPU。</p></li><li><p>对日志进行分析发现，计算时间约为60s，模型参数加密、解密以及传输的时间约为比例约为600s，二者比例约为1:10。因此可以得出结论：结肠癌联邦学习的时间瓶颈不在于本地模型的训练时间，而是在于模型参数加密、解密以及传输时间。</p></li></ol><h1 id="补充"><a href="#补充" class="headerlink" title="补充"></a>补充</h1><p>修改了homo_nn的源码，导致原有的homo_nn的功能失效，所以这里不推荐这样改，更推荐开发新的组件来完成。</p><p>‍</p>]]></content>
    
    
      
      
    <summary type="html">&lt;blockquote&gt;
&lt;p&gt;在上一篇已经在本地跑通了肠癌图像分类的整个流程，现在我们将它移植到FATE上，实现联邦学习。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h1 id=&quot;数据预处理&quot;&gt;&lt;a href=&quot;#数据预处理&quot; class=&quot;headerlink&quot; title=&quot;数</summary>
      
    
    
    
    <category term="联邦学习" scheme="https://guoyujian.github.io/categories/%E8%81%94%E9%82%A6%E5%AD%A6%E4%B9%A0/"/>
    
    
    <category term="联邦学习" scheme="https://guoyujian.github.io/tags/%E8%81%94%E9%82%A6%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>FATE横向联邦学习：肠癌图像分类任务（上）——baseline</title>
    <link href="https://guoyujian.github.io/2022/11/04/FATE%E6%A8%AA%E5%90%91%E8%81%94%E9%82%A6%E5%AD%A6%E4%B9%A0%EF%BC%9A%E8%82%A0%E7%99%8C%E5%9B%BE%E5%83%8F%E5%88%86%E7%B1%BB%E4%BB%BB%E5%8A%A1%EF%BC%88%E4%B8%8A%EF%BC%89%E2%80%94%E2%80%94baseline/"/>
    <id>https://guoyujian.github.io/2022/11/04/FATE%E6%A8%AA%E5%90%91%E8%81%94%E9%82%A6%E5%AD%A6%E4%B9%A0%EF%BC%9A%E8%82%A0%E7%99%8C%E5%9B%BE%E5%83%8F%E5%88%86%E7%B1%BB%E4%BB%BB%E5%8A%A1%EF%BC%88%E4%B8%8A%EF%BC%89%E2%80%94%E2%80%94baseline/</id>
    <published>2022-11-03T16:07:00.000Z</published>
    <updated>2022-11-03T16:08:08.651Z</updated>
    
    <content type="html"><![CDATA[<p>本案例分上下两篇，上篇介绍肠癌图像分类任务的本地baseline，下篇介绍将肠癌图像分类任务移植到FATE上，实现联邦学习。</p><h1 id="任务目标"><a href="#任务目标" class="headerlink" title="任务目标"></a>任务目标</h1><ol><li>使用FATE开发新的组件，实现图像横向联邦学习</li><li>证明联邦学习有效</li></ol><h1 id="任务介绍"><a href="#任务介绍" class="headerlink" title="任务介绍"></a>任务介绍</h1><p>该任务将开发基于结肠的组织病理学图像正确判断是良性组织或者结肠癌的二分类算法。</p><h2 id="数据集"><a href="#数据集" class="headerlink" title="数据集"></a>数据集</h2><p>数据集来自于<a href="https://www.kaggle.com/datasets/andrewmvd/lung-and-colon-cancer-histopathological-images的colon_image_sets">https://www.kaggle.com/datasets/andrewmvd/lung-and-colon-cancer-histopathological-images的colon_image_sets</a></p><p>本任务数据集由2个类别组成的10000张符合HIPAA标准的结肠组织病理学图像。所有图像的尺寸为$768 <em> 768 </em> 3$，为jpeg文件格式。</p><p>为了进行实验，需要对数据进行划分：步骤如下：</p><ol><li><p>数据shuffle。</p></li><li><p>分为五个子集，包含三份训练集子集，命名为Train_1, Train_2, Train_3，训练集子集各三千张图像，一份验证集和一份测试集各500张，分别命名为val和test。（这里我没有对图像本身进行改动，而是生成了一个excel，每个sheet包含image_path和type两列，分别对应图像的位置和label，一共有input1，input2，input3，val和test五个sheet页）</p></li></ol><p>三份训练数据和一份测试数据对应的三种类型的图像数量如下：</p><div class="table-container"><table><thead><tr><th>Data</th><th>结肠癌组织</th><th>良性组织</th><th>总计</th></tr></thead><tbody><tr><td>Train_1</td><td>1505</td><td>1495</td><td>3000</td></tr><tr><td>Train_2</td><td>1467</td><td>1533</td><td>3000</td></tr><tr><td>Train_3</td><td>1515</td><td>1485</td><td>3000</td></tr><tr><td>Test</td><td>253</td><td>247</td><td>500</td></tr><tr><td>总计（不算Test）</td><td>4487</td><td>4513</td><td>/</td></tr></tbody></table></div><h2 id="算法"><a href="#算法" class="headerlink" title="算法"></a>算法</h2><p>为了保证单一变量影响，在本地训练和联邦训练的模型参数相同，具体参数如下表</p><div class="table-container"><table><thead><tr><th>key</th><th>val</th></tr></thead><tbody><tr><td>平台</td><td>kaggle</td></tr><tr><td>算法</td><td>基于ImageNet1K预训练的vgg16模型</td></tr><tr><td>Epoch</td><td>2</td></tr><tr><td>Batch Size</td><td>16 or 32</td></tr><tr><td>Optimizer</td><td>Adam</td></tr><tr><td>Learning Rate</td><td>1e-5</td></tr><tr><td>Loss</td><td>CrossEntropyLoss</td></tr><tr><td>Metrics</td><td>Accuracy</td></tr></tbody></table></div><h1 id="实验步骤"><a href="#实验步骤" class="headerlink" title="实验步骤"></a>实验步骤</h1><ol><li><p>使用全部训练集在本地进行训练，在测试集进行模型评估。</p></li><li><p>分别使用三份训练集子集在本地进行训练，在测试集进行模型评估。</p></li><li><p>使用FATE对三份训练集子集进行联邦训练，在测试集上进行模型评估。</p></li></ol><h1 id="Code"><a href="#Code" class="headerlink" title="Code"></a>Code</h1><blockquote><p>这里只列出重要的code，详细code可以参见：<a href="https://www.kaggle.com/code/guoyujian/colon-cancer101">https://www.kaggle.com/code/guoyujian/colon-cancer101</a></p></blockquote><h2 id="define-params"><a href="#define-params" class="headerlink" title="define params"></a>define params</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">EPOCHS = <span class="number">2</span></span><br><span class="line">BATCH_SIZE = <span class="number">32</span></span><br><span class="line">lr = <span class="number">1e-5</span></span><br><span class="line"></span><br><span class="line">device = torch.device(<span class="string">&#x27;cuda&#x27;</span> <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> <span class="string">&#x27;cpu&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(device)</span><br></pre></td></tr></table></figure><h2 id="加载数据"><a href="#加载数据" class="headerlink" title="加载数据"></a>加载数据</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 从元数据中读取图像的path和label</span></span><br><span class="line">metadata_path = <span class="string">&#x27;../input/input-colon/colon_inputs.xls&#x27;</span></span><br><span class="line"><span class="comment"># metadata_path = &#x27;../input/input-colon-cuts/colon_inputs_cuts.xls&#x27;</span></span><br><span class="line">df1 = pd.read_excel(metadata_path, sheet_name = <span class="string">&#x27;input1&#x27;</span>)</span><br><span class="line">df2 = pd.read_excel(metadata_path, sheet_name = <span class="string">&#x27;input2&#x27;</span>)</span><br><span class="line">df3 = pd.read_excel(metadata_path, sheet_name = <span class="string">&#x27;input3&#x27;</span>)</span><br><span class="line">df4 = pd.read_excel(metadata_path, sheet_name = <span class="string">&#x27;val&#x27;</span>)</span><br><span class="line">df5 = pd.read_excel(metadata_path, sheet_name = <span class="string">&#x27;test&#x27;</span>)</span><br><span class="line">df = pd.concat([df1, df2, df3])</span><br><span class="line"></span><br><span class="line">df.head()</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 全部的图片路径和标签</span></span><br><span class="line"><span class="comment"># images_all_over = df[&#x27;image_path&#x27;].to_list()</span></span><br><span class="line">images_all_over = []</span><br><span class="line"><span class="keyword">for</span> item <span class="keyword">in</span> df[<span class="string">&#x27;image_path&#x27;</span>]:</span><br><span class="line">    item = images_all_over.append(<span class="string">&#x27;../input/lung-and-colon-cancer-histopathological-images/lung_colon_image_set/colon_image_sets/&#x27;</span> + item)</span><br><span class="line">labels_all_over = df[<span class="string">&#x27;type&#x27;</span>].to_list()</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&#x27;len images_all_over: <span class="subst">&#123;<span class="built_in">len</span>(images_all_over)&#125;</span>; len labels_all_over: <span class="subst">&#123;<span class="built_in">len</span>(labels_all_over)&#125;</span>; &#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># part1,2,3 &amp; val</span></span><br><span class="line">images_1_over = []</span><br><span class="line"><span class="keyword">for</span> item <span class="keyword">in</span> df1[<span class="string">&#x27;image_path&#x27;</span>]:</span><br><span class="line">    item = images_1_over.append(<span class="string">&#x27;../input/lung-and-colon-cancer-histopathological-images/lung_colon_image_set/colon_image_sets/&#x27;</span> + item)</span><br><span class="line">labels_1_over = df1[<span class="string">&#x27;type&#x27;</span>].to_list()</span><br><span class="line"></span><br><span class="line">images_2_over = []</span><br><span class="line"><span class="keyword">for</span> item <span class="keyword">in</span> df2[<span class="string">&#x27;image_path&#x27;</span>]:</span><br><span class="line">    item = images_2_over.append(<span class="string">&#x27;../input/lung-and-colon-cancer-histopathological-images/lung_colon_image_set/colon_image_sets/&#x27;</span> + item)</span><br><span class="line">labels_2_over = df2[<span class="string">&#x27;type&#x27;</span>].to_list()</span><br><span class="line"></span><br><span class="line">images_3_over = []</span><br><span class="line"><span class="keyword">for</span> item <span class="keyword">in</span> df3[<span class="string">&#x27;image_path&#x27;</span>]:</span><br><span class="line">    item = images_3_over.append(<span class="string">&#x27;../input/lung-and-colon-cancer-histopathological-images/lung_colon_image_set/colon_image_sets/&#x27;</span> + item)</span><br><span class="line">labels_3_over = df3[<span class="string">&#x27;type&#x27;</span>].to_list()</span><br><span class="line"></span><br><span class="line">images_val_over = []</span><br><span class="line"><span class="keyword">for</span> item <span class="keyword">in</span> df4[<span class="string">&#x27;image_path&#x27;</span>]:</span><br><span class="line">    item = images_val_over.append(<span class="string">&#x27;../input/lung-and-colon-cancer-histopathological-images/lung_colon_image_set/colon_image_sets/&#x27;</span> + item)</span><br><span class="line">labels_val_over = df4[<span class="string">&#x27;type&#x27;</span>].to_list()</span><br><span class="line"></span><br><span class="line">images_test_over = []</span><br><span class="line"><span class="keyword">for</span> item <span class="keyword">in</span> df5[<span class="string">&#x27;image_path&#x27;</span>]:</span><br><span class="line">    item = images_test_over.append(<span class="string">&#x27;../input/lung-and-colon-cancer-histopathological-images/lung_colon_image_set/colon_image_sets/&#x27;</span> + item)</span><br><span class="line">labels_test_over = df5[<span class="string">&#x27;type&#x27;</span>].to_list()</span><br><span class="line"></span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 对全部数据shuffle</span></span><br><span class="line"></span><br><span class="line">shuffle_dataset = np.hstack((np.array(images_all_over).reshape(-<span class="number">1</span>, <span class="number">1</span>), np.array(labels_all_over).reshape(-<span class="number">1</span>, <span class="number">1</span>)))</span><br><span class="line">np.random.shuffle(shuffle_dataset)</span><br><span class="line">images_all_over = shuffle_dataset[:, <span class="number">0</span>].tolist()</span><br><span class="line">labels_all_over = shuffle_dataset[:, <span class="number">1</span>].astype(<span class="built_in">int</span>).tolist()</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#定义dataset类</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Colon_Dataset</span>(<span class="title class_ inherited__">Dataset</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, image_path, target, train_transform = <span class="literal">None</span>, test_transform = <span class="literal">None</span></span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        self.image_path = image_path</span><br><span class="line">        self.target = target</span><br><span class="line">        self.train_transform = train_transform</span><br><span class="line">        self.test_transform = test_transform</span><br><span class="line">        self.transform = <span class="literal">None</span></span><br><span class="line">  </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__len__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">len</span>(self.image_path)</span><br><span class="line">  </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__getitem__</span>(<span class="params">self, index</span>):</span><br><span class="line">        path = self.image_path[index]</span><br><span class="line">        image = cv2.imread(path)</span><br><span class="line">        label = self.target[index]</span><br><span class="line">        <span class="keyword">if</span> self.transform:</span><br><span class="line">            image = self.transform(image)</span><br><span class="line">        <span class="keyword">return</span> image, label</span><br><span class="line">  </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">train_mode</span>(<span class="params">self</span>):</span><br><span class="line">        self.transform = self.train_transform</span><br><span class="line">  </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">test_mode</span>(<span class="params">self</span>):</span><br><span class="line">        self.transform = self.test_transform</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># define data transform</span></span><br><span class="line">train_transform = transforms.Compose([</span><br><span class="line">    transforms.ToPILImage(),</span><br><span class="line">    transforms.Resize(<span class="number">256</span>),</span><br><span class="line">    transforms.CenterCrop(<span class="number">224</span>),</span><br><span class="line">    transforms.RandomHorizontalFlip(),</span><br><span class="line">    transforms.RandomRotation(<span class="number">10</span>),</span><br><span class="line">    transforms.ColorJitter(),</span><br><span class="line">    transforms.ToTensor(),</span><br><span class="line">])</span><br><span class="line"></span><br><span class="line">test_transform = transforms.Compose([</span><br><span class="line">    transforms.ToPILImage(),</span><br><span class="line">    transforms.Resize(<span class="number">256</span>),</span><br><span class="line">    transforms.CenterCrop(<span class="number">224</span>),</span><br><span class="line">    transforms.ToTensor()</span><br><span class="line">])</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 全部训练数据</span></span><br><span class="line">colon_all_dataset = Colon_Dataset(images_all_over, labels_all_over, train_transform, test_transform)</span><br><span class="line">train_loader = DataLoader(colon_all_dataset, batch_size=BATCH_SIZE)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 三份训练数据、验证数据和测试数据</span></span><br><span class="line">colon_1_dataset = Colon_Dataset(images_1_over, labels_1_over, train_transform, test_transform)</span><br><span class="line">colon_2_dataset = Colon_Dataset(images_2_over, labels_2_over, train_transform, test_transform)</span><br><span class="line">colon_3_dataset = Colon_Dataset(images_3_over, labels_3_over, train_transform, test_transform)</span><br><span class="line">colon_val_dataset = Colon_Dataset(images_val_over, labels_val_over, train_transform, test_transform)</span><br><span class="line">colon_test_dataset = Colon_Dataset(images_test_over, labels_test_over, train_transform, test_transform)</span><br><span class="line"></span><br><span class="line">train_1_loader = DataLoader(colon_1_dataset, batch_size=BATCH_SIZE)</span><br><span class="line">train_2_loader = DataLoader(colon_2_dataset, batch_size=BATCH_SIZE)</span><br><span class="line">train_3_loader = DataLoader(colon_3_dataset, batch_size=BATCH_SIZE)</span><br><span class="line">val_loader = DataLoader(colon_val_dataset, batch_size=BATCH_SIZE)</span><br><span class="line">test_loader = DataLoader(colon_test_dataset, batch_size=BATCH_SIZE)</span><br></pre></td></tr></table></figure><h2 id="define-a-model"><a href="#define-a-model" class="headerlink" title="define a model"></a>define a model</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">Model = models.vgg16(pretrained=<span class="literal">True</span>)</span><br><span class="line">Model.classifier[<span class="number">6</span>] = nn.Linear(in_features=<span class="number">4096</span>, out_features=<span class="number">2</span>, bias=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">Model = Model.to(device)</span><br><span class="line"></span><br><span class="line">optimizer = torch.optim.Adam(Model.parameters() , lr = lr)</span><br><span class="line"></span><br><span class="line">scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[<span class="number">10</span>, <span class="number">25</span>, <span class="number">50</span>, <span class="number">75</span>, <span class="number">120</span>], gamma=<span class="number">0.5</span>)</span><br><span class="line"></span><br><span class="line">loss_fn = nn.CrossEntropyLoss()</span><br></pre></td></tr></table></figure><h2 id="train-amp-val"><a href="#train-amp-val" class="headerlink" title="train&amp;val"></a>train&amp;val</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 训练一轮</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">train_one_epoch</span>(<span class="params">train_loader, model, criterion, optimizer, device</span>):</span><br><span class="line">    model.train()</span><br><span class="line">  </span><br><span class="line">    colon_all_dataset.train_mode()</span><br><span class="line">    colon_1_dataset.train_mode()</span><br><span class="line">    colon_2_dataset.train_mode()</span><br><span class="line">    colon_3_dataset.train_mode()</span><br><span class="line">    colon_val_dataset.train_mode()</span><br><span class="line">  </span><br><span class="line">    size = <span class="built_in">len</span>(train_loader.dataset)</span><br><span class="line">    num_batches = <span class="built_in">len</span>(train_loader)</span><br><span class="line">    losses, correct = <span class="number">0</span>, <span class="number">0</span></span><br><span class="line">    <span class="comment">################################# train #################################</span></span><br><span class="line">    <span class="keyword">for</span> batch, (x, y) <span class="keyword">in</span> <span class="built_in">enumerate</span>(tqdm(train_loader)):</span><br><span class="line">        device = torch.device(device)</span><br><span class="line">        x, y = x.to(device), y.to(device)  </span><br><span class="line">        optimizer.zero_grad()</span><br><span class="line">        pred = model(x)</span><br><span class="line"></span><br><span class="line">        loss = criterion(pred, y.long().squeeze())</span><br><span class="line"></span><br><span class="line">        current = batch * <span class="built_in">len</span>(x)</span><br><span class="line">        loss.backward()</span><br><span class="line">        optimizer.step()</span><br><span class="line">        y_pred, y_true = torch.argmax(pred, axis=<span class="number">1</span>), y.long().squeeze()</span><br><span class="line">        correct += (y_pred == y_true).<span class="built_in">type</span>(torch.<span class="built_in">float</span>).<span class="built_in">sum</span>().item()</span><br><span class="line">        losses += loss.item()</span><br><span class="line">    correct /= size</span><br><span class="line">    losses /= num_batches</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;Train: Accuracy: <span class="subst">&#123;(<span class="number">100</span>*correct):&gt;<span class="number">0.2</span>f&#125;</span>%, Avg loss: <span class="subst">&#123;losses:&gt;5f&#125;</span>&quot;</span>)</span><br><span class="line">    <span class="keyword">return</span> losses, correct</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 验证一轮， 验证集数据加载，模型，损失函数，device</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">valid_one_epoch</span>(<span class="params">valid_loader, model, criterion, device</span>):</span><br><span class="line">    model.<span class="built_in">eval</span>()</span><br><span class="line"></span><br><span class="line">    colon_all_dataset.train_mode()</span><br><span class="line">    colon_1_dataset.train_mode()</span><br><span class="line">    colon_2_dataset.train_mode()</span><br><span class="line">    colon_3_dataset.train_mode()</span><br><span class="line">    colon_val_dataset.train_mode()</span><br><span class="line">  </span><br><span class="line">    size = <span class="built_in">len</span>(valid_loader.dataset)</span><br><span class="line">    num_batches = <span class="built_in">len</span>(valid_loader)</span><br><span class="line">    losses, correct = <span class="number">0</span>, <span class="number">0</span></span><br><span class="line">    <span class="comment">################################# validation #################################</span></span><br><span class="line">    <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">        <span class="keyword">for</span> batch, (x, y) <span class="keyword">in</span> <span class="built_in">enumerate</span>(tqdm(valid_loader)):</span><br><span class="line">            device = torch.device(device)</span><br><span class="line">            x, y = x.to(device), y.to(device)</span><br><span class="line">            pred = model(x)</span><br><span class="line">            loss = criterion(pred, y.long().squeeze())</span><br><span class="line"></span><br><span class="line">            current = batch * <span class="built_in">len</span>(x)</span><br><span class="line">            y_pred, y_true = torch.argmax(pred, axis=<span class="number">1</span>), y.long().squeeze()</span><br><span class="line">            correct += (y_pred == y_true).<span class="built_in">type</span>(torch.<span class="built_in">float</span>).<span class="built_in">sum</span>().item()</span><br><span class="line">            losses += loss.item()</span><br><span class="line">    correct /= size</span><br><span class="line">    losses /= num_batches</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;Valid: Accuracy: <span class="subst">&#123;(<span class="number">100</span>*correct):&gt;<span class="number">0.2</span>f&#125;</span>%, Avg loss: <span class="subst">&#123;losses:&gt;5f&#125;</span> \n&quot;</span>)</span><br><span class="line">    <span class="keyword">return</span> losses, correct</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">train_valid</span>(<span class="params">train_loader,valid_loader, model, criterion, optimizer, scheduler, device, part = <span class="literal">None</span></span>):</span><br><span class="line">    liveloss = PlotLosses()</span><br><span class="line">  </span><br><span class="line">    tolerance = <span class="number">0</span></span><br><span class="line">    best_loss = np.inf</span><br><span class="line">    best_epoch = <span class="number">0</span></span><br><span class="line">    best_acc = <span class="number">0</span></span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;Starting Training...\n&#x27;</span>)</span><br><span class="line">    <span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>, EPOCHS):</span><br><span class="line">        logs = &#123;&#125;</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;-------------------------------   Epoch <span class="subst">&#123;epoch + <span class="number">1</span>&#125;</span>   -------------------------------&quot;</span>)</span><br><span class="line"></span><br><span class="line">        train_loss, train_acc = train_one_epoch(train_loader, model, criterion, optimizer, device)</span><br><span class="line">        valid_loss, valid_acc = valid_one_epoch(valid_loader, model, criterion, device)</span><br><span class="line">        scheduler.step()</span><br><span class="line">      </span><br><span class="line">        <span class="comment"># save validation loss if it was improved (reduced) &amp; validation accuracy if it was improved (increased)</span></span><br><span class="line">        <span class="keyword">if</span> valid_loss &lt; best_loss <span class="keyword">and</span> valid_acc &gt; best_acc:</span><br><span class="line">            best_epoch = epoch + <span class="number">1</span></span><br><span class="line">            best_loss = valid_loss</span><br><span class="line">            best_acc = valid_acc</span><br><span class="line">            <span class="comment"># save the model&#x27;s weights and biases</span></span><br><span class="line">            <span class="keyword">if</span> part:</span><br><span class="line">                torch.save(model, <span class="string">f&quot;vgg_ep<span class="subst">&#123;best_epoch&#125;</span>_part<span class="subst">&#123;part&#125;</span>.pth&quot;</span>)</span><br><span class="line">            <span class="keyword">else</span>: </span><br><span class="line">                torch.save(model, <span class="string">f&quot;vgg_ep<span class="subst">&#123;best_epoch&#125;</span>.pth&quot;</span>)</span><br><span class="line"></span><br><span class="line">      </span><br><span class="line">        <span class="keyword">if</span> valid_acc &lt; best_acc:</span><br><span class="line">            tolerance += <span class="number">1</span></span><br><span class="line">      </span><br><span class="line">        logs[<span class="string">&#x27;log loss&#x27;</span>] = train_loss</span><br><span class="line">        logs[<span class="string">&#x27;accuracy&#x27;</span>] = train_acc*<span class="number">100</span></span><br><span class="line">        logs[<span class="string">&#x27;val_log loss&#x27;</span>] = valid_loss</span><br><span class="line">        logs[<span class="string">&#x27;val_accuracy&#x27;</span>] = valid_acc*<span class="number">100</span></span><br><span class="line">      </span><br><span class="line">        liveloss.update(logs)</span><br><span class="line">        liveloss.send()</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;Done!&quot;</span>)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># train all</span></span><br><span class="line">train_valid(train_loader,val_loader, Model, loss_fn, optimizer, scheduler, device)</span><br></pre></td></tr></table></figure><p>可以看到模型拟合的很快</p><p><img src="image-20221101180725-qad0jfu.png" alt="image.png"></p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 3 parts train </span></span><br><span class="line">train_valid(train_1_loader,val_loader, Model, loss_fn, optimizer, scheduler, device, part = <span class="number">1</span>)</span><br><span class="line">train_valid(train_2_loader,val_loader, Model, loss_fn, optimizer, scheduler, device, part = <span class="number">2</span>)</span><br><span class="line">train_valid(train_3_loader,val_loader, Model, loss_fn, optimizer, scheduler, device, part = <span class="number">3</span>)</span><br></pre></td></tr></table></figure><h2 id="模型评估"><a href="#模型评估" class="headerlink" title="模型评估"></a>模型评估</h2><p>这里注意的是不需要先对pred进行softmax，在计算loss，而是直接计算loss：</p><p>Ref:<a href="https://blog.csdn.net/DragonGirI/article/details/105743487">pytorch 计算 CrossEntropyLoss 和 softmax 激活层</a></p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># test</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">test_model</span>(<span class="params">test_loader, model, criterion, device</span>):</span><br><span class="line">    model.<span class="built_in">eval</span>()</span><br><span class="line">    cervical_test_dataset.test_mode()</span><br><span class="line">  </span><br><span class="line">    true_labels = []</span><br><span class="line">    pred_labels = []</span><br><span class="line">    scores = []</span><br><span class="line"></span><br><span class="line">    size = <span class="built_in">len</span>(test_loader.dataset)</span><br><span class="line"></span><br><span class="line">    num_batches = <span class="built_in">len</span>(test_loader)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&#x27;size:<span class="subst">&#123;size&#125;</span>; num_batches:<span class="subst">&#123;num_batches&#125;</span>&#x27;</span>)</span><br><span class="line">    losses, correct = <span class="number">0</span>, <span class="number">0</span></span><br><span class="line">    <span class="comment">################################# validation #################################</span></span><br><span class="line">    <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">        <span class="keyword">for</span> batch, (x, y) <span class="keyword">in</span> <span class="built_in">enumerate</span>(tqdm(test_loader)):</span><br><span class="line">            device = torch.device(device)</span><br><span class="line">            x, y = x.to(device), y.to(device)</span><br><span class="line">            pred = model(x)</span><br><span class="line"><span class="comment">#             pred = nn.Softmax()(pred)</span></span><br><span class="line"></span><br><span class="line">            loss = criterion(pred, y.long().squeeze()) </span><br><span class="line">            current = batch * <span class="built_in">len</span>(x)</span><br><span class="line">            scores += pred.tolist()</span><br><span class="line">            y_pred, y_true = torch.argmax(pred, axis=<span class="number">1</span>), y.long().squeeze()</span><br><span class="line">            correct += (y_pred == y_true).<span class="built_in">type</span>(torch.<span class="built_in">float</span>).<span class="built_in">sum</span>().item()</span><br><span class="line">            loss, current = np.<span class="built_in">round</span>(loss.item(), <span class="number">5</span>), batch * <span class="built_in">len</span>(x)</span><br><span class="line">            true_labels += y_true.detach().cpu().tolist()</span><br><span class="line">            pred_labels += y_pred.detach().cpu().tolist()</span><br><span class="line">            losses += loss.item()</span><br><span class="line">    correct /= size</span><br><span class="line">    losses /= num_batches</span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;Test: Accuracy: <span class="subst">&#123;(<span class="number">100</span>*correct):&gt;<span class="number">0.2</span>f&#125;</span>%, Avg loss: <span class="subst">&#123;losses:&gt;5f&#125;</span> \n&quot;</span>)</span><br><span class="line">    <span class="keyword">return</span> np.array(true_labels), np.array(pred_labels), np.array(scores)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">test_model_obj = torch.load(<span class="string">&#x27;模型文件path&#x27;</span>)</span><br><span class="line">test_model_obj = test_model_obj.to(device)</span><br><span class="line">test_model(test_loader, test_model_obj, loss_fn, device)</span><br></pre></td></tr></table></figure><h1 id="实验结果"><a href="#实验结果" class="headerlink" title="实验结果"></a>实验结果</h1><div class="table-container"><table><thead><tr><th>使用的数据</th><th>评估结果</th></tr></thead><tbody><tr><td>全部训练数据（Train_1+Train_2+Train_3）</td><td>Accuracy: 99.60%, Avg loss: 0.011775</td></tr><tr><td>Train_1</td><td>Accuracy: 73.20%, Avg loss: 0.641481</td></tr><tr><td>Train_2</td><td>Accuracy: 71.40%, Avg loss: 0.649055</td></tr><tr><td>Train_3</td><td>Accuracy: 56.80%, Avg loss: 0.654335</td></tr></tbody></table></div><h1 id="实验分析"><a href="#实验分析" class="headerlink" title="实验分析"></a>实验分析</h1><p>见下篇</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;本案例分上下两篇，上篇介绍肠癌图像分类任务的本地baseline，下篇介绍将肠癌图像分类任务移植到FATE上，实现联邦学习。&lt;/p&gt;
&lt;h1 id=&quot;任务目标&quot;&gt;&lt;a href=&quot;#任务目标&quot; class=&quot;headerlink&quot; title=&quot;任务目标&quot;&gt;&lt;/a&gt;任务目标</summary>
      
    
    
    
    <category term="联邦学习" scheme="https://guoyujian.github.io/categories/%E8%81%94%E9%82%A6%E5%AD%A6%E4%B9%A0/"/>
    
    
    <category term="联邦学习" scheme="https://guoyujian.github.io/tags/%E8%81%94%E9%82%A6%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>FATE横向联邦学习：手写数字识别</title>
    <link href="https://guoyujian.github.io/2022/11/04/FATE%E6%A8%AA%E5%90%91%E8%81%94%E9%82%A6%E5%AD%A6%E4%B9%A0%EF%BC%9A%E6%89%8B%E5%86%99%E6%95%B0%E5%AD%97%E8%AF%86%E5%88%AB/"/>
    <id>https://guoyujian.github.io/2022/11/04/FATE%E6%A8%AA%E5%90%91%E8%81%94%E9%82%A6%E5%AD%A6%E4%B9%A0%EF%BC%9A%E6%89%8B%E5%86%99%E6%95%B0%E5%AD%97%E8%AF%86%E5%88%AB/</id>
    <published>2022-11-03T16:04:59.000Z</published>
    <updated>2022-11-03T16:06:33.144Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>上上一篇介绍了如何使用FATE发起一个横向联邦学习任务，使用的数据格式是结构化的数据，使用的算法是经典的LR算法。</p><p>能不能使用FATE做计算机视觉的神经网络的联邦学习呢？</p><p>答案是可以的。本篇就通过手写数字识别这一经典任务来学习如何使用FATE来完成一个计算机视觉方面的神经网络算法的联邦学习job</p></blockquote><p>‍</p><h1 id="实验环境"><a href="#实验环境" class="headerlink" title="实验环境"></a>实验环境</h1><p>fate standalone 1.9.0</p><ul><li>数据集mnist：<code>/data/projects/fate/examples/data/mnist_train</code></li><li>code:<code>/data/projects/fate/examples/dsl/v2/homo_nn/mnist_demo</code></li></ul><blockquote><p>最好把这几个文件夹复制出来，再改</p></blockquote><p>code文件夹中有以下几个文件，后面需要用到。</p><p>‍</p><p>在README.md中已经写出了用法，本篇将详细讲解。</p><p><img src="image-20221028155604-ny1t6o7.png" alt="image.png"></p><p>‍</p><h1 id="实验步骤"><a href="#实验步骤" class="headerlink" title="实验步骤"></a>实验步骤</h1><h2 id="下载数据集"><a href="#下载数据集" class="headerlink" title="下载数据集"></a>下载数据集</h2><p>执行<code>fate_test data download -t mnist</code>命令下载mnist数据集，下载的位置位于<code>FATE/examples/data/mnist_train</code></p><h2 id="绑定数据"><a href="#绑定数据" class="headerlink" title="绑定数据"></a>绑定数据</h2><p>修改bind_local_path.json的address.path为数据集文件夹所在的位置，修改后如下。</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">&#123;</span><br><span class="line">    <span class="string">&quot;engine&quot;</span>: <span class="string">&quot;PATH&quot;</span>,</span><br><span class="line">    <span class="string">&quot;namespace&quot;</span>: <span class="string">&quot;experiment&quot;</span>,</span><br><span class="line">    <span class="string">&quot;name&quot;</span>: <span class="string">&quot;mnist_images&quot;</span>,</span><br><span class="line">    <span class="string">&quot;address&quot;</span>: &#123;</span><br><span class="line">        <span class="string">&quot;path&quot;</span>: <span class="string">&quot;/data/projects/fate/examples/data/mnist_train&quot;</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>修改完成后执行<code>flow table bind -c bind_local_path.json</code>命令进行数据绑定。这样一来，文件夹中的数据就和命名空间为experiment，表名为mnist_images的表关联了起来。</p><p>返回类似即绑定成功。</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="string">&quot;retcode&quot;</span>: 0,</span><br><span class="line"><span class="string">&quot;retmsg&quot;</span>: <span class="string">&quot;success&quot;</span></span><br></pre></td></tr></table></figure><h2 id="配置文件并提交job"><a href="#配置文件并提交job" class="headerlink" title="配置文件并提交job"></a>配置文件并提交job</h2><p>mnist_dsl.json文件：</p><figure class="highlight json"><table><tr><td class="code"><pre><span class="line"><span class="punctuation">&#123;</span></span><br><span class="line">    <span class="attr">&quot;components&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">        <span class="attr">&quot;reader_0&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">            <span class="attr">&quot;module&quot;</span><span class="punctuation">:</span> <span class="string">&quot;Reader&quot;</span><span class="punctuation">,</span></span><br><span class="line">            <span class="attr">&quot;output&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">                <span class="attr">&quot;data&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span></span><br><span class="line">                    <span class="string">&quot;data&quot;</span></span><br><span class="line">                <span class="punctuation">]</span></span><br><span class="line">            <span class="punctuation">&#125;</span></span><br><span class="line">        <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">&quot;homo_nn_0&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">            <span class="attr">&quot;module&quot;</span><span class="punctuation">:</span> <span class="string">&quot;HomoNN&quot;</span><span class="punctuation">,</span></span><br><span class="line">            <span class="attr">&quot;input&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">                <span class="attr">&quot;data&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">                    <span class="attr">&quot;train_data&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span></span><br><span class="line">                        <span class="string">&quot;reader_0.data&quot;</span></span><br><span class="line">                    <span class="punctuation">]</span></span><br><span class="line">                <span class="punctuation">&#125;</span></span><br><span class="line">            <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">            <span class="attr">&quot;output&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">                <span class="attr">&quot;data&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span></span><br><span class="line">                    <span class="string">&quot;data&quot;</span></span><br><span class="line">                <span class="punctuation">]</span><span class="punctuation">,</span></span><br><span class="line">                <span class="attr">&quot;model&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span></span><br><span class="line">                    <span class="string">&quot;model&quot;</span></span><br><span class="line">                <span class="punctuation">]</span></span><br><span class="line">            <span class="punctuation">&#125;</span></span><br><span class="line">        <span class="punctuation">&#125;</span></span><br><span class="line">    <span class="punctuation">&#125;</span></span><br><span class="line"><span class="punctuation">&#125;</span></span><br></pre></td></tr></table></figure><p>mnist_conf.json文件：</p><figure class="highlight json"><table><tr><td class="code"><pre><span class="line"><span class="punctuation">&#123;</span></span><br><span class="line">    <span class="attr">&quot;dsl_version&quot;</span><span class="punctuation">:</span> <span class="number">2</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;initiator&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">        <span class="attr">&quot;role&quot;</span><span class="punctuation">:</span> <span class="string">&quot;guest&quot;</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">&quot;party_id&quot;</span><span class="punctuation">:</span> <span class="number">9999</span></span><br><span class="line">    <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;role&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">        <span class="attr">&quot;arbiter&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span></span><br><span class="line">            <span class="number">9999</span></span><br><span class="line">        <span class="punctuation">]</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">&quot;host&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span></span><br><span class="line">            <span class="number">9999</span></span><br><span class="line">        <span class="punctuation">]</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">&quot;guest&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span></span><br><span class="line">            <span class="number">9999</span></span><br><span class="line">        <span class="punctuation">]</span></span><br><span class="line">    <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;component_parameters&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">        <span class="attr">&quot;common&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">            <span class="attr">&quot;homo_nn_0&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">                <span class="attr">&quot;api_version&quot;</span><span class="punctuation">:</span> <span class="number">2</span><span class="punctuation">,</span></span><br><span class="line">                <span class="attr">&quot;encode_label&quot;</span><span class="punctuation">:</span> <span class="keyword">true</span><span class="punctuation">,</span></span><br><span class="line">                <span class="attr">&quot;max_iter&quot;</span><span class="punctuation">:</span> <span class="number">2</span><span class="punctuation">,</span></span><br><span class="line">                <span class="attr">&quot;batch_size&quot;</span><span class="punctuation">:</span> <span class="number">32</span><span class="punctuation">,</span></span><br><span class="line">                <span class="attr">&quot;early_stop&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">                    <span class="attr">&quot;early_stop&quot;</span><span class="punctuation">:</span> <span class="string">&quot;diff&quot;</span><span class="punctuation">,</span></span><br><span class="line">                    <span class="attr">&quot;eps&quot;</span><span class="punctuation">:</span> <span class="number">0.0001</span></span><br><span class="line">                <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">                <span class="attr">&quot;optimizer&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">                    <span class="attr">&quot;lr&quot;</span><span class="punctuation">:</span> <span class="number">0.001</span><span class="punctuation">,</span></span><br><span class="line">                    <span class="attr">&quot;optimizer&quot;</span><span class="punctuation">:</span> <span class="string">&quot;Adam&quot;</span></span><br><span class="line">                <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">                <span class="attr">&quot;loss&quot;</span><span class="punctuation">:</span> <span class="string">&quot;NLLLoss&quot;</span><span class="punctuation">,</span></span><br><span class="line">                <span class="attr">&quot;metrics&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span></span><br><span class="line">                    <span class="string">&quot;accuracy&quot;</span></span><br><span class="line">                <span class="punctuation">]</span><span class="punctuation">,</span></span><br><span class="line">                <span class="attr">&quot;nn_define&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span></span><br><span class="line">                    <span class="punctuation">&#123;</span></span><br><span class="line">                        <span class="attr">&quot;layer&quot;</span><span class="punctuation">:</span> <span class="string">&quot;Conv2d&quot;</span><span class="punctuation">,</span></span><br><span class="line">                        <span class="attr">&quot;in_channels&quot;</span><span class="punctuation">:</span> <span class="number">1</span><span class="punctuation">,</span></span><br><span class="line">                        <span class="attr">&quot;out_channels&quot;</span><span class="punctuation">:</span> <span class="number">10</span><span class="punctuation">,</span></span><br><span class="line">                        <span class="attr">&quot;kernel_size&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span></span><br><span class="line">                            <span class="number">5</span><span class="punctuation">,</span></span><br><span class="line">                            <span class="number">5</span></span><br><span class="line">                        <span class="punctuation">]</span></span><br><span class="line">                    <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">                    <span class="punctuation">&#123;</span></span><br><span class="line">                        <span class="attr">&quot;layer&quot;</span><span class="punctuation">:</span> <span class="string">&quot;MaxPool2d&quot;</span><span class="punctuation">,</span></span><br><span class="line">                        <span class="attr">&quot;kernel_size&quot;</span><span class="punctuation">:</span> <span class="number">2</span></span><br><span class="line">                    <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">                    <span class="punctuation">&#123;</span></span><br><span class="line">                        <span class="attr">&quot;layer&quot;</span><span class="punctuation">:</span> <span class="string">&quot;ReLU&quot;</span></span><br><span class="line">                    <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">                    <span class="punctuation">&#123;</span></span><br><span class="line">                        <span class="attr">&quot;layer&quot;</span><span class="punctuation">:</span> <span class="string">&quot;Conv2d&quot;</span><span class="punctuation">,</span></span><br><span class="line">                        <span class="attr">&quot;in_channels&quot;</span><span class="punctuation">:</span> <span class="number">10</span><span class="punctuation">,</span></span><br><span class="line">                        <span class="attr">&quot;out_channels&quot;</span><span class="punctuation">:</span> <span class="number">20</span><span class="punctuation">,</span></span><br><span class="line">                        <span class="attr">&quot;kernel_size&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span></span><br><span class="line">                            <span class="number">5</span><span class="punctuation">,</span></span><br><span class="line">                            <span class="number">5</span></span><br><span class="line">                        <span class="punctuation">]</span></span><br><span class="line">                    <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">                    <span class="punctuation">&#123;</span></span><br><span class="line">                        <span class="attr">&quot;layer&quot;</span><span class="punctuation">:</span> <span class="string">&quot;Dropout2d&quot;</span></span><br><span class="line">                    <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">                    <span class="punctuation">&#123;</span></span><br><span class="line">                        <span class="attr">&quot;layer&quot;</span><span class="punctuation">:</span> <span class="string">&quot;MaxPool2d&quot;</span><span class="punctuation">,</span></span><br><span class="line">                        <span class="attr">&quot;kernel_size&quot;</span><span class="punctuation">:</span> <span class="number">2</span></span><br><span class="line">                    <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">                    <span class="punctuation">&#123;</span></span><br><span class="line">                        <span class="attr">&quot;layer&quot;</span><span class="punctuation">:</span> <span class="string">&quot;ReLU&quot;</span></span><br><span class="line">                    <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">                    <span class="punctuation">&#123;</span></span><br><span class="line">                        <span class="attr">&quot;layer&quot;</span><span class="punctuation">:</span> <span class="string">&quot;Flatten&quot;</span></span><br><span class="line">                    <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">                    <span class="punctuation">&#123;</span></span><br><span class="line">                        <span class="attr">&quot;layer&quot;</span><span class="punctuation">:</span> <span class="string">&quot;Linear&quot;</span><span class="punctuation">,</span></span><br><span class="line">                        <span class="attr">&quot;in_features&quot;</span><span class="punctuation">:</span> <span class="number">320</span><span class="punctuation">,</span></span><br><span class="line">                        <span class="attr">&quot;out_features&quot;</span><span class="punctuation">:</span> <span class="number">50</span></span><br><span class="line">                    <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">                    <span class="punctuation">&#123;</span></span><br><span class="line">                        <span class="attr">&quot;layer&quot;</span><span class="punctuation">:</span> <span class="string">&quot;ReLU&quot;</span></span><br><span class="line">                    <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">                    <span class="punctuation">&#123;</span></span><br><span class="line">                        <span class="attr">&quot;layer&quot;</span><span class="punctuation">:</span> <span class="string">&quot;Linear&quot;</span><span class="punctuation">,</span></span><br><span class="line">                        <span class="attr">&quot;in_features&quot;</span><span class="punctuation">:</span> <span class="number">50</span><span class="punctuation">,</span></span><br><span class="line">                        <span class="attr">&quot;out_features&quot;</span><span class="punctuation">:</span> <span class="number">10</span></span><br><span class="line">                    <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">                    <span class="punctuation">&#123;</span></span><br><span class="line">                        <span class="attr">&quot;layer&quot;</span><span class="punctuation">:</span> <span class="string">&quot;LogSoftmax&quot;</span></span><br><span class="line">                    <span class="punctuation">&#125;</span></span><br><span class="line">                <span class="punctuation">]</span><span class="punctuation">,</span></span><br><span class="line">                <span class="attr">&quot;config_type&quot;</span><span class="punctuation">:</span> <span class="string">&quot;pytorch&quot;</span></span><br><span class="line">            <span class="punctuation">&#125;</span></span><br><span class="line">        <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">&quot;role&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">            <span class="attr">&quot;host&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">                <span class="attr">&quot;0&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">                    <span class="attr">&quot;reader_0&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">                        <span class="attr">&quot;table&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">                            <span class="attr">&quot;name&quot;</span><span class="punctuation">:</span> <span class="string">&quot;mnist_images&quot;</span><span class="punctuation">,</span></span><br><span class="line">                            <span class="attr">&quot;namespace&quot;</span><span class="punctuation">:</span> <span class="string">&quot;experiment&quot;</span></span><br><span class="line">                        <span class="punctuation">&#125;</span></span><br><span class="line">                    <span class="punctuation">&#125;</span></span><br><span class="line">                <span class="punctuation">&#125;</span></span><br><span class="line">            <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">            <span class="attr">&quot;guest&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">                <span class="attr">&quot;0&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">                    <span class="attr">&quot;reader_0&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">                        <span class="attr">&quot;table&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">                            <span class="attr">&quot;name&quot;</span><span class="punctuation">:</span> <span class="string">&quot;mnist_images&quot;</span><span class="punctuation">,</span></span><br><span class="line">                            <span class="attr">&quot;namespace&quot;</span><span class="punctuation">:</span> <span class="string">&quot;experiment&quot;</span></span><br><span class="line">                        <span class="punctuation">&#125;</span></span><br><span class="line">                    <span class="punctuation">&#125;</span></span><br><span class="line">                <span class="punctuation">&#125;</span></span><br><span class="line">            <span class="punctuation">&#125;</span></span><br><span class="line">        <span class="punctuation">&#125;</span></span><br><span class="line">    <span class="punctuation">&#125;</span></span><br><span class="line"><span class="punctuation">&#125;</span></span><br><span class="line"></span><br></pre></td></tr></table></figure><p>执行<code>flow job submit -c mnist_conf.json -d mnist_dsl.json</code>命令提交job：</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[root@693afd940463 mnist_demo]<span class="comment"># flow job submit -c mnist_conf.json -d mnist_dsl.json </span></span><br><span class="line">&#123;</span><br><span class="line">    <span class="string">&quot;data&quot;</span>: &#123;</span><br><span class="line">        <span class="string">&quot;board_url&quot;</span>: <span class="string">&quot;http://127.0.0.1:8080/index.html#/dashboard?job_id=202209210827526887030&amp;role=guest&amp;party_id=10000&quot;</span>,</span><br><span class="line">        <span class="string">&quot;code&quot;</span>: 0,</span><br><span class="line">        <span class="string">&quot;dsl_path&quot;</span>: <span class="string">&quot;/data/projects/fate/fateflow/jobs/202209210827526887030/job_dsl.json&quot;</span>,</span><br><span class="line">        <span class="string">&quot;job_id&quot;</span>: <span class="string">&quot;202209210827526887030&quot;</span>,</span><br><span class="line">        <span class="string">&quot;logs_directory&quot;</span>: <span class="string">&quot;/data/projects/fate/fateflow/logs/202209210827526887030&quot;</span>,</span><br><span class="line">        <span class="string">&quot;message&quot;</span>: <span class="string">&quot;success&quot;</span>,</span><br><span class="line">        <span class="string">&quot;model_info&quot;</span>: &#123;</span><br><span class="line">            <span class="string">&quot;model_id&quot;</span>: <span class="string">&quot;arbiter-10000#guest-10000#host-10000#model&quot;</span>,</span><br><span class="line">            <span class="string">&quot;model_version&quot;</span>: <span class="string">&quot;202209210827526887030&quot;</span></span><br><span class="line">        &#125;,</span><br><span class="line">        <span class="string">&quot;pipeline_dsl_path&quot;</span>: <span class="string">&quot;/data/projects/fate/fateflow/jobs/202209210827526887030/pipeline_dsl.json&quot;</span>,</span><br><span class="line">        <span class="string">&quot;runtime_conf_on_party_path&quot;</span>: <span class="string">&quot;/data/projects/fate/fateflow/jobs/202209210827526887030/guest/10000/job_runtime_on_party_conf.json&quot;</span>,</span><br><span class="line">        <span class="string">&quot;runtime_conf_path&quot;</span>: <span class="string">&quot;/data/projects/fate/fateflow/jobs/202209210827526887030/job_runtime_conf.json&quot;</span>,</span><br><span class="line">        <span class="string">&quot;train_runtime_conf_path&quot;</span>: <span class="string">&quot;/data/projects/fate/fateflow/jobs/202209210827526887030/train_runtime_conf.json&quot;</span></span><br><span class="line">    &#125;,</span><br><span class="line">    <span class="string">&quot;jobId&quot;</span>: <span class="string">&quot;202209210827526887030&quot;</span>,</span><br><span class="line">    <span class="string">&quot;retcode&quot;</span>: 0,</span><br><span class="line">    <span class="string">&quot;retmsg&quot;</span>: <span class="string">&quot;success&quot;</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="使用flow-test提交Job"><a href="#使用flow-test提交Job" class="headerlink" title="使用flow-test提交Job"></a>使用flow-test提交Job</h2><p>除了上述之外，还可以快速提交一个job。</p><p>flow-test 快速的flow测试，比较方便，只需要修改mnist_nn_testsuite.json并执行一次命令即可。他有以下特点：</p><ul><li>不需要提前绑定数据，执行完成后，也不存在被绑定的数据</li><li>日志会保存在到本地目录logs</li><li>不会产生model_id和model_version</li></ul><p>下面介绍执行步骤：</p><h3 id="修改mnist-nn-testsuite-json"><a href="#修改mnist-nn-testsuite-json" class="headerlink" title="修改mnist_nn_testsuite.json"></a>修改<code>mnist_nn_testsuite.json</code></h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">&#123;</span><br><span class="line">    <span class="string">&quot;data&quot;</span>: [</span><br><span class="line">        &#123;</span><br><span class="line">            <span class="string">&quot;engine&quot;</span>: <span class="string">&quot;PATH&quot;</span>,</span><br><span class="line">            <span class="string">&quot;namespace&quot;</span>: <span class="string">&quot;experiment&quot;</span>,</span><br><span class="line">            <span class="string">&quot;name&quot;</span>: <span class="string">&quot;mnist_images&quot;</span>,</span><br><span class="line">            <span class="string">&quot;address&quot;</span>: &#123;</span><br><span class="line">                <span class="string">&quot;path&quot;</span>: <span class="string">&quot;/data/projects/fate/work/mnist_fed/mnist_images&quot;</span></span><br><span class="line">            &#125;,</span><br><span class="line">            <span class="string">&quot;role&quot;</span>: <span class="string">&quot;guest_0&quot;</span></span><br><span class="line">        &#125;,</span><br><span class="line">        &#123;</span><br><span class="line">            <span class="string">&quot;engine&quot;</span>: <span class="string">&quot;PATH&quot;</span>,</span><br><span class="line">            <span class="string">&quot;namespace&quot;</span>: <span class="string">&quot;experiment&quot;</span>,</span><br><span class="line">            <span class="string">&quot;name&quot;</span>: <span class="string">&quot;mnist_images&quot;</span>,</span><br><span class="line">            <span class="string">&quot;address&quot;</span>: &#123;</span><br><span class="line">                <span class="string">&quot;path&quot;</span>: <span class="string">&quot;/data/projects/fate/work/mnist_fed/mnist_images&quot;</span></span><br><span class="line">            &#125;,</span><br><span class="line">            <span class="string">&quot;role&quot;</span>: <span class="string">&quot;host_0&quot;</span></span><br><span class="line">        &#125;</span><br><span class="line">    ],</span><br><span class="line">    <span class="string">&quot;tasks&quot;</span>: &#123;</span><br><span class="line">        <span class="string">&quot;mnist&quot;</span>: &#123;</span><br><span class="line">            <span class="string">&quot;conf&quot;</span>: <span class="string">&quot;./mnist_conf.json&quot;</span>,</span><br><span class="line">            <span class="string">&quot;dsl&quot;</span>: <span class="string">&quot;./mnist_dsl.json&quot;</span></span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure><h3 id="执行flow-test"><a href="#执行flow-test" class="headerlink" title="执行flow-test"></a>执行flow-test</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">fate_test suite -i mnist_nn_testsuite.json</span><br></pre></td></tr></table></figure><p>执行结果如下：</p><p><img src="image-20220922142054-e4f41jc.png" alt="image.png"></p><p>‍</p><h1 id="模型评估"><a href="#模型评估" class="headerlink" title="模型评估"></a>模型评估</h1><p>上述训练完成之后，如何进行评估本次训练得到的模型效果呢？</p><p>答案是：截止到1.9.0版本，FATE还暂不支持对计算机视觉类任务进行模型评估。。。</p><p>我的做法是，<strong>直接在FATE-FLOW中找到Job生成的模型文件，自行实现对模型的评估。</strong></p><p>要做到这一点需要熟悉源码。</p><h1 id="从How到Why"><a href="#从How到Why" class="headerlink" title="从How到Why"></a>从How到Why</h1><p>前面我们了解了FATE提交一个视觉分类任务的基本流程，但是我们还有很多未知的东西：比如为什么要这样组织数据，FATE是如何读取配置创建模型的，联邦学习结束后保存的模型在哪里，如何调用？</p><p>想要知道这些需要读懂FATE源码。</p><h1 id="源码（部分）"><a href="#源码（部分）" class="headerlink" title="源码（部分）"></a>源码（部分）</h1><p>该部分介绍FATE是如何根据DSL和CONF配置读入数据、创建和训练模型以及导出模型的。</p><p>这里先介绍一些比较重要的目录：</p><blockquote><ul><li><a href="https://github.com/FederatedAI/FATE：">https://github.com/FederatedAI/FATE：</a> FATE官方开源的根目录</li><li><a href="https://github.com/FederatedAI/FATE/tree/master/python/federatedml：FATE联邦学习算法组件的源码目录，也是后面重点研究的目录，读懂该目录下的源码就可以开始开发新的算法组件。">https://github.com/FederatedAI/FATE/tree/master/python/federatedml：FATE联邦学习算法组件的源码目录，也是后面重点研究的目录，读懂该目录下的源码就可以开始开发新的算法组件。</a></li><li><a href="https://github.com/FederatedAI/FATE-Flow/tree/3afbc3e5d335ac96634eadfc493c4c697ecbfc19/python/fate_flow/apps：FATE">https://github.com/FederatedAI/FATE-Flow/tree/3afbc3e5d335ac96634eadfc493c4c697ecbfc19/python/fate_flow/apps：FATE</a> API源码目录，可以在这里开发新的API</li></ul></blockquote><p>‍</p><p>从上面的案例中可以看到，我们主要使用的是HomoNN算法组件，所以这里我们要找到NN对应的位置：<a href="https://github.com/FederatedAI/FATE/tree/master/python/federatedml/nn，这里nn是神经网络的意思。">https://github.com/FederatedAI/FATE/tree/master/python/federatedml/nn，这里nn是神经网络的意思。</a></p><p>在该目录下，可以看到三个文件夹：</p><ul><li>backend：公共后端代码</li><li>hetero_nn：纵向nn组件</li><li>homo_nn：横向nn组件</li></ul><p>这三个文件夹中是需要重点读懂的代码。</p><p>首先，这里明确，我们要弄懂的问题：</p><ol><li>图像数据是如何input的</li><li>为什么做图像任务时，数据的组织形式要分为images/、config.yaml、filenames以及targets</li><li>FATE是如何根据CONF生成模型，optimizer等算法参数的。</li><li>FATE是如何进行训练的。</li><li>FATE是否支持使用预训练的模型进行训练，是否支持使用GPU进行训练，是否可以自定义添加log等等，如果不能，可否开发自己的组件来实现。</li><li>如果使用配置定义模型，那么FATE支持的layer以及参数有哪些？</li></ol><p>带着这些问题，我们来学习源码。</p><h2 id="enter-point-py"><a href="#enter-point-py" class="headerlink" title="enter_point.py"></a>enter_point.py</h2><p>enter_point是homo_nn组件被调用的起点（存疑），文件位置：<a href="https://github.com/FederatedAI/FATE/blob/master/python/federatedml/nn/homo_nn/enter_point.py">https://github.com/FederatedAI/FATE/blob/master/python/federatedml/nn/homo_nn/enter_point.py</a></p><p>重点关注<code>HomoNNClient</code>类。它包含几个重要的方法：</p><ul><li>fit：模型训练</li><li>predict：模型预测</li><li>export_model和load_model：模型的导出和加载。</li></ul><h3 id="fit"><a href="#fit" class="headerlink" title="fit"></a>fit</h3><p>以下是该方法的主要代码。</p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">fit</span>(<span class="params">self, data, *args</span>):</span><br><span class="line">...</span><br><span class="line">        <span class="keyword">from</span> federatedml.nn.homo_nn._torch <span class="keyword">import</span> build_trainer</span><br><span class="line">...</span><br><span class="line">        self._trainer, dataloader = build_trainer(</span><br><span class="line">            param=self.param,</span><br><span class="line">            data=data,</span><br><span class="line">            should_label_align=<span class="keyword">not</span> self.component_properties.is_warm_start,</span><br><span class="line">            trainer=self._trainer,</span><br><span class="line">        ) <span class="comment"># 调用build_trainer获取trainer和dataloader</span></span><br><span class="line">        self._trainer.fit(dataloader) <span class="comment"># 执行训练</span></span><br><span class="line">        self.set_summary(self._trainer.summary())</span><br><span class="line">        <span class="comment"># save model to local filesystem</span></span><br><span class="line">        self._trainer.save_checkpoint()</span><br><span class="line">...</span><br></pre></td></tr></table></figure><p>可以看到trainer和dataloader是通过调用build_trainer返回的。</p><p>‍</p><h2 id="torch-py"><a href="#torch-py" class="headerlink" title="_torch.py"></a>_torch.py</h2><p>这是FATE进行联邦学习，homo_nn组件的主要实现代码。</p><h3 id="build-trainer"><a href="#build-trainer" class="headerlink" title="build_trainer"></a>build_trainer</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">build_trainer</span>(<span class="params">param: HomoNNParam, data, should_label_align=<span class="literal">True</span>, trainer=<span class="literal">None</span></span>):</span><br><span class="line">    ...</span><br><span class="line">    pl_trainer = pl.Trainer(</span><br><span class="line">        max_epochs=total_epoch,</span><br><span class="line">        callbacks=[EarlyStopCallback(context)],</span><br><span class="line">        num_sanity_val_steps=<span class="number">0</span>,</span><br><span class="line">    )</span><br><span class="line">    ...</span><br><span class="line">    pl_model = FedLightModule(</span><br><span class="line">        context,</span><br><span class="line">        layers_config=param.nn_define,</span><br><span class="line">        optimizer_config=param.optimizer,</span><br><span class="line">        loss_config=&#123;<span class="string">&quot;loss&quot;</span>: param.loss&#125;,</span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">    ...</span><br><span class="line"></span><br><span class="line">    dataset = make_dataset(</span><br><span class="line">        data=data,</span><br><span class="line">        is_train=should_label_align,</span><br><span class="line">        expected_label_type=expected_label_type,</span><br><span class="line">    )</span><br><span class="line">    ...</span><br><span class="line">    dataloader = torch.utils.data.DataLoader(</span><br><span class="line">        dataset=dataset, batch_size=batch_size, num_workers=<span class="number">1</span></span><br><span class="line">    )</span><br><span class="line"><span class="keyword">return</span> trainer, dataloader</span><br></pre></td></tr></table></figure><p>这里就可以看到dataset是调用make_dataset方法得到，model是FedLightModule的实例化对象。</p><p>‍</p><h3 id="make-dataset"><a href="#make-dataset" class="headerlink" title="make_dataset"></a>make_dataset</h3><p>这里可以看到，图像数据，是通过VisionDataSet实例化得到的。具体VisionDataSet后面再谈。</p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">make_dataset</span>(<span class="params">data, **kwargs</span>):</span><br><span class="line">    <span class="keyword">if</span> is_table(data):</span><br><span class="line">        dataset = TableDataSet(data_instances=data, **kwargs)</span><br><span class="line">    <span class="keyword">elif</span> <span class="built_in">isinstance</span>(data, LocalData):</span><br><span class="line">        dataset = VisionDataSet(data.path, **kwargs)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">raise</span> TypeError(<span class="string">f&quot;data type <span class="subst">&#123;data&#125;</span> not supported&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> dataset</span><br></pre></td></tr></table></figure><p>‍</p><h3 id="FedLightModule-init"><a href="#FedLightModule-init" class="headerlink" title="FedLightModule.init()"></a>FedLightModule.<strong>init</strong>()</h3><p>关注<code>FedLightModule</code>这个类。该类继承了<code>LightningModule</code>。这东西看上去是一个将pytorch轻量化、规范化的库。</p><p>该类有以下方法：</p><ul><li><strong>init</strong>：初始化</li><li>forward：前向传播</li><li>training_step：每个batch训练的执行代码，传入batch和batch_idx，返回loss</li><li>validation_step：每个batch验证的执行代码，传入batch和batch_idx，返回loss和acc</li><li>validation_epoch_end：每个epoch结束后执行，输入的是所有batch的outputs，打印该epoch的local loss和local acc。（local的意思是，只基于自己这一方的数据计算的结果）</li><li>configure_optimizers：配置optimizer</li></ul><p>在init方法中，非常清晰的可以看到，model、loss和optimizer是如何读取配置定义出来的。</p><p>model是通过读取配置中的layer_config，生成模型的每一层，然后在“组装起来”。</p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params"></span></span><br><span class="line"><span class="params">    self,</span></span><br><span class="line"><span class="params">    context: PyTorchSAClientContext,</span></span><br><span class="line"><span class="params">    layers_config: typing.<span class="type">List</span>[typing.Mapping],</span></span><br><span class="line"><span class="params">    optimizer_config: types.SimpleNamespace,</span></span><br><span class="line"><span class="params">    loss_config: typing.Mapping,</span></span><br><span class="line"><span class="params"></span>):</span><br><span class="line">    <span class="built_in">super</span>().__init__()</span><br><span class="line">    self.save_hyperparameters()</span><br><span class="line">    self.context = context</span><br><span class="line"></span><br><span class="line">    <span class="comment"># model</span></span><br><span class="line">    layers = []</span><br><span class="line">    <span class="keyword">for</span> layer_config <span class="keyword">in</span> layers_config:</span><br><span class="line">        layer_name = layer_config[<span class="string">&quot;layer&quot;</span>]</span><br><span class="line">        layer_kwargs = &#123;k: v <span class="keyword">for</span> k, v <span class="keyword">in</span> layer_config.items() <span class="keyword">if</span> k != <span class="string">&quot;layer&quot;</span>&#125;</span><br><span class="line">        layers.append(get_layer_fn(layer_name, layer_kwargs))</span><br><span class="line">    self.model = nn.Sequential(*layers)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># loss</span></span><br><span class="line">    loss_name = loss_config[<span class="string">&quot;loss&quot;</span>]</span><br><span class="line">    loss_kwargs = &#123;k: v <span class="keyword">for</span> k, v <span class="keyword">in</span> loss_config.items() <span class="keyword">if</span> k != <span class="string">&quot;loss&quot;</span>&#125;</span><br><span class="line">    self.loss_fn, self.expected_label_type = get_loss_fn(loss_name, loss_kwargs)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># optimizer</span></span><br><span class="line">    self._optimizer_name = optimizer_config.optimizer</span><br><span class="line">    self._optimizer_kwargs = optimizer_config.kwargs</span><br><span class="line"></span><br><span class="line">    self.num_data_consumed = <span class="number">0</span></span><br><span class="line">    self._all_consumed_data_aggregated = <span class="literal">True</span></span><br><span class="line"></span><br><span class="line">    self._should_early_stop = <span class="literal">False</span></span><br><span class="line">    self._loss = <span class="literal">None</span></span><br></pre></td></tr></table></figure><p>如果我们需要定义自己的模型，比如，我们想要定义一个预训练的vgg16，则修改代码：</p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">self.model = models.vgg16(pretrained=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure><p>这里，我们可以回答第三、四、五个问题： FATE本身不支持加载预训练模型、使用GPU训练、自定义日志，但是您可以自行开发。</p><h3 id="PyTorchFederatedTrainer"><a href="#PyTorchFederatedTrainer" class="headerlink" title="PyTorchFederatedTrainer"></a>PyTorchFederatedTrainer</h3><p>这个类和模型有关。从<code>save_checkpoint</code>方法中可以知道，FATE将模型文件保存为model.ckpt。从<code>load_model</code>方法中可以了解到，加载最后得到的模型文件的方式：</p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">pl_model = FedLightModule.load_from_checkpoint(filepath)</span><br></pre></td></tr></table></figure><p>这样，我们只需要找到最后生成的模型，就可以load进来， 自己开发进行模型评估。</p><h2 id="data-py"><a href="#data-py" class="headerlink" title="data.py"></a>data.py</h2><p><a href="https://github.com/FederatedAI/FATE/blob/master/python/federatedml/nn/backend/pytorch/data.py">https://github.com/FederatedAI/FATE/blob/master/python/federatedml/nn/backend/pytorch/data.py</a></p><p>FATE通过<code>VisionDataSet</code>类加载图像数据，这也回答了第一、二个问题。</p><p>‍</p><h2 id="FATE支持的layer"><a href="#FATE支持的layer" class="headerlink" title="FATE支持的layer"></a>FATE支持的layer</h2><p>在CONF文件的“nn_define”中出现了很多类型的layer：Conv2d、ReLu…</p><p>FATE支持的层的定义位于<a href="https://github.com/FederatedAI/FATE/blob/master/python/federatedml/nn/backend/fate_torch/nn.py">https://github.com/FederatedAI/FATE/blob/master/python/federatedml/nn/backend/fate_torch/nn.py</a></p><blockquote><p>这里我一开始误以为定义的层位于：<a href="https://github.com/FederatedAI/FATE/blob/master/python/federatedml/nn/backend/pytorch/nn_model.py">https://github.com/FederatedAI/FATE/blob/master/python/federatedml/nn/backend/pytorch/nn_model.py</a></p><p>后来发现是不对的，为什么不对。我也没搞清楚。</p></blockquote>]]></content>
    
    
      
      
    <summary type="html">&lt;blockquote&gt;
&lt;p&gt;上上一篇介绍了如何使用FATE发起一个横向联邦学习任务，使用的数据格式是结构化的数据，使用的算法是经典的LR算法。&lt;/p&gt;
&lt;p&gt;能不能使用FATE做计算机视觉的神经网络的联邦学习呢？&lt;/p&gt;
&lt;p&gt;答案是可以的。本篇就通过手写数字识别这一经典任务</summary>
      
    
    
    
    <category term="联邦学习" scheme="https://guoyujian.github.io/categories/%E8%81%94%E9%82%A6%E5%AD%A6%E4%B9%A0/"/>
    
    
    <category term="联邦学习" scheme="https://guoyujian.github.io/tags/%E8%81%94%E9%82%A6%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>FATE DSL配置文件详细解释</title>
    <link href="https://guoyujian.github.io/2022/11/04/FATE-DSL%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6%E8%AF%A6%E7%BB%86%E8%A7%A3%E9%87%8A/"/>
    <id>https://guoyujian.github.io/2022/11/04/FATE-DSL%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6%E8%AF%A6%E7%BB%86%E8%A7%A3%E9%87%8A/</id>
    <published>2022-11-03T16:03:55.000Z</published>
    <updated>2022-11-03T16:04:41.428Z</updated>
    
    <content type="html"><![CDATA[<p>这里对FATE DSL文件做详细解释。</p><h1 id="DSL"><a href="#DSL" class="headerlink" title="DSL"></a>DSL</h1><p>DSL有两个版本，FATE 1.7以上版本强制使用v2。</p><p>dsl.json提供了流程，conf.json提供了个流程参数。</p><p>其中dsl.json的配置参见：<a href="https://github.com/FederatedAI/FATE/blob/master/doc/tutorial/dsl_conf/dsl_conf_v2_setting_guide.zh.md">https://github.com/FederatedAI/FATE/blob/master/doc/tutorial/dsl_conf/dsl_conf_v2_setting_guide.zh.md</a></p><p>下面选取一个案例。</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">//dsl.json</span><br><span class="line">&#123;</span><br><span class="line">    &quot;components&quot;: &#123; // 一级配置，表示这个任务会使用的组件</span><br><span class="line">        &quot;reader_0&quot;: &#123; // 组件的名字，自定义</span><br><span class="line">    // 指定模块，参数需要和目录/data/projects/fate/fate/python/federatedml/components一致，里面有一些定义好的组件，但是感觉不全，我的建议还是看官方docs：https://fate.readthedocs.io/en/latest/federatedml_component/</span><br><span class="line">            &quot;module&quot;: &quot;Reader&quot;, //数据需要通过Reader组件从数据存储拿取数据，注意此组件仅有输出output，此模块必须要有</span><br><span class="line">            &quot;output&quot;: &#123;</span><br><span class="line">                &quot;data&quot;: [</span><br><span class="line">                    &quot;data&quot; // 这个地方是自定义还是必须是train？需要尝试</span><br><span class="line">                ]</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;,</span><br><span class="line">// 除reader之外，每个组件下包含input和output，input和output下又包含data和model</span><br><span class="line">// data input: 来自于之前的组件有四种可能的类型，</span><br><span class="line">// 1. data: 用在data_transform, feature_engineering modules 和 evaluation模块</span><br><span class="line">// 2. train_data: 用在训练组件，比如HeteroLR、HeteroSBT，如果使用了这个字段， 则这个task会被解析为一个fit task（训练任务？）</span><br><span class="line">// 3. validate_data: 如果有了train_data，那么该字段就是可选地. 这种情况下，数据被用作validation集.</span><br><span class="line">// 4. test_data: 指定用于预测的数据，如果设置了这个字段，模型也需要。</span><br><span class="line"></span><br><span class="line">// model input: 来自于之前的模块，有2种可能的类型，</span><br><span class="line">// 1. model: 由同类型（指“module”字段相同）组件输入的模型。把其他组件的模型输出作为输入。</span><br><span class="line">// 2. isometric_model: 模型输入来自上游组件。</span><br><span class="line"></span><br><span class="line">// data output: 来自于之前的模块，有4种可能的类型，</span><br><span class="line">// 1. data: </span><br><span class="line">// 2. train_data、validate_data、test_data: 仅用于数据分片？</span><br><span class="line"></span><br><span class="line">// model : 来自于之前的模块，有1种可能的类型，</span><br><span class="line">// 1. model</span><br><span class="line"></span><br><span class="line">        &quot;data_transform_0&quot;: &#123;</span><br><span class="line">            &quot;module&quot;: &quot;DataTransform&quot;,</span><br><span class="line">            &quot;input&quot;: &#123;</span><br><span class="line">                &quot;data&quot;: &#123;</span><br><span class="line">                    &quot;data&quot;: [</span><br><span class="line">                        &quot;reader_0.data&quot;</span><br><span class="line">                    ]</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;,</span><br><span class="line">            &quot;output&quot;: &#123;</span><br><span class="line">                &quot;data&quot;: [</span><br><span class="line">                    &quot;data&quot;</span><br><span class="line">                ],</span><br><span class="line">                &quot;model&quot;: [</span><br><span class="line">                    &quot;model&quot;</span><br><span class="line">                ]</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;,</span><br><span class="line">        &quot;scale_0&quot;: &#123;</span><br><span class="line">            &quot;module&quot;: &quot;FeatureScale&quot;,</span><br><span class="line">            &quot;input&quot;: &#123;</span><br><span class="line">                &quot;data&quot;: &#123;</span><br><span class="line">                    &quot;data&quot;: [</span><br><span class="line">                        &quot;data_transform_0.data&quot;</span><br><span class="line">                    ]</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;,</span><br><span class="line">            &quot;output&quot;: &#123;</span><br><span class="line">                &quot;data&quot;: [</span><br><span class="line">                    &quot;data&quot;</span><br><span class="line">                ],</span><br><span class="line">                &quot;model&quot;: [</span><br><span class="line">                    &quot;model&quot;</span><br><span class="line">                ]</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;,</span><br><span class="line">        &quot;homo_lr_0&quot;: &#123;</span><br><span class="line">            &quot;module&quot;: &quot;HomoLR&quot;,</span><br><span class="line">            &quot;input&quot;: &#123;</span><br><span class="line">                &quot;data&quot;: &#123;</span><br><span class="line">                    &quot;train_data&quot;: [</span><br><span class="line">                        &quot;scale_0.data&quot;</span><br><span class="line">                    ]</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;,</span><br><span class="line">            &quot;output&quot;: &#123;</span><br><span class="line">                &quot;data&quot;: [</span><br><span class="line">                    &quot;data&quot;</span><br><span class="line">                ],</span><br><span class="line">                &quot;model&quot;: [</span><br><span class="line">                    &quot;model&quot;</span><br><span class="line">                ]</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;,</span><br><span class="line">        &quot;evaluation_0&quot;: &#123;</span><br><span class="line">            &quot;module&quot;: &quot;Evaluation&quot;,</span><br><span class="line">            &quot;input&quot;: &#123;</span><br><span class="line">                &quot;data&quot;: &#123;</span><br><span class="line">                    &quot;data&quot;: [</span><br><span class="line">                        &quot;homo_lr_0.data&quot;</span><br><span class="line">                    ]</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;,</span><br><span class="line">            &quot;output&quot;: &#123;</span><br><span class="line">                &quot;data&quot;: [</span><br><span class="line">                    &quot;data&quot;</span><br><span class="line">                ]</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure><p>‍</p><h1 id="CONF"><a href="#CONF" class="headerlink" title="CONF"></a>CONF</h1><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">//conf.json</span><br><span class="line">&#123;</span><br><span class="line">    //fate版本大于等于1.7时，必须设置dsl_version=2</span><br><span class="line">    &quot;dsl_version&quot;: 2,</span><br><span class="line"></span><br><span class="line">    &quot;initiator&quot;: &#123; //定义发起者的角色和partyid</span><br><span class="line">        &quot;role&quot;: &quot;guest&quot;,</span><br><span class="line">        &quot;party_id&quot;: 10000</span><br><span class="line">    &#125;,</span><br><span class="line">    //定义所有的参与方</span><br><span class="line">    &quot;role&quot;: &#123;</span><br><span class="line">        &quot;guest&quot;: [</span><br><span class="line">            10000</span><br><span class="line">        ],</span><br><span class="line">        &quot;host&quot;: [</span><br><span class="line">            10000</span><br><span class="line">        ],</span><br><span class="line">        &quot;arbiter&quot;: [</span><br><span class="line">            10000</span><br><span class="line">        ]</span><br><span class="line">    &#125;,</span><br><span class="line">  </span><br><span class="line">    &quot;component_parameters&quot;: &#123;</span><br><span class="line">        //common：参数应用到所有的参与方, role：参数应用到指定的参与方</span><br><span class="line">        &quot;common&quot;: &#123;</span><br><span class="line">    //组件的详细参数参见：https://fate.readthedocs.io/en/latest/federatedml_component/</span><br><span class="line">            &quot;data_transform_0&quot;: &#123;</span><br><span class="line">                &quot;with_label&quot;: true,</span><br><span class="line">                &quot;output_format&quot;: &quot;dense&quot;</span><br><span class="line">            &#125;,</span><br><span class="line">            &quot;homo_lr_0&quot;: &#123;</span><br><span class="line">                &quot;penalty&quot;: &quot;L2&quot;,</span><br><span class="line">                &quot;tol&quot;: 1e-05,</span><br><span class="line">                &quot;alpha&quot;: 0.01,</span><br><span class="line">                &quot;optimizer&quot;: &quot;sgd&quot;,</span><br><span class="line">                &quot;batch_size&quot;: -1,</span><br><span class="line">                &quot;learning_rate&quot;: 0.15,</span><br><span class="line">                &quot;init_param&quot;: &#123;</span><br><span class="line">                    &quot;init_method&quot;: &quot;zeros&quot;</span><br><span class="line">                &#125;,</span><br><span class="line">                &quot;max_iter&quot;: 30,</span><br><span class="line">                &quot;early_stop&quot;: &quot;diff&quot;,</span><br><span class="line">                &quot;encrypt_param&quot;: &#123;</span><br><span class="line">                    &quot;method&quot;: null</span><br><span class="line">                &#125;,</span><br><span class="line">                &quot;cv_param&quot;: &#123;</span><br><span class="line">                    &quot;n_splits&quot;: 4,</span><br><span class="line">                    &quot;shuffle&quot;: true,</span><br><span class="line">                    &quot;random_seed&quot;: 33,</span><br><span class="line">                    &quot;need_cv&quot;: false</span><br><span class="line">                &#125;,</span><br><span class="line">                &quot;decay&quot;: 1,</span><br><span class="line">                &quot;decay_sqrt&quot;: true</span><br><span class="line">            &#125;,</span><br><span class="line">            &quot;evaluation_0&quot;: &#123;</span><br><span class="line">                &quot;eval_type&quot;: &quot;binary&quot;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;,</span><br><span class="line"></span><br><span class="line">        &quot;role&quot;: &#123;</span><br><span class="line">            &quot;host&quot;: &#123;</span><br><span class="line">                &quot;0&quot;: &#123; //role.host.0：参数应用到host的index=0的参与方</span><br><span class="line">                    &quot;reader_0&quot;: &#123;</span><br><span class="line">                        &quot;table&quot;: &#123;</span><br><span class="line">                            &quot;name&quot;: &quot;homo_default_credit_host&quot;,</span><br><span class="line">                            &quot;namespace&quot;: &quot;homo_default_credit_host&quot;</span><br><span class="line">                        &#125;</span><br><span class="line">                    &#125;,</span><br><span class="line">                    &quot;evaluation_0&quot;: &#123;</span><br><span class="line">                        &quot;need_run&quot;: false</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;,</span><br><span class="line">            &quot;guest&quot;: &#123;</span><br><span class="line">                &quot;0&quot;: &#123;</span><br><span class="line">                    &quot;reader_0&quot;: &#123;</span><br><span class="line">                        &quot;table&quot;: &#123;</span><br><span class="line">                            &quot;name&quot;: &quot;homo_default_credit_guest&quot;,</span><br><span class="line">                            &quot;namespace&quot;: &quot;homo_default_credit_guest&quot;</span><br><span class="line">                        &#125;</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>注：</p><ol><li>上面的conf没有使用到provider组件，该组件支持加载多种且多版本的组件提供方</li><li>上面conf没涉及系统运行时参数，具体参见：<a href="https://federatedai.github.io/FATE-Flow/latest/zh/fate_flow_job_scheduling/#43">https://federatedai.github.io/FATE-Flow/latest/zh/fate_flow_job_scheduling/#43</a></li><li>dsl v2中，predict dsl不会在训练后自动生成，用户需要通过flow client部署所需的组件：<a href="https://github.com/FederatedAI/FATE-Flow/blob/main/doc/cli/model.md#deploy">https://github.com/FederatedAI/FATE-Flow/blob/main/doc/cli/model.md#deploy</a></li><li>train dsl 和predict dsl examples：</li></ol><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&quot;components&quot;: &#123;</span><br><span class="line">    &quot;reader_0&quot;: &#123;</span><br><span class="line">        &quot;module&quot;: &quot;Reader&quot;,</span><br><span class="line">        &quot;output&quot;: &#123;</span><br><span class="line">            &quot;data&quot;: [</span><br><span class="line">                &quot;data&quot;</span><br><span class="line">            ]</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;,</span><br><span class="line">    &quot;data_transform_0&quot;: &#123;</span><br><span class="line">        &quot;module&quot;: &quot;DataTransform&quot;,</span><br><span class="line">        &quot;input&quot;: &#123;</span><br><span class="line">            &quot;data&quot;: &#123;</span><br><span class="line">                &quot;data&quot;: [</span><br><span class="line">                    &quot;reader_0.data&quot;</span><br><span class="line">                ]</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;,</span><br><span class="line">        &quot;output&quot;: &#123;</span><br><span class="line">            &quot;data&quot;: [</span><br><span class="line">                &quot;data&quot;</span><br><span class="line">            ],</span><br><span class="line">            &quot;model&quot;: [</span><br><span class="line">                &quot;model&quot;</span><br><span class="line">            ]</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;,</span><br><span class="line">    &quot;intersection_0&quot;: &#123;</span><br><span class="line">        &quot;module&quot;: &quot;Intersection&quot;,</span><br><span class="line">        &quot;input&quot;: &#123;</span><br><span class="line">            &quot;data&quot;: &#123;</span><br><span class="line">                &quot;data&quot;: [</span><br><span class="line">                    &quot;data_transform_0.data&quot;</span><br><span class="line">                ]</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;,</span><br><span class="line">        &quot;output&quot;: &#123;</span><br><span class="line">            &quot;data&quot;:[</span><br><span class="line">                &quot;data&quot;</span><br><span class="line">            ]</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;,</span><br><span class="line">    &quot;hetero_nn_0&quot;: &#123;</span><br><span class="line">        &quot;module&quot;: &quot;HeteroNN&quot;,</span><br><span class="line">        &quot;input&quot;: &#123;</span><br><span class="line">            &quot;data&quot;: &#123;</span><br><span class="line">                &quot;train_data&quot;: [</span><br><span class="line">                    &quot;intersection_0.data&quot;</span><br><span class="line">                ]</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;,</span><br><span class="line">        &quot;output&quot;: &#123;</span><br><span class="line">            &quot;data&quot;: [</span><br><span class="line">                &quot;data&quot;</span><br><span class="line">            ],</span><br><span class="line">            &quot;model&quot;: [</span><br><span class="line">                &quot;model&quot;</span><br><span class="line">            ]</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>‍</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&quot;components&quot;: &#123;</span><br><span class="line">    &quot;reader_0&quot;: &#123;</span><br><span class="line">        &quot;module&quot;: &quot;Reader&quot;,</span><br><span class="line">        &quot;output&quot;: &#123;</span><br><span class="line">            &quot;data&quot;: [</span><br><span class="line">                &quot;data&quot;</span><br><span class="line">            ]</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;,</span><br><span class="line">    &quot;data_transform_0&quot;: &#123;</span><br><span class="line">        &quot;module&quot;: &quot;DataTransform&quot;,</span><br><span class="line">        &quot;input&quot;: &#123;</span><br><span class="line">            &quot;data&quot;: &#123;</span><br><span class="line">                &quot;data&quot;: [</span><br><span class="line">                    &quot;reader_0.data&quot;</span><br><span class="line">                ]</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;,</span><br><span class="line">        &quot;output&quot;: &#123;</span><br><span class="line">            &quot;data&quot;: [</span><br><span class="line">                &quot;data&quot;</span><br><span class="line">            ],</span><br><span class="line">            &quot;model&quot;: [</span><br><span class="line">                &quot;model&quot;</span><br><span class="line">            ]</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;,</span><br><span class="line">    &quot;intersection_0&quot;: &#123;</span><br><span class="line">        &quot;module&quot;: &quot;Intersection&quot;,</span><br><span class="line">        &quot;input&quot;: &#123;</span><br><span class="line">            &quot;data&quot;: &#123;</span><br><span class="line">                &quot;data&quot;: [</span><br><span class="line">                    &quot;data_transform_0.data&quot;</span><br><span class="line">                ]</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;,</span><br><span class="line">        &quot;output&quot;: &#123;</span><br><span class="line">            &quot;data&quot;:[</span><br><span class="line">                &quot;data&quot;</span><br><span class="line">            ]</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;,</span><br><span class="line">    &quot;hetero_nn_0&quot;: &#123;</span><br><span class="line">        &quot;module&quot;: &quot;HeteroNN&quot;,</span><br><span class="line">        &quot;input&quot;: &#123;</span><br><span class="line">            &quot;data&quot;: &#123;</span><br><span class="line">                &quot;train_data&quot;: [</span><br><span class="line">                    &quot;intersection_0.data&quot;</span><br><span class="line">                ]</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;,</span><br><span class="line">        &quot;output&quot;: &#123;</span><br><span class="line">            &quot;data&quot;: [</span><br><span class="line">                &quot;data&quot;</span><br><span class="line">            ],</span><br><span class="line">            &quot;model&quot;: [</span><br><span class="line">                &quot;model&quot;</span><br><span class="line">            ]</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;,</span><br><span class="line">    &quot;evaluation_0&quot;: &#123;</span><br><span class="line">        &quot;module&quot;: &quot;Evaluation&quot;,</span><br><span class="line">        &quot;input&quot;: &#123;</span><br><span class="line">            &quot;data&quot;: &#123;</span><br><span class="line">                &quot;data&quot;: [</span><br><span class="line">                    &quot;hetero_nn_0.data&quot;</span><br><span class="line">                ]</span><br><span class="line">            &#125;</span><br><span class="line">         &#125;,</span><br><span class="line">         &quot;output&quot;: &#123;</span><br><span class="line">             &quot;data&quot;: [</span><br><span class="line">                 &quot;data&quot;</span><br><span class="line">             ]</span><br><span class="line">          &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure><h1 id="基本工作流"><a href="#基本工作流" class="headerlink" title="基本工作流"></a>基本工作流</h1><ol><li>提交作业后，作业的dsl和配置会存储到相应的目录：<code>/data/projects/fate/fateflow/jobs</code></li><li>解析dsl和conf，生成配置，分发共同的配置给每一方，并生成存储特定方的配置在目录：<code>/data/projects/fate/fateflow/jobs/[job_id]/[role]/[party_id]</code></li></ol><p>‍</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;这里对FATE DSL文件做详细解释。&lt;/p&gt;
&lt;h1 id=&quot;DSL&quot;&gt;&lt;a href=&quot;#DSL&quot; class=&quot;headerlink&quot; title=&quot;DSL&quot;&gt;&lt;/a&gt;DSL&lt;/h1&gt;&lt;p&gt;DSL有两个版本，FATE 1.7以上版本强制使用v2。&lt;/p&gt;
&lt;p&gt;dsl</summary>
      
    
    
    
    <category term="联邦学习" scheme="https://guoyujian.github.io/categories/%E8%81%94%E9%82%A6%E5%AD%A6%E4%B9%A0/"/>
    
    
    <category term="联邦学习" scheme="https://guoyujian.github.io/tags/%E8%81%94%E9%82%A6%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>FATE横向联邦学习：信用数据案例</title>
    <link href="https://guoyujian.github.io/2022/11/04/FATE%E6%A8%AA%E5%90%91%E8%81%94%E9%82%A6%E5%AD%A6%E4%B9%A0%EF%BC%9A%E4%BF%A1%E7%94%A8%E6%95%B0%E6%8D%AE%E6%A1%88%E4%BE%8B/"/>
    <id>https://guoyujian.github.io/2022/11/04/FATE%E6%A8%AA%E5%90%91%E8%81%94%E9%82%A6%E5%AD%A6%E4%B9%A0%EF%BC%9A%E4%BF%A1%E7%94%A8%E6%95%B0%E6%8D%AE%E6%A1%88%E4%BE%8B/</id>
    <published>2022-11-03T16:01:28.000Z</published>
    <updated>2022-11-03T16:03:23.148Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>通过FATE平台提交联邦学习job，有两种方式：DSL和pipline；</p><p>DSL是通过写配置文件的方式，配置联邦学习job的各个参数；pipeline是通过写python代码的方式配置和提交job</p><p>本文使用Fate的信用样例数据，介绍通过DSL的方式进行Fate横向联邦学习的使用案例。</p></blockquote><h1 id="实验设置"><a href="#实验设置" class="headerlink" title="实验设置"></a>实验设置</h1><blockquote><p>fate lastest 1.9 standalone</p><p>数据集：信用数据，位置FATE/examples/data/default_credit_homo_guest/</p><p>算法：logistics regression</p></blockquote><h1 id="实验配置"><a href="#实验配置" class="headerlink" title="实验配置"></a>实验配置</h1><h2 id="上传两方数据"><a href="#上传两方数据" class="headerlink" title="上传两方数据"></a>上传两方数据</h2><p>编辑上传数据配置文件：upload_my_homolr_guest.json</p><figure class="highlight json"><table><tr><td class="code"><pre><span class="line"><span class="punctuation">&#123;</span></span><br><span class="line"> <span class="attr">&quot;file&quot;</span><span class="punctuation">:</span><span class="string">&quot;/data/projects/fate/examples/data/default_credit_homo_guest.csv&quot;</span><span class="punctuation">,</span></span><br><span class="line"> <span class="attr">&quot;head&quot;</span><span class="punctuation">:</span><span class="number">1</span><span class="punctuation">,</span></span><br><span class="line"> <span class="attr">&quot;partition&quot;</span><span class="punctuation">:</span><span class="number">10</span><span class="punctuation">,</span></span><br><span class="line"> <span class="attr">&quot;work_mode&quot;</span><span class="punctuation">:</span><span class="number">0</span><span class="punctuation">,</span></span><br><span class="line"> <span class="attr">&quot;namespace&quot;</span><span class="punctuation">:</span><span class="string">&quot;homo_default_credit_guest&quot;</span><span class="punctuation">,</span></span><br><span class="line"> <span class="attr">&quot;table_name&quot;</span><span class="punctuation">:</span><span class="string">&quot;homo_default_credit_guest&quot;</span></span><br><span class="line"><span class="punctuation">&#125;</span></span><br><span class="line"></span><br></pre></td></tr></table></figure><p>upload_my_homolr_host.json</p><figure class="highlight json"><table><tr><td class="code"><pre><span class="line"><span class="punctuation">&#123;</span></span><br><span class="line"> <span class="attr">&quot;file&quot;</span><span class="punctuation">:</span><span class="string">&quot;/data/projects/fate/examples/data/default_credit_homo_host_1.csv&quot;</span><span class="punctuation">,</span></span><br><span class="line"> <span class="attr">&quot;head&quot;</span><span class="punctuation">:</span><span class="number">1</span><span class="punctuation">,</span></span><br><span class="line"> <span class="attr">&quot;partition&quot;</span><span class="punctuation">:</span><span class="number">10</span><span class="punctuation">,</span></span><br><span class="line"> <span class="attr">&quot;work_mode&quot;</span><span class="punctuation">:</span><span class="number">0</span><span class="punctuation">,</span></span><br><span class="line"> <span class="attr">&quot;namespace&quot;</span><span class="punctuation">:</span><span class="string">&quot;homo_default_credit_host&quot;</span><span class="punctuation">,</span></span><br><span class="line"> <span class="attr">&quot;table_name&quot;</span><span class="punctuation">:</span><span class="string">&quot;homo_default_credit_host&quot;</span></span><br><span class="line"><span class="punctuation">&#125;</span></span><br><span class="line"></span><br></pre></td></tr></table></figure><p>说明：</p><ul><li>file指出数据文件的位置</li><li>namespace和table_name确定上传表的命名空间和表名。</li></ul><h2 id="DSL配置文件"><a href="#DSL配置文件" class="headerlink" title="DSL配置文件"></a>DSL配置文件</h2><p>找到dsl配置文件：<code>/data/projects/fate/examples/dsl/v2/homo_logistic_regression/homo_lr_train_dsl.json</code>，内容如下：</p><figure class="highlight json"><table><tr><td class="code"><pre><span class="line"><span class="punctuation">&#123;</span></span><br><span class="line">    <span class="attr">&quot;components&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">        <span class="attr">&quot;reader_0&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">            <span class="attr">&quot;module&quot;</span><span class="punctuation">:</span> <span class="string">&quot;Reader&quot;</span><span class="punctuation">,</span></span><br><span class="line">            <span class="attr">&quot;output&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">                <span class="attr">&quot;data&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span></span><br><span class="line">                    <span class="string">&quot;data&quot;</span></span><br><span class="line">                <span class="punctuation">]</span></span><br><span class="line">            <span class="punctuation">&#125;</span></span><br><span class="line">        <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">&quot;data_transform_0&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">            <span class="attr">&quot;module&quot;</span><span class="punctuation">:</span> <span class="string">&quot;DataTransform&quot;</span><span class="punctuation">,</span></span><br><span class="line">            <span class="attr">&quot;input&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">                <span class="attr">&quot;data&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">                    <span class="attr">&quot;data&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span></span><br><span class="line">                        <span class="string">&quot;reader_0.data&quot;</span></span><br><span class="line">                    <span class="punctuation">]</span></span><br><span class="line">                <span class="punctuation">&#125;</span></span><br><span class="line">            <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">            <span class="attr">&quot;output&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">                <span class="attr">&quot;data&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span></span><br><span class="line">                    <span class="string">&quot;data&quot;</span></span><br><span class="line">                <span class="punctuation">]</span><span class="punctuation">,</span></span><br><span class="line">                <span class="attr">&quot;model&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span></span><br><span class="line">                    <span class="string">&quot;model&quot;</span></span><br><span class="line">                <span class="punctuation">]</span></span><br><span class="line">            <span class="punctuation">&#125;</span></span><br><span class="line">        <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">&quot;scale_0&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">            <span class="attr">&quot;module&quot;</span><span class="punctuation">:</span> <span class="string">&quot;FeatureScale&quot;</span><span class="punctuation">,</span></span><br><span class="line">            <span class="attr">&quot;input&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">                <span class="attr">&quot;data&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">                    <span class="attr">&quot;data&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span></span><br><span class="line">                        <span class="string">&quot;data_transform_0.data&quot;</span></span><br><span class="line">                    <span class="punctuation">]</span></span><br><span class="line">                <span class="punctuation">&#125;</span></span><br><span class="line">            <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">            <span class="attr">&quot;output&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">                <span class="attr">&quot;data&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span></span><br><span class="line">                    <span class="string">&quot;data&quot;</span></span><br><span class="line">                <span class="punctuation">]</span><span class="punctuation">,</span></span><br><span class="line">                <span class="attr">&quot;model&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span></span><br><span class="line">                    <span class="string">&quot;model&quot;</span></span><br><span class="line">                <span class="punctuation">]</span></span><br><span class="line">            <span class="punctuation">&#125;</span></span><br><span class="line">        <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">&quot;homo_lr_0&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">            <span class="attr">&quot;module&quot;</span><span class="punctuation">:</span> <span class="string">&quot;HomoLR&quot;</span><span class="punctuation">,</span></span><br><span class="line">            <span class="attr">&quot;input&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">                <span class="attr">&quot;data&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">                    <span class="attr">&quot;train_data&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span></span><br><span class="line">                        <span class="string">&quot;scale_0.data&quot;</span></span><br><span class="line">                    <span class="punctuation">]</span></span><br><span class="line">                <span class="punctuation">&#125;</span></span><br><span class="line">            <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">            <span class="attr">&quot;output&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">                <span class="attr">&quot;data&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span></span><br><span class="line">                    <span class="string">&quot;data&quot;</span></span><br><span class="line">                <span class="punctuation">]</span><span class="punctuation">,</span></span><br><span class="line">                <span class="attr">&quot;model&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span></span><br><span class="line">                    <span class="string">&quot;model&quot;</span></span><br><span class="line">                <span class="punctuation">]</span></span><br><span class="line">            <span class="punctuation">&#125;</span></span><br><span class="line">        <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">&quot;evaluation_0&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">            <span class="attr">&quot;module&quot;</span><span class="punctuation">:</span> <span class="string">&quot;Evaluation&quot;</span><span class="punctuation">,</span></span><br><span class="line">            <span class="attr">&quot;input&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">                <span class="attr">&quot;data&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">                    <span class="attr">&quot;data&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span></span><br><span class="line">                        <span class="string">&quot;homo_lr_0.data&quot;</span></span><br><span class="line">                    <span class="punctuation">]</span></span><br><span class="line">                <span class="punctuation">&#125;</span></span><br><span class="line">            <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">            <span class="attr">&quot;output&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">                <span class="attr">&quot;data&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span></span><br><span class="line">                    <span class="string">&quot;data&quot;</span></span><br><span class="line">                <span class="punctuation">]</span></span><br><span class="line">            <span class="punctuation">&#125;</span></span><br><span class="line">        <span class="punctuation">&#125;</span></span><br><span class="line">    <span class="punctuation">&#125;</span></span><br><span class="line"><span class="punctuation">&#125;</span></span><br></pre></td></tr></table></figure><p>该文件配置了job的各个组件的类型，以及组件的输入、输出。</p><p>找到conf配置文件：<code>/data/projects/fate/examples/dsl/v2/homo_logistic_regression/homo_lr_train_conf.json</code>，内容（略作修改）如下：</p><figure class="highlight json"><table><tr><td class="code"><pre><span class="line"><span class="punctuation">&#123;</span></span><br><span class="line">    <span class="attr">&quot;dsl_version&quot;</span><span class="punctuation">:</span> <span class="number">2</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;initiator&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">        <span class="attr">&quot;role&quot;</span><span class="punctuation">:</span> <span class="string">&quot;guest&quot;</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">&quot;party_id&quot;</span><span class="punctuation">:</span> <span class="number">10000</span></span><br><span class="line">    <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;role&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">        <span class="attr">&quot;guest&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span></span><br><span class="line">            <span class="number">10000</span></span><br><span class="line">        <span class="punctuation">]</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">&quot;host&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span></span><br><span class="line">            <span class="number">10000</span></span><br><span class="line">        <span class="punctuation">]</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">&quot;arbiter&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span></span><br><span class="line">            <span class="number">10000</span></span><br><span class="line">        <span class="punctuation">]</span></span><br><span class="line">    <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;component_parameters&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">        <span class="attr">&quot;common&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">            <span class="attr">&quot;data_transform_0&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">                <span class="attr">&quot;with_label&quot;</span><span class="punctuation">:</span> <span class="keyword">true</span><span class="punctuation">,</span></span><br><span class="line">                <span class="attr">&quot;output_format&quot;</span><span class="punctuation">:</span> <span class="string">&quot;dense&quot;</span></span><br><span class="line">            <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">            <span class="attr">&quot;homo_lr_0&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">                <span class="attr">&quot;penalty&quot;</span><span class="punctuation">:</span> <span class="string">&quot;L2&quot;</span><span class="punctuation">,</span></span><br><span class="line">                <span class="attr">&quot;tol&quot;</span><span class="punctuation">:</span> <span class="number">1e-05</span><span class="punctuation">,</span></span><br><span class="line">                <span class="attr">&quot;alpha&quot;</span><span class="punctuation">:</span> <span class="number">0.01</span><span class="punctuation">,</span></span><br><span class="line">                <span class="attr">&quot;optimizer&quot;</span><span class="punctuation">:</span> <span class="string">&quot;sgd&quot;</span><span class="punctuation">,</span></span><br><span class="line">                <span class="attr">&quot;batch_size&quot;</span><span class="punctuation">:</span> <span class="number">-1</span><span class="punctuation">,</span></span><br><span class="line">                <span class="attr">&quot;learning_rate&quot;</span><span class="punctuation">:</span> <span class="number">0.15</span><span class="punctuation">,</span></span><br><span class="line">                <span class="attr">&quot;init_param&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">                    <span class="attr">&quot;init_method&quot;</span><span class="punctuation">:</span> <span class="string">&quot;zeros&quot;</span></span><br><span class="line">                <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">                <span class="attr">&quot;max_iter&quot;</span><span class="punctuation">:</span> <span class="number">30</span><span class="punctuation">,</span></span><br><span class="line">                <span class="attr">&quot;early_stop&quot;</span><span class="punctuation">:</span> <span class="string">&quot;diff&quot;</span><span class="punctuation">,</span></span><br><span class="line">                <span class="attr">&quot;encrypt_param&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">                    <span class="attr">&quot;method&quot;</span><span class="punctuation">:</span> <span class="keyword">null</span></span><br><span class="line">                <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">                <span class="attr">&quot;cv_param&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">                    <span class="attr">&quot;n_splits&quot;</span><span class="punctuation">:</span> <span class="number">4</span><span class="punctuation">,</span></span><br><span class="line">                    <span class="attr">&quot;shuffle&quot;</span><span class="punctuation">:</span> <span class="keyword">true</span><span class="punctuation">,</span></span><br><span class="line">                    <span class="attr">&quot;random_seed&quot;</span><span class="punctuation">:</span> <span class="number">33</span><span class="punctuation">,</span></span><br><span class="line">                    <span class="attr">&quot;need_cv&quot;</span><span class="punctuation">:</span> <span class="keyword">false</span></span><br><span class="line">                <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">                <span class="attr">&quot;decay&quot;</span><span class="punctuation">:</span> <span class="number">1</span><span class="punctuation">,</span></span><br><span class="line">                <span class="attr">&quot;decay_sqrt&quot;</span><span class="punctuation">:</span> <span class="keyword">true</span></span><br><span class="line">            <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">            <span class="attr">&quot;evaluation_0&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">                <span class="attr">&quot;eval_type&quot;</span><span class="punctuation">:</span> <span class="string">&quot;binary&quot;</span></span><br><span class="line">            <span class="punctuation">&#125;</span></span><br><span class="line">        <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">&quot;role&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">            <span class="attr">&quot;host&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">                <span class="attr">&quot;0&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">                    <span class="attr">&quot;reader_0&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">                        <span class="attr">&quot;table&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">                            <span class="attr">&quot;name&quot;</span><span class="punctuation">:</span> <span class="string">&quot;homo_default_credit_guest&quot;</span><span class="punctuation">,</span></span><br><span class="line">                            <span class="attr">&quot;namespace&quot;</span><span class="punctuation">:</span> <span class="string">&quot;homo_default_credit_guest&quot;</span></span><br><span class="line">                        <span class="punctuation">&#125;</span></span><br><span class="line">                    <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">                    <span class="attr">&quot;evaluation_0&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">                        <span class="attr">&quot;need_run&quot;</span><span class="punctuation">:</span> <span class="keyword">false</span></span><br><span class="line">                    <span class="punctuation">&#125;</span></span><br><span class="line">                <span class="punctuation">&#125;</span></span><br><span class="line">            <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">            <span class="attr">&quot;guest&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">                <span class="attr">&quot;0&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">                    <span class="attr">&quot;reader_0&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">                        <span class="attr">&quot;table&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">                            <span class="attr">&quot;name&quot;</span><span class="punctuation">:</span> <span class="string">&quot;homo_default_credit_host&quot;</span><span class="punctuation">,</span></span><br><span class="line">                            <span class="attr">&quot;namespace&quot;</span><span class="punctuation">:</span> <span class="string">&quot;homo_default_credit_host&quot;</span></span><br><span class="line">                        <span class="punctuation">&#125;</span></span><br><span class="line">                    <span class="punctuation">&#125;</span></span><br><span class="line">                <span class="punctuation">&#125;</span></span><br><span class="line">            <span class="punctuation">&#125;</span></span><br><span class="line">        <span class="punctuation">&#125;</span></span><br><span class="line">    <span class="punctuation">&#125;</span></span><br><span class="line"><span class="punctuation">&#125;</span></span><br></pre></td></tr></table></figure><p>该文件配置了联邦学习发起方（initiator）、参与方（role）以及每一方组件的参数（component_parameters）。</p><blockquote><ol><li>initiator段设置了联邦发起者的角色和id</li><li>role段设置了联邦的参与方，和参与方的角色</li><li>job_parameters定义了工作模式（单机/集群）</li><li>component_parameters设置了组件的参数，分为各参与方公共的参数（common），以及各参与方的独特的参数（role）</li></ol></blockquote><h1 id="实验步骤"><a href="#实验步骤" class="headerlink" title="实验步骤"></a>实验步骤</h1><p>进入实验环境；这里使用standalone模拟两方联邦学习，所以所有操作是在同一机器上进行。</p><h2 id="上传训练数据"><a href="#上传训练数据" class="headerlink" title="上传训练数据"></a>上传训练数据</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">(venv) [root@5af726377674 fate]<span class="comment"># flow data upload -c upload_my_homolr_guest.json</span></span><br><span class="line">...</span><br><span class="line">(venv) [root@5af726377674 fate]<span class="comment"># flow data upload -c upload_my_homolr_host.json</span></span><br><span class="line">...</span><br><span class="line"><span class="comment">#guest host分两次上传。</span></span><br></pre></td></tr></table></figure><p>使用flow table 查看上传的表信息：homo_default_credit_host</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">(venv) [root@5af726377674 fate]# flow table info -n homo_default_credit_host -t homo_default_credit_host</span><br><span class="line">&#123;</span><br><span class="line">    &quot;data&quot;: &#123;</span><br><span class="line">        &quot;address&quot;: &#123;</span><br><span class="line">            &quot;connector_name&quot;: null,</span><br><span class="line">            &quot;home&quot;: null,</span><br><span class="line">            &quot;name&quot;: &quot;homo_default_credit_host&quot;,</span><br><span class="line">            &quot;namespace&quot;: &quot;homo_default_credit_host&quot;,</span><br><span class="line">            &quot;storage_type&quot;: &quot;LMDB&quot;</span><br><span class="line">        &#125;,</span><br><span class="line">        &quot;count&quot;: 8000,</span><br><span class="line">        &quot;enable&quot;: true,</span><br><span class="line">        &quot;exist&quot;: 1,</span><br><span class="line">        &quot;namespace&quot;: &quot;homo_default_credit_host&quot;,</span><br><span class="line">        &quot;origin&quot;: &quot;upload&quot;,</span><br><span class="line">        &quot;partition&quot;: 10,</span><br><span class="line">        &quot;schema&quot;: &#123;</span><br><span class="line">            &quot;header&quot;: &quot;y,x0,x1,x2,x3,x4,x5,x6,x7,x8,x9,x10,x11,x12,x13,x14,x15,x16,x17,x18,x19,x20,x21,x22&quot;,</span><br><span class="line">            &quot;sid&quot;: &quot;id&quot;</span><br><span class="line">        &#125;,</span><br><span class="line">        &quot;table_name&quot;: &quot;homo_default_credit_host&quot;</span><br><span class="line">    &#125;,</span><br><span class="line">    &quot;retcode&quot;: 0,</span><br><span class="line">    &quot;retmsg&quot;: &quot;success&quot;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure><h2 id="提交训练任务"><a href="#提交训练任务" class="headerlink" title="提交训练任务"></a>提交训练任务</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">(venv) [root@5af726377674 fate]<span class="comment"># flow job submit -d test_my_homolr_train_dsl.json -c test_my_homolr_train_conf.json </span></span><br><span class="line">&#123;</span><br><span class="line">    <span class="string">&quot;data&quot;</span>: &#123;</span><br><span class="line">        <span class="string">&quot;board_url&quot;</span>: <span class="string">&quot;http://127.0.0.1:8080/index.html#/dashboard?job_id=202209200821441165650&amp;role=guest&amp;party_id=10000&quot;</span>,</span><br><span class="line">        <span class="string">&quot;code&quot;</span>: 0,</span><br><span class="line">        <span class="string">&quot;dsl_path&quot;</span>: <span class="string">&quot;/data/projects/fate/fateflow/jobs/202209200821441165650/job_dsl.json&quot;</span>,</span><br><span class="line">        <span class="string">&quot;job_id&quot;</span>: <span class="string">&quot;202209200821441165650&quot;</span>,</span><br><span class="line">        <span class="string">&quot;logs_directory&quot;</span>: <span class="string">&quot;/data/projects/fate/fateflow/logs/202209200821441165650&quot;</span>,</span><br><span class="line">        <span class="string">&quot;message&quot;</span>: <span class="string">&quot;success&quot;</span>,</span><br><span class="line">        <span class="string">&quot;model_info&quot;</span>: &#123;</span><br><span class="line">            <span class="string">&quot;model_id&quot;</span>: <span class="string">&quot;arbiter-10000#guest-10000#host-10000#model&quot;</span>,</span><br><span class="line">            <span class="string">&quot;model_version&quot;</span>: <span class="string">&quot;202209200821441165650&quot;</span></span><br><span class="line">        &#125;,</span><br><span class="line">        <span class="string">&quot;pipeline_dsl_path&quot;</span>: <span class="string">&quot;/data/projects/fate/fateflow/jobs/202209200821441165650/pipeline_dsl.json&quot;</span>,</span><br><span class="line">        <span class="string">&quot;runtime_conf_on_party_path&quot;</span>: <span class="string">&quot;/data/projects/fate/fateflow/jobs/202209200821441165650/guest/10000/job_runtime_on_party_conf.json&quot;</span>,</span><br><span class="line">        <span class="string">&quot;runtime_conf_path&quot;</span>: <span class="string">&quot;/data/projects/fate/fateflow/jobs/202209200821441165650/job_runtime_conf.json&quot;</span>,</span><br><span class="line">        <span class="string">&quot;train_runtime_conf_path&quot;</span>: <span class="string">&quot;/data/projects/fate/fateflow/jobs/202209200821441165650/train_runtime_conf.json&quot;</span></span><br><span class="line">    &#125;,</span><br><span class="line">    <span class="string">&quot;jobId&quot;</span>: <span class="string">&quot;202209200821441165650&quot;</span>,</span><br><span class="line">    <span class="string">&quot;retcode&quot;</span>: 0,</span><br><span class="line">    <span class="string">&quot;retmsg&quot;</span>: <span class="string">&quot;success&quot;</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure><h2 id="查看状态"><a href="#查看状态" class="headerlink" title="查看状态"></a>查看状态</h2><p>在fate-board上查看训练状态：<code>http://ip:8086</code></p><p><img src="image-20220920170949-v81vtm8.png" alt="image.png"></p><p>选择<code>guest</code>的那条记录，进入详情页。点击<code>evaluation</code>，选择<code>view the outputs</code>，查看模型效果。</p><p><img src="image-20220920203955-qua2axz.png" alt="image.png"></p><p><img src="image-20220920204118-0eu2i1y.png" alt="image.png"></p><p>loss在<code>homo_lr_0</code>的outputs</p><p>‍</p><h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><ol><li>使用DSL进行FATE横向联邦学习的流程包括：各方上传数据；编写DSL和CONF文件配置组件、参与方信息等；提交job。</li><li>为了方便测试，这里使用的standalone单机版本，所以所有操作都在同一台机器上。实际在集群上可能会有所不同，例如需要在多方机器上上传不同的数据。</li><li>FATE的组件列表、组件输入的格式、组件的参数配置可以查看官方文档：<a href="https://fate.readthedocs.io/en/latest/federatedml_component/">https://fate.readthedocs.io/en/latest/federatedml_component/</a></li><li>FATE关于DSL和CONF文件的配置说明可以参考：<a href="https://github.com/FederatedAI/FATE/blob/master/doc/tutorial/dsl_conf/dsl_conf_v2_setting_guide.zh.md">https://github.com/FederatedAI/FATE/blob/master/doc/tutorial/dsl_conf/dsl_conf_v2_setting_guide.zh.md</a></li><li>flow命令指南：<a href="https://federatedai.github.io/FATE-Flow/latest/zh/document_navigation/">https://federatedai.github.io/FATE-Flow/latest/zh/document_navigation/</a></li><li>flow api文档：<a href="https://federatedai.github.io/FATE-Flow/latest/zh/swagger/">https://federatedai.github.io/FATE-Flow/latest/zh/swagger/</a></li></ol><h1 id="Refs"><a href="#Refs" class="headerlink" title="Refs"></a>Refs</h1><ol><li><a href="https://www.freesion.com/article/2169210597/#1_3">联邦学习框架FATE使用案例记录</a></li><li><a href="https://blog.csdn.net/WenDong1997/article/details/106743620">联邦学习框架FATE实践（训练/测试步骤及参数说明</a></li></ol><p>‍</p>]]></content>
    
    
      
      
    <summary type="html">&lt;blockquote&gt;
&lt;p&gt;通过FATE平台提交联邦学习job，有两种方式：DSL和pipline；&lt;/p&gt;
&lt;p&gt;DSL是通过写配置文件的方式，配置联邦学习job的各个参数；pipeline是通过写python代码的方式配置和提交job&lt;/p&gt;
&lt;p&gt;本文使用Fate的信用</summary>
      
    
    
    
    <category term="联邦学习" scheme="https://guoyujian.github.io/categories/%E8%81%94%E9%82%A6%E5%AD%A6%E4%B9%A0/"/>
    
    
    <category term="联邦学习" scheme="https://guoyujian.github.io/tags/%E8%81%94%E9%82%A6%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>FATE联邦学习框架简介</title>
    <link href="https://guoyujian.github.io/2022/11/03/FATE%E8%81%94%E9%82%A6%E5%AD%A6%E4%B9%A0%E6%A1%86%E6%9E%B6%E7%AE%80%E4%BB%8B/"/>
    <id>https://guoyujian.github.io/2022/11/03/FATE%E8%81%94%E9%82%A6%E5%AD%A6%E4%B9%A0%E6%A1%86%E6%9E%B6%E7%AE%80%E4%BB%8B/</id>
    <published>2022-11-03T15:57:19.000Z</published>
    <updated>2022-11-03T16:00:29.302Z</updated>
    
    <content type="html"><![CDATA[<h1 id="联邦学习介绍"><a href="#联邦学习介绍" class="headerlink" title="联邦学习介绍"></a>联邦学习介绍</h1><h2 id="联邦学习的出现解决什么问题"><a href="#联邦学习的出现解决什么问题" class="headerlink" title="联邦学习的出现解决什么问题"></a>联邦学习的出现解决什么问题</h2><p>解决“数据孤岛”问题，保证数据安全与隐私保护。</p><p>由于各种原因，数据孤岛问题普遍存在。在用户和企业角度下，商业公司所拥有的数据往往都有巨大的潜在价值。两个公司甚至公司间的部门都要考虑利益的交换，往往这些机构不会提供各自数据与其他公司做与单的聚合，导致即使在同一个公司内，数据也往往以孤岛形式出现。</p><h2 id="联邦学习的概念"><a href="#联邦学习的概念" class="headerlink" title="联邦学习的概念"></a>联邦学习的概念</h2><p>本质：联邦学习本质上是一种<strong>分布式</strong>机器学习技术，或机器学习<strong>框架</strong>。</p><p>目标：联邦学习的目标是在保证数据隐私安全及合法合规的基础上，实现共同建模，提升AI模型的效果。</p><h2 id="联邦学习的分类"><a href="#联邦学习的分类" class="headerlink" title="联邦学习的分类"></a>联邦学习的分类</h2><p>根据每个参与共同建模的企业称为参与方，根据多参与方之间数据分布的不同，把联邦学习分为三类：横向联邦学习、纵向联邦学习和联邦迁移学习。</p><p><img src="image-20221016171301-jpflppr.png" alt="image.png"></p><ul><li>横向联邦适用于，参与方之间的数据特征相似，但样本不同。</li><li>纵向联邦适用于，参与方之间的数据特征重叠多，但样本重叠少。</li><li>联邦迁移学习则适用于，参与方之间的数据特征重叠少，样本重叠也少。</li></ul><p>这三种类型的联邦学习的学习过程不太相同，这里不做详细描述。</p><h2 id="联邦学习框架"><a href="#联邦学习框架" class="headerlink" title="联邦学习框架"></a>联邦学习框架</h2><p>据了解，联邦学习框架有Fate、PySyft、FedLab、Rosetta、PaddleFL等等。具体可参见<a href="https://zhuanlan.zhihu.com/p/387101962">联邦学习开源框架调研</a></p><p>不同框架的受众定位、加密手段、支持的算法、开发的机构不同。下面是对比图。图片来源于Fate官网。</p><p>这张图时间比较久了，具体还是要看最新版本。</p><p><img src="image-20220907160332-fp0kf9k.png" alt="image.png"></p><p>‍</p><h1 id="Fate介绍"><a href="#Fate介绍" class="headerlink" title="Fate介绍"></a>Fate介绍</h1><p>FATE (Federated AI Technology Enabler) 是微众银行AI部门发起的开源项目，为联邦学习生态系统提供了可靠的安全计算框架。FATE项目使用多方安全计算 (MPC) 以及同态加密 (HE) 技术构建底层安全计算协议，以此支持不同种类的机器学习的安全计算，包括逻辑回归、基于树的算法、深度学习和迁移学习等。</p><h2 id="Fate架构"><a href="#Fate架构" class="headerlink" title="Fate架构"></a>Fate架构</h2><p><img src="image-20220907151347-1sl8y67.png" alt="image.png"></p><p>其中，</p><ul><li>FATE Board：联邦学习可视化界面。</li><li>FATE Flow：联邦学习端到端全流程的多方联合任务安全调度平台，提供生产级的服务能力。</li><li>FATE Serving：在线模型管理服务（只支持纵向联邦学习）</li><li>FederatedML：联邦学习的核心组件</li><li>Secure Protocols：FATE的安全协议</li></ul><h2 id="FATE核心功能"><a href="#FATE核心功能" class="headerlink" title="FATE核心功能"></a>FATE核心功能</h2><ul><li>联邦在线模型服务（FATE Serving）</li><li>联邦建模Pipline和可视化（FATE Flow）</li><li>联邦学习算法的各个功能组件（FederatedML）</li><li>分布式计算和存储抽象（EggRoll）</li><li>跨站点网络通信抽象（Federated Network）</li></ul><h2 id="更多介绍"><a href="#更多介绍" class="headerlink" title="更多介绍"></a>更多介绍</h2><p>FATE github地址：<a href="https://github.com/FederatedAI/FATE">https://github.com/FederatedAI/FATE</a></p><h2 id="单机版FATE安装"><a href="#单机版FATE安装" class="headerlink" title="单机版FATE安装"></a>单机版FATE安装</h2><p>这里采用docker安装</p><p><a href="https://github.com/FederatedAI/FATE/blob/master/deploy/standalone-deploy/README.zh.md">部署文档</a></p><p>如果需要docker使用GPU资源，需要在docker容器启动时加上参数<code>--gpus</code></p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">docker run -d --gpus all --name standalone_fate -p 8080:8080 federatedai/standalone_fate:1.9.0</span><br></pre></td></tr></table></figure><p>如果启动报类似错误：<code>Error could not select device driver with capabilities: [[gpu]]</code>，则查看下面的链接进行解决。</p><p><a href="https://developer.aliyun.com/article/767168">Centos7安装nvidia-container-toolkit</a></p><p>安装完成后，进入容器，要先执行命令：<code>source bin/init_env.sh</code></p><p>FATE Board 默认用户名密码：admin/admin</p><p>想要修改用户名和密码</p><p><code>/data/projects/fate/fateboard/conf/application.properties</code></p><h2 id="集群版"><a href="#集群版" class="headerlink" title="集群版"></a>集群版</h2><p>集群可以使用docker-compose或者kube安装，这里不做介绍。</p><p>集群版会加入eggroll、mysql之类的组件，其开放的端口如下：</p><p><img src="C:/Users/11599/Desktop/FATE联邦学习框架/FATE联邦学习框架/assets/image-20220923161817-1viqwi3.png" alt="image.png"></p><p>9380端口是FATE flow调用api的接口，有哪些接口可以参看下面的链接。</p><p><a href="https://federatedai.github.io/FATE-Flow/latest/zh/swagger/">https://federatedai.github.io/FATE-Flow/latest/zh/swagger/</a></p><p>集群安装后，每个节点应该有以下docker容器</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">fate@vm172-31-0-217:~$ docker ps </span><br><span class="line">CONTAINER ID   IMAGE                                   COMMAND                  CREATED       STATUS                PORTS                                            NAMES</span><br><span class="line">f2ab95400e3f   federatedai/client:1.9.0-release        <span class="string">&quot;/bin/sh -c &#x27;flow in…&quot;</span>   2 weeks ago   Up 7 days             0.0.0.0:20000-&gt;20000/tcp                         confs-10000-client-1</span><br><span class="line">f24fac183cbe   federatedai/fateboard:1.9.0-release     <span class="string">&quot;/bin/sh -c &#x27;java -D…&quot;</span>   2 weeks ago   Up 7 days             0.0.0.0:6080-&gt;6080/tcp, 8080/tcp                 confs-10000-fateboard-1</span><br><span class="line">33ca56f46fe3   federatedai/fateflow-nn:1.9.0-release   <span class="string">&quot;/bin/bash -c &#x27;set -…&quot;</span>   2 weeks ago   Up 7 days (healthy)   0.0.0.0:9360-&gt;9360/tcp, 0.0.0.0:9380-&gt;9380/tcp   confs-10000-fateflow-1</span><br><span class="line">4dbb83db37cc   mysql:8.0.28                            <span class="string">&quot;docker-entrypoint.s…&quot;</span>   2 weeks ago   Up 7 days             3306/tcp, 33060/tcp                              confs-10000-mysql-1</span><br><span class="line">7e4567d52d9d   federatedai/eggroll-nn:1.9.0-release    <span class="string">&quot;/tini -- bash -c &#x27;j…&quot;</span>   2 weeks ago   Up 7 days             0.0.0.0:9370-&gt;9370/tcp                           confs-10000-rollsite-1</span><br><span class="line">10f118347296   federatedai/eggroll-nn:1.9.0-release    <span class="string">&quot;/tini -- bash -c &#x27;j…&quot;</span>   2 weeks ago   Up 7 days             4670/tcp                                         confs-10000-clustermanager-1</span><br><span class="line">7ceafb32bfd9   federatedai/eggroll-nn:1.9.0-release    <span class="string">&quot;/tini -- bash -c &#x27;j…&quot;</span>   2 weeks ago   Up 7 days             4671/tcp   </span><br></pre></td></tr></table></figure><p>集群开放的端口：</p><div class="table-container"><table><thead><tr><th>port</th><th>service</th></tr></thead><tbody><tr><td>6080</td><td>fate-board</td></tr><tr><td>8350</td><td>serving</td></tr><tr><td>20000</td><td>jupyter</td></tr><tr><td>9370</td><td>rollsite</td></tr><tr><td>9380</td><td>flow api</td></tr></tbody></table></div><p>这里我们使用了四个节点，分别是FATE9997-10000，其中FATE10000为arbiter用于将梯度聚合和分发，其余为guest/host，是参与联邦学习的各方。</p><h2 id="Toy-Test"><a href="#Toy-Test" class="headerlink" title="Toy Test"></a>Toy Test</h2><p>安装完成后可以进行简单测试，以检查安装是否成功。10000是各个参与方的partyid</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">flow test toy -gid 10000 -hid 10000</span><br></pre></td></tr></table></figure><h1 id="Refs"><a href="#Refs" class="headerlink" title="Refs"></a>Refs</h1><ol><li><a href="https://zhuanlan.zhihu.com/p/79284686">详解联邦学习Federated Learning</a></li></ol><p>‍</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;联邦学习介绍&quot;&gt;&lt;a href=&quot;#联邦学习介绍&quot; class=&quot;headerlink&quot; title=&quot;联邦学习介绍&quot;&gt;&lt;/a&gt;联邦学习介绍&lt;/h1&gt;&lt;h2 id=&quot;联邦学习的出现解决什么问题&quot;&gt;&lt;a href=&quot;#联邦学习的出现解决什么问题&quot; class=&quot;he</summary>
      
    
    
    
    <category term="联邦学习" scheme="https://guoyujian.github.io/categories/%E8%81%94%E9%82%A6%E5%AD%A6%E4%B9%A0/"/>
    
    
    <category term="联邦学习" scheme="https://guoyujian.github.io/tags/%E8%81%94%E9%82%A6%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>FATE联邦学习框架（共八篇）</title>
    <link href="https://guoyujian.github.io/2022/11/03/FATE%E8%81%94%E9%82%A6%E5%AD%A6%E4%B9%A0%E6%A1%86%E6%9E%B6%EF%BC%88%E5%85%B1%E5%85%AB%E7%AF%87%EF%BC%89/"/>
    <id>https://guoyujian.github.io/2022/11/03/FATE%E8%81%94%E9%82%A6%E5%AD%A6%E4%B9%A0%E6%A1%86%E6%9E%B6%EF%BC%88%E5%85%B1%E5%85%AB%E7%AF%87%EF%BC%89/</id>
    <published>2022-11-03T15:55:20.000Z</published>
    <updated>2022-11-07T13:48:50.085Z</updated>
    
    <content type="html"><![CDATA[<h1 id="目录"><a href="#目录" class="headerlink" title="目录"></a>目录</h1><ol><li>FATE联邦学习框架简介：联邦学习+fate介绍+单机版docker安装+toy test</li><li>FATE横向联邦学习：信用数据案例</li><li>FATE DSL配置文件详细解释</li><li>FATE横向联邦学习：手写数字识别（开发组件：自定义的模型、使用gpu、模型评估？）</li><li>FATE横向联邦学习：肠癌图像分类任务（上）——baseline</li><li>FATE横向联邦学习：肠癌图像分类任务（下）——联邦化</li><li>FATE横向联邦学习：肺炎的多模态任务的联邦学习</li><li>FATE使用遇到的问题汇总</li></ol><h1 id="仓库"><a href="#仓库" class="headerlink" title="仓库"></a>仓库</h1><p><a href="https://github.com/guoyujian/FATE">https://github.com/guoyujian/FATE</a></p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;目录&quot;&gt;&lt;a href=&quot;#目录&quot; class=&quot;headerlink&quot; title=&quot;目录&quot;&gt;&lt;/a&gt;目录&lt;/h1&gt;&lt;ol&gt;
&lt;li&gt;FATE联邦学习框架简介：联邦学习+fate介绍+单机版docker安装+toy test&lt;/li&gt;
&lt;li&gt;FATE横向联邦学</summary>
      
    
    
    
    <category term="联邦学习" scheme="https://guoyujian.github.io/categories/%E8%81%94%E9%82%A6%E5%AD%A6%E4%B9%A0/"/>
    
    
    <category term="联邦学习" scheme="https://guoyujian.github.io/tags/%E8%81%94%E9%82%A6%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>HTTP缓存</title>
    <link href="https://guoyujian.github.io/2022/09/24/HTTP%E7%BC%93%E5%AD%98/"/>
    <id>https://guoyujian.github.io/2022/09/24/HTTP%E7%BC%93%E5%AD%98/</id>
    <published>2022-09-23T16:26:34.000Z</published>
    <updated>2022-09-23T16:32:47.718Z</updated>
    
    <content type="html"><![CDATA[<h1 id="前端缓存知识点"><a href="#前端缓存知识点" class="headerlink" title="前端缓存知识点"></a>前端缓存知识点</h1><p><img src="前端缓存一览.png" alt="前端缓存一览">​</p><h1 id="什么是HTTP缓存"><a href="#什么是HTTP缓存" class="headerlink" title="什么是HTTP缓存"></a>什么是HTTP缓存</h1><p>http缓存指的是: 当客户端向服务器请求资源时，会先抵达浏览器缓存，如果浏览器有“要请求资源”的副本，就可以直接从浏览器缓存中提取而不是从原始服务器中提取这个资源。</p><p>常见的http缓存只能缓存get请求响应的资源，对于其他类型的响应则无能为力，所以后续说的请求缓存都是指GET请求。</p><p>http缓存都是从第二次请求开始的。第一次请求资源时，服务器返回资源，并在respone header头中回传资源的缓存参数；第二次请求时，浏览器判断这些请求参数，命中强缓存就直接200，否则就把请求参数加到request header头中传给服务器，看是否命中协商缓存，命中则返回304，否则服务器会返回新的资源。</p><h1 id="为什么要使用HTTP缓存-？"><a href="#为什么要使用HTTP缓存-？" class="headerlink" title="为什么要使用HTTP缓存 ？"></a>为什么要使用HTTP缓存 ？</h1><ol><li>减少了冗余的数据传输，节省了网费。</li><li>缓解了服务器的压力， 大大提高了网站的性能</li><li>加快了客户端加载网页的速度</li></ol><h1 id="如何使用HTTP缓存-？"><a href="#如何使用HTTP缓存-？" class="headerlink" title="如何使用HTTP缓存 ？"></a>如何使用HTTP缓存 ？</h1><p>一般需要缓存的资源有html页面和其他静态资源：</p><blockquote><p>1、 <strong>html页面缓存的设置主要是在<code>&lt;head&gt;</code>标签中嵌入<code>&lt;meta&gt;</code>标签，这种方式只对页面有效，对页面上的资源无效</strong></p></blockquote><p>1.1 html页面禁用缓存的设置如下：</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&lt;meta http-equiv=&quot;cache-control&quot; content=&quot;no-cache&quot; \&gt;</span><br></pre></td></tr></table></figure><p>1.2 html设置缓存如下：</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&lt;meta http-equiv=&quot;Cache-Control&quot; content=&quot;max-age=7200&quot; /&gt;</span><br></pre></td></tr></table></figure><blockquote><p>2、 <strong>静态资源的缓存一般是在web服务器上配置的，常用的web服务器有：nginx、apache。具体的配置这里不做详细介绍，大家自行查阅。</strong></p><p><strong>3、不想使用缓存的几种方式</strong></p></blockquote><ul><li>Ctrl + F5强制刷新，都会直接向服务器提取数据。</li><li>按F5刷新或浏览器的刷新按钮，默认加上Cache-Control：max-age=0，即会走协商缓存。</li><li>还有就是上面1、2中禁用缓存的做法</li></ul><h1 id="HTTP缓存的几个注意点"><a href="#HTTP缓存的几个注意点" class="headerlink" title="HTTP缓存的几个注意点"></a>HTTP缓存的几个注意点</h1><p>1、强缓存情况下，只要缓存还没过期，就会直接从缓存中取数据，就算服务器端有数据变化，也不会从服务器端获取了，这样就无法获取到修改后的数据。解决的办法有：在修改后的资源加上随机数，确保不会从缓存中取。</p><p>例如：<code>http://www.kimshare.club/kim/common.css?v=22324432</code></p><p>2、尽量减少304的请求，因为我们知道，协商缓存每次都会与后台服务器进行交互，所以性能上不是很好。从性能上来看尽量多使用强缓存。</p><p>3、与缓存相关的几个header属性有：Vary、Date/Age。</p><h1 id="HTTP缓存的分类"><a href="#HTTP缓存的分类" class="headerlink" title="HTTP缓存的分类"></a><strong>HTTP缓存的分类</strong></h1><ul><li>根据是否需要重新向服务器发起请求来分类，可分为强制缓存，协商缓存</li><li>根据是否可以被单个或者多个用户使用来分类，可分为私有缓存，共享缓存（不care）</li></ul><p>强制缓存如果生效，不需要再和服务器发生交互，而协商缓存不管是否生效，都需要与服务端发生交互。下面是强制缓存和协商缓存的一些对比：</p><p><img src="HTTP缓存分类.png" alt="HTTP缓存分类"></p><h2 id="强缓存"><a href="#强缓存" class="headerlink" title="强缓存"></a>强缓存</h2><p>强制缓存在缓存数据未失效的情况下（即Cache-Control的max-age没有过期或者Expires的缓存时间没有过期），那么就会直接使用浏览器的缓存数据，不会再向服务器发送任何请求。</p><p>强制缓存生效时，http状态码为200。这种方式页面的加载速度是最快的，性能也是很好的，但是在这期间，如果服务器端的资源修改了，页面上是拿不到的，因为它不会再向服务器发请求了。</p><p>这种情况就是我们在开发种经常遇到的，比如你修改了页面上的某个样式，在页面上刷新了但没有生效，因为走的是强缓存，所以Ctrl + F5一顿操作之后就好了。 </p><p>跟强制缓存相关的header头属性有（Pragma/Cache-Control/Expires）</p><h2 id="协商缓存"><a href="#协商缓存" class="headerlink" title="协商缓存"></a>协商缓存</h2><p>当第一次请求时服务器返回的响应头中没有Cache-Control和Expires或者Cache-Control和Expires过期还或者它的属性设置为no-cache时(即不走强缓存)，那么浏览器第二次请求时就会与服务器进行协商，与服务器端对比判断资源是否进行了修改更新。</p><p>如果服务器端的资源没有修改，那么就会返回304状态码，告诉浏览器可以使用缓存中的数据，这样就减少了服务器的数据传输压力。</p><p>如果数据有更新就会返回200状态码，服务器就会返回更新后的资源并且将缓存信息一起返回。</p><p>跟协商缓存相关的header头属性有（ETag/If-Not-Match 、Last-Modified/If-Modified-Since）请求头和响应头需要成对出现。</p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p><strong>下图是浏览器首次和再次发送http请求的执行流程图：</strong></p><p><img src="首次HTTP请求.png" alt="首次HTTP请求"></p><p><img src="再次HTTP请求.png" alt="再次HTTP请求"></p><h1 id="Refs"><a href="#Refs" class="headerlink" title="Refs"></a>Refs</h1><ol><li><a href="https://www.jianshu.com/p/227cee9c8d15">https://www.jianshu.com/p/227cee9c8d15</a></li></ol>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;前端缓存知识点&quot;&gt;&lt;a href=&quot;#前端缓存知识点&quot; class=&quot;headerlink&quot; title=&quot;前端缓存知识点&quot;&gt;&lt;/a&gt;前端缓存知识点&lt;/h1&gt;&lt;p&gt;&lt;img src=&quot;前端缓存一览.png&quot; alt=&quot;前端缓存一览&quot;&gt;​&lt;/p&gt;
&lt;h1 id=&quot;什</summary>
      
    
    
    
    <category term="计算机网络" scheme="https://guoyujian.github.io/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/"/>
    
    <category term="HTTP协议" scheme="https://guoyujian.github.io/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/HTTP%E5%8D%8F%E8%AE%AE/"/>
    
    
    <category term="计算机网络" scheme="https://guoyujian.github.io/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/"/>
    
    <category term="HTTP协议" scheme="https://guoyujian.github.io/tags/HTTP%E5%8D%8F%E8%AE%AE/"/>
    
  </entry>
  
  <entry>
    <title>HTTPS协议</title>
    <link href="https://guoyujian.github.io/2022/09/24/HTTPS%E5%8D%8F%E8%AE%AE/"/>
    <id>https://guoyujian.github.io/2022/09/24/HTTPS%E5%8D%8F%E8%AE%AE/</id>
    <published>2022-09-23T16:22:25.000Z</published>
    <updated>2022-09-23T16:25:50.622Z</updated>
    
    <content type="html"><![CDATA[<h1 id="前置知识"><a href="#前置知识" class="headerlink" title="前置知识"></a>前置知识</h1><p>加密分为对称加密和非对称加密，HTTPS兼顾两者。</p><p>关于非对称加密，可以查阅相关资料。这里只提一点：</p><blockquote><p><strong>公钥加密，私钥解密！</strong></p></blockquote><h1 id="为什么需要HTTPS"><a href="#为什么需要HTTPS" class="headerlink" title="为什么需要HTTPS"></a>为什么需要HTTPS</h1><p>HTTP 主要有这些不足：</p><ul><li>通信使用明文（不加密），内容可能会被窃听；</li><li>不验证通信方的身份，因此有可能遭遇伪装；</li><li>无法证明报文的完整性，所以有可能已遭篡改；</li></ul><p>为了解决这些问题，HTTPS顺应而生。</p><h1 id="HTTPS介绍"><a href="#HTTPS介绍" class="headerlink" title="HTTPS介绍"></a>HTTPS介绍</h1><p><strong>HTTP+ 加密 + 认证 + 完整性保护=HTTPS</strong>。</p><p>可以这么理解，HTTPS是安全版的HTTP，它不是一个新的协议，而是HTTP 加上加密处理（解决HTTP通信使用明文的问题）和认证（解决HTTP不验证通信方的身份问题）以及完整性保护（解决HTTP无法证明报文完整性的问题）后的东西。</p><p><strong>端口：443</strong></p><p><img src="HTTP和HTTPS对比.png" alt="HTTP和HTTPS对比"></p><p>注：上图并不代表顺序。也就是说<strong>HTTPS是先建立TCP连接，再进行TLS/SSL握手。</strong></p><h1 id="HTTPS通信"><a href="#HTTPS通信" class="headerlink" title="HTTPS通信"></a>HTTPS通信</h1><p>直接上图</p><p><img src="HTTPS通信.png" alt="HTTPS通信">​</p><p>上图基本把HTTPS的通信流程说的非常清晰了，补充两点：</p><ol><li>这里对比HASH是为了防止握手消息被篡改。浏览器与网站互相发送加密的握手消息并验证，目的是为了保证双方都获得了一致的密码，并且可以正常的加密解密数据，为后续真正数据的传输做一次测试。</li><li>因为对称加密要比非对称加密的计算快很多，所以HTTPS没有全程使用非对称加密，而是先使用非对称加密交换对称密钥，再使用对称加密手段通信。</li><li>证书确保了双方身份。</li></ol><p>另外，HTTPS一般使用的加密与HASH算法如下：</p><ul><li>非对称加密算法：RSA，DSA/DSS</li><li>对称加密算法：AES，RC4，3DES</li><li>HASH算法：MD5，SHA1，SHA256</li></ul><h1 id="HTTPS-的优缺点"><a href="#HTTPS-的优缺点" class="headerlink" title="HTTPS 的优缺点?"></a>HTTPS 的优缺点?</h1><p>优点</p><ul><li><p>安全性：</p><ul><li>使用HTTPS协议可认证用户和服务器，确保数据发送到正确的客户机和服务器；</li><li>HTTPS协议是由SSL+HTTP协议构建的可进行加密传输、身份认证的网络协议，要比http协议安全，可防止数据在传输过程中不被窃取、改变，确保数据的完整性。</li><li>HTTPS是现行架构下最安全的解决方案，虽然不是绝对安全，但它大幅增加了中间人攻击的成本。</li></ul></li><li>SEO方面：谷歌曾在2014年8月份调整搜索引擎算法，并称“比起同等HTTP网站，采用HTTPS加密的网站在搜索结果中的排名将会更高”。</li></ul><p>缺点</p><ul><li>在相同网络环境中，HTTPS 相比 HTTP 无论是响应时间还是耗电量都有大幅度上升。</li><li>HTTPS 的安全是有范围的，在黑客攻击、服务器劫持等情况下几乎起不到作用。</li><li>在现有的证书机制下，中间人攻击依然有可能发生。</li><li>HTTPS 需要更多的服务器资源，也会导致成本的升高。</li></ul><h1 id="Refs"><a href="#Refs" class="headerlink" title="Refs"></a>Refs</h1><ol><li><a href="https://www.ruanyifeng.com/blog/2014/02/ssl_tls.html">SSL/TLS协议运行机制的概述</a></li><li><a href="https://www.cnblogs.com/zery/p/5164795.html">HTTPS 原理解析</a></li><li><a href="https://cloud.tencent.com/developer/article/1007810?from=article.detail.1017988">HTTPS 建立连接的详细过程</a></li><li><a href="https://juejin.cn/post/6906126429381984264">HTTPS连接过程</a></li><li><a href="https://zhuanlan.zhihu.com/p/45390160">HTTPS详细介绍</a></li></ol>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;前置知识&quot;&gt;&lt;a href=&quot;#前置知识&quot; class=&quot;headerlink&quot; title=&quot;前置知识&quot;&gt;&lt;/a&gt;前置知识&lt;/h1&gt;&lt;p&gt;加密分为对称加密和非对称加密，HTTPS兼顾两者。&lt;/p&gt;
&lt;p&gt;关于非对称加密，可以查阅相关资料。这里只提一点：&lt;/p&gt;
</summary>
      
    
    
    
    <category term="计算机网络" scheme="https://guoyujian.github.io/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/"/>
    
    <category term="HTTP协议" scheme="https://guoyujian.github.io/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/HTTP%E5%8D%8F%E8%AE%AE/"/>
    
    
    <category term="计算机网络" scheme="https://guoyujian.github.io/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/"/>
    
    <category term="HTTP协议" scheme="https://guoyujian.github.io/tags/HTTP%E5%8D%8F%E8%AE%AE/"/>
    
  </entry>
  
  <entry>
    <title>HTTP面试题</title>
    <link href="https://guoyujian.github.io/2022/09/24/HTTP%E9%9D%A2%E8%AF%95%E9%A2%98/"/>
    <id>https://guoyujian.github.io/2022/09/24/HTTP%E9%9D%A2%E8%AF%95%E9%A2%98/</id>
    <published>2022-09-23T16:07:45.000Z</published>
    <updated>2022-09-23T16:21:17.281Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>作为复习，也作为一个目录</p></blockquote><h1 id="说一下HTTP协议"><a href="#说一下HTTP协议" class="headerlink" title="说一下HTTP协议"></a>说一下HTTP协议</h1><p>HTTP全称是Hyper Text Transfer Protocol。即<strong>超文本传输协议</strong>，它是以<strong>TCP/IP</strong>为基础来传输HTML，文件，图片等。 它本身处于<strong>应用层</strong>，<strong>端口号80</strong>。</p><ol><li>HTTP是基于<strong>浏览器/服务器</strong>架构；</li><li>HTTP是<strong>无状态</strong>协议：HTTP本身并不保存用户的任何信息，也不会对传输的数据，状态信息进行持久化；</li><li>HTTP是<strong>无连接</strong>协议：每次连接只处理一个请求，服务器处理完用户请求，即断开连接，借此节约传输时间。</li></ol><h1 id="HTTP通信过程"><a href="#HTTP通信过程" class="headerlink" title="HTTP通信过程"></a>HTTP通信过程</h1><ol><li>用户输入网址</li><li>DNS服务器解析域名</li><li>浏览器和服务器建立TCP连接</li><li>浏览器向服务器发送请求行</li><li>浏览器向服务器发送请求头，并以空行代表发送结束，如果请求类型为<code>post</code>，则继续发送请求体</li><li>服务器应答协议版本号和应答状态码</li><li>服务器发送响应头，并以空行代表发送结束</li><li>服务器发送数据：以<code>Content-Type</code>给出的格式发送用户所请求的信息</li><li>服务器关闭TCP连接：如果浏览器或者服务器的头信息中加入了这样一段代码：<code>connection：Keep-alive</code> 则TCP连接会保持打开状态</li><li>客户端浏览器解析HTML内容</li></ol><p>下图整理了HTTP通信的关键步骤：</p><p><img src="http通信过程.png" alt="计算机网络-http通信过程">​</p><h1 id="说一下HTTPS协议"><a href="#说一下HTTPS协议" class="headerlink" title="说一下HTTPS协议"></a>说一下HTTPS协议</h1><p>可以看我的博客：《HTTPS协议》</p><h1 id="HTTP与HTTPS的对比"><a href="#HTTP与HTTPS的对比" class="headerlink" title="HTTP与HTTPS的对比"></a>HTTP与HTTPS的对比</h1><ul><li>两者工作的端口号不同：HTTP工作在80，HTTPS工作在443；</li><li>HTTPS需要用到CA（数字证书认证机构）申请证书，一般需要一定费用；</li><li>HTTP响应比HTTPS快，主要因为HTTPS除了TCP3次握手外还要加上<strong>SSL9次握手</strong>共12次握手；</li><li>HTTPS是构建在SSL/TLS上的HTTP协议，因此需要占用服务器资源。</li></ul><h1 id="HTTP缓存​"><a href="#HTTP缓存​" class="headerlink" title="HTTP缓存​"></a>HTTP缓存​</h1><p>http缓存指的是: 当客户端向服务器请求资源时，会先抵达<strong>浏览器缓存</strong>，如果浏览器有“要请求资源”的副本，就可以<strong>直接从浏览器缓存中提取</strong>而不是从原始服务器中提取这个资源。</p><p>常见的http缓存<strong>只能缓存get请求</strong>响应的资源，对于其他类型的响应则无能为力，所以后续说的请求缓存都是指GET请求。<br>http缓存都是从第二次请求开始的。第一次请求资源时，服务器返回资源，并在respone header头中回传资源的缓存参数；第二次请求时，浏览器判断这些请求参数，命中强缓存就直接200，否则就把请求参数加到request header头中传给服务器，看是否命中协商缓存，命中则返回304，否则服务器会返回新的资源。（可以画个图理解一下）</p><p>HTTP 缓存又分为<strong>强缓存</strong>和 <strong>协商缓存</strong> ：</p><p><strong>强制缓存</strong>：在缓存数据未失效的情况下（即Cache-Control的max-age没有过期或者Expires的缓存时间没有过期），那么就会直接使用浏览器的缓存数据，不会再向服务器发送任何请求。</p><p><strong>协商缓存</strong>：当第一次请求时服务器返回的响应头中没有Cache-Control和Expires或者Cache-Control和Expires过期还或者它的属性设置为no-cache时(即不走强缓存)，那么浏览器第二次请求时就会与服务器进行 <strong>协商</strong>，与服务器端对比判断资源是否进行了修改更新。如果服务器端的资源没有修改，那么就会返回304状态码，告诉浏览器可以使用缓存中的数据，这样就减少了服务器的数据传输压力。如果数据有更新就会返回200状态码，服务器就会返回更新后的资源并且将缓存信息一起返回。</p><h1 id="HTTP状态码"><a href="#HTTP状态码" class="headerlink" title="HTTP状态码"></a>HTTP状态码</h1><ul><li>1xx：<strong>目前是协议的中间状态，还需要后续请求。</strong><ul><li>101 切换请求协议，从 HTTP 切换到 WebSocket</li></ul></li><li>2xx：<strong>表示请求成功。</strong><ul><li>200 请求成功，有响应体</li></ul></li><li><p>3xx：<strong>表示重定向状态，需要重新请求。</strong></p><ul><li>301 永久重定向：会缓存</li><li>302 临时重定向：不会缓存</li><li>304 协商缓存命中</li></ul></li><li><p>4xx：<strong>请求报文错误。</strong></p><ul><li>403 服务器禁止访问</li><li>404 资源未找到</li><li>400 请求错误</li></ul></li><li><p>5xx：<strong>服务器错误。</strong></p><ul><li>500 服务器端错误</li><li>503 服务器繁忙</li></ul></li></ul><h1 id="一个典型的HTTP请求报文包括哪些部分？响应报文呢？"><a href="#一个典型的HTTP请求报文包括哪些部分？响应报文呢？" class="headerlink" title="一个典型的HTTP请求报文包括哪些部分？响应报文呢？"></a>一个典型的HTTP请求报文包括哪些部分？响应报文呢？</h1><p>一个HTTP请求报文包括：  <strong>请求头，请求行，空行，请求体</strong>。</p><p>一个响应报文包括： <strong>响应行，响应头，空行，响应体</strong> 。</p><p>具体参考我的博客《详解HTTP协议》</p><h1 id="HTTP1-0、HTTP1-1、HTTP2-0区别"><a href="#HTTP1-0、HTTP1-1、HTTP2-0区别" class="headerlink" title="HTTP1.0、HTTP1.1、HTTP2.0区别"></a>HTTP1.0、HTTP1.1、HTTP2.0区别</h1><h2 id="HTTP1-0和HTTP1-1的区别-长短连接的区别"><a href="#HTTP1-0和HTTP1-1的区别-长短连接的区别" class="headerlink" title="HTTP1.0和HTTP1.1的区别/长短连接的区别"></a>HTTP1.0和HTTP1.1的区别/长短连接的区别</h2><p>这里主要回答长短连接的区别就行吧。。</p><p>在HTTP/1.0中采用短连接。客户端和服务器每进行一次HTTP操作，就建立一次连接，任务中断连接；Connection: close</p><p>在HTTP/1.1默认采用长连接和请求的流水线（Pipelining）处理，在一个TCP连接上可以传送多个HTTP请求和响应，减少了建立和关闭连接的消耗和延迟。Connection: keep-alive，就是保持连接。</p><hr><p>长连接适用的场景：长连接适用于操作频繁/点对点通讯等连接数不太多的情况，如：一些游戏/即时通讯场景应该使用长连接；</p><p>短连接适用的场景： 短连接适用于大量连接的场景，如Web【wapWeb/H5等】的http服务，长连接对于服务端来说会耗费一定资源。</p><blockquote><p>补充其他区别：</p><ul><li>长短连接</li><li><strong>缓存处理</strong>：在HTTP1.0中主要使用header里的If-Modified-Since,Expires来做为缓存判断的标准，HTTP1.1则引入了更多的缓存控制策略，可供选择的缓存头来控制缓存策略。</li><li><strong>带宽优化及网络连接的使用</strong>：HTTP1.0中，存在一些浪费带宽的现象，例如客户端只是需要某个对象的一部分，而服务器却将整个对象送过来了，并且不支持断点续传功能，HTTP1.1则在请求头引入了range头域，它允许只请求资源的某个部分，即返回码是206（Partial Content），这样就方便了开发者自由的选择以便于充分利用带宽和连接。</li><li><strong>错误通知的管理</strong>：在HTTP1.1中新增了24个错误状态响应码，如409（Conflict）表示请求的资源与资源的当前状态发生冲突；410（Gone）表示服务器上的某个资源被永久性的删除。</li><li><strong>Host头处理</strong>：在HTTP1.0中认为每台服务器都绑定一个唯一的IP地址，因此，请求消息中的URL并没有传递主机名（hostname）。但随着虚拟主机技术的发展，在一台物理服务器上可以存在多个虚拟主机（Multi-homed Web Servers），并且它们共享一个IP地址。HTTP1.1的请求消息和响应消息都应支持Host头域，且请求消息中如果没有Host头域会报告一个错误（400 Bad Request）。</li></ul></blockquote><h2 id="HTTP1和HTTP2的区别"><a href="#HTTP1和HTTP2的区别" class="headerlink" title="HTTP1和HTTP2的区别"></a>HTTP1和HTTP2的区别</h2><p>HTTP2.0是第二代TCP协议。它与HTTP1.1的不同点在于：</p><ul><li>HTTP2采用<strong>二进制</strong>而非文本格式；此属性减轻了框架的复杂性，并简化了由于包含文本和可选空格的命令而导致混淆的命令的实现。</li><li>HTTP2是 <strong>完全多路复用</strong> ，而线端阻塞的——只需一个连接可以实现并行；</li><li>HTTP2使用<strong>标头（headers）压缩</strong> ，减小了开销；</li><li>HTTP2让服务器可以将响应主动推送到客户端缓存中。</li></ul><p>名词解释：</p><blockquote><p>线端阻塞和多路复用</p><p>HTTP/1.x 有个问题叫线端阻塞(head-of-line blocking), 它是指<strong>一个连接(connection)一次只提交一个请求的效率比较高, 多了就会变慢</strong>。 HTTP/1.1 试过用流水线(pipelining)来解决这个问题, 但是效果并不理想(数据量较大或者速度较慢的响应, 会阻碍排在他后面的请求)。</p><p>多路传输(Multiplexing)能很好的解决这些问题, 因为它能同时处理多个消息的请求和响应; 甚至可以在传输过程中将一个消息跟另外一个掺杂在一起。所以<strong>客户端只需要一个连接</strong>就能加载一个页面。减少额外的往返时间。</p><p><img src="http1和2建立连接.png" alt="http1和2建立连接"></p><p>主动推送：通俗理解就是客户端请求了html，服务器觉得和其相关的css也会被关联到，于是主动同送其他资源到客户端。</p></blockquote><h1 id="GET、POST区别"><a href="#GET、POST区别" class="headerlink" title="GET、POST区别"></a>GET、POST区别</h1><p>具体看我的博客《详解HTTP协议》和《HTTP协议幂等性》</p><p><img src="get和post区别.png" alt="get和post区别"></p><p>‍</p>]]></content>
    
    
      
      
    <summary type="html">&lt;blockquote&gt;
&lt;p&gt;作为复习，也作为一个目录&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h1 id=&quot;说一下HTTP协议&quot;&gt;&lt;a href=&quot;#说一下HTTP协议&quot; class=&quot;headerlink&quot; title=&quot;说一下HTTP协议&quot;&gt;&lt;/a&gt;说一下HTTP协议&lt;/h</summary>
      
    
    
    
    <category term="计算机网络" scheme="https://guoyujian.github.io/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/"/>
    
    <category term="HTTP协议" scheme="https://guoyujian.github.io/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/HTTP%E5%8D%8F%E8%AE%AE/"/>
    
    
    <category term="计算机网络" scheme="https://guoyujian.github.io/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/"/>
    
    <category term="HTTP协议" scheme="https://guoyujian.github.io/tags/HTTP%E5%8D%8F%E8%AE%AE/"/>
    
  </entry>
  
  <entry>
    <title>使用腾讯会议的屏幕共享功能时开启PPT演示者视图的方法</title>
    <link href="https://guoyujian.github.io/2022/09/11/%E4%BD%BF%E7%94%A8%E8%85%BE%E8%AE%AF%E4%BC%9A%E8%AE%AE%E7%9A%84%E5%B1%8F%E5%B9%95%E5%85%B1%E4%BA%AB%E5%8A%9F%E8%83%BD%E6%97%B6%E5%BC%80%E5%90%AFPPT%E6%BC%94%E7%A4%BA%E8%80%85%E8%A7%86%E5%9B%BE%E7%9A%84%E6%96%B9%E6%B3%95/"/>
    <id>https://guoyujian.github.io/2022/09/11/%E4%BD%BF%E7%94%A8%E8%85%BE%E8%AE%AF%E4%BC%9A%E8%AE%AE%E7%9A%84%E5%B1%8F%E5%B9%95%E5%85%B1%E4%BA%AB%E5%8A%9F%E8%83%BD%E6%97%B6%E5%BC%80%E5%90%AFPPT%E6%BC%94%E7%A4%BA%E8%80%85%E8%A7%86%E5%9B%BE%E7%9A%84%E6%96%B9%E6%B3%95/</id>
    <published>2022-09-11T06:13:47.000Z</published>
    <updated>2022-09-11T06:14:43.767Z</updated>
    
    <content type="html"><![CDATA[<p><a href="https://meeting.tencent.com/support-doc-detail/79/index.html">https://meeting.tencent.com/support-doc-detail/79/index.html</a></p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;&lt;a href=&quot;https://meeting.tencent.com/support-doc-detail/79/index.html&quot;&gt;https://meeting.tencent.com/support-doc-detail/79/index.html&lt;/a&gt;&lt;/</summary>
      
    
    
    
    <category term="工具箱" scheme="https://guoyujian.github.io/categories/%E5%B7%A5%E5%85%B7%E7%AE%B1/"/>
    
    
    <category term="腾讯会议" scheme="https://guoyujian.github.io/tags/%E8%85%BE%E8%AE%AF%E4%BC%9A%E8%AE%AE/"/>
    
    <category term="ppt" scheme="https://guoyujian.github.io/tags/ppt/"/>
    
    <category term="演示者视图" scheme="https://guoyujian.github.io/tags/%E6%BC%94%E7%A4%BA%E8%80%85%E8%A7%86%E5%9B%BE/"/>
    
  </entry>
  
  <entry>
    <title>markdown公式编辑语法</title>
    <link href="https://guoyujian.github.io/2022/09/11/markdown%E5%85%AC%E5%BC%8F%E7%BC%96%E8%BE%91%E8%AF%AD%E6%B3%95/"/>
    <id>https://guoyujian.github.io/2022/09/11/markdown%E5%85%AC%E5%BC%8F%E7%BC%96%E8%BE%91%E8%AF%AD%E6%B3%95/</id>
    <published>2022-09-11T06:06:19.000Z</published>
    <updated>2022-09-11T06:10:33.036Z</updated>
    
    <content type="html"><![CDATA[<p>下面两个连接给出的公式语法涵盖了大部分的内容，第一个是官方连接。</p><ol><li><a href="https://katex.org/docs/supported.html">Supported Functions</a></li><li><a href="https://blog.csdn.net/weixin_42782150/article/details/104878759">史上最全Markdown公式、符号总结！！！</a></li></ol><p>另外推荐一款公式生成软件</p><blockquote><p><strong>mathpix snipping tool</strong></p></blockquote><p>通过截图生成公式code，可以直接复制公式代码，也可以直接复制到word等。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;下面两个连接给出的公式语法涵盖了大部分的内容，第一个是官方连接。&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;a href=&quot;https://katex.org/docs/supported.html&quot;&gt;Supported Functions&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;h</summary>
      
    
    
    
    <category term="工具箱" scheme="https://guoyujian.github.io/categories/%E5%B7%A5%E5%85%B7%E7%AE%B1/"/>
    
    
    <category term="markdown" scheme="https://guoyujian.github.io/tags/markdown/"/>
    
    <category term="typora" scheme="https://guoyujian.github.io/tags/typora/"/>
    
  </entry>
  
  <entry>
    <title>【不经意传输】算法介绍</title>
    <link href="https://guoyujian.github.io/2022/09/11/%E3%80%90%E4%B8%8D%E7%BB%8F%E6%84%8F%E4%BC%A0%E8%BE%93%E3%80%91%E7%AE%97%E6%B3%95%E4%BB%8B%E7%BB%8D/"/>
    <id>https://guoyujian.github.io/2022/09/11/%E3%80%90%E4%B8%8D%E7%BB%8F%E6%84%8F%E4%BC%A0%E8%BE%93%E3%80%91%E7%AE%97%E6%B3%95%E4%BB%8B%E7%BB%8D/</id>
    <published>2022-09-11T05:32:22.000Z</published>
    <updated>2022-09-11T05:38:01.807Z</updated>
    
    <content type="html"><![CDATA[<h1 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h1><p>“不经意传输”要解决这类问题：你需要给对方多条信息，但是你又必须确保对方只获得其中一条，但是对方又希望能够确保你不知道他看到哪一条信息。</p><p>设计一个具体场景：你给你的哥们介绍相亲女朋友，你有两个可供介绍的单身女性，但是你不想同时将两人的情况和联系方式给对方。但你也无法抉择到底给哪个，所以你想让他随机抽签选择一个。但与此同时，你的哥们也不想让你知道，他最终抽到了谁。</p><h1 id="定义"><a href="#定义" class="headerlink" title="定义"></a>定义</h1><p><strong>不经意传输</strong>（Oblivious Transfer，简称OT）是一个密码学协议，在这个协议中，消息发送者从一些待发送的消息中发送一条给接收者，但事后对发送了哪一条消息仍然oblivious（不知道），这个协议也叫茫然传输协议。</p><p>不经意传输是密码学中的一个基本而重要的问题，被认为是该领域的关键问题之一，对于<strong>安全多方计算</strong>来说是完整的实现。</p><p>例如下图，Alice是消息发送者，Bob是消息接受者。Alice想要将消息$M_0$、$M_1$之一传给Bob，Bob只能得到自己想要的那个（$M_0$或$M_1$）不能获取另外一个消息，Alice也不能知道Bob选的是哪一条消息。</p><p><img src="不经意传输1.png" alt="不经意传输1"></p><h1 id="历史"><a href="#历史" class="headerlink" title="历史"></a>历史</h1><p>第一种形式的不经意传输，最初是在1981由Michael O.Rabin提出，在这种不经意传输中，发送者Alice发送一条消息给接收着Bob，而Bob以1/2的概率接收到信息，在结束后Alice并不知道Bob是否接收到了信息，而Bob能确信地知道自己是否收到了信息。</p><p>另一种更实用的不经意传输协议，被称为2选一不经意传输（1 out 2 oblivious transfer）由 Shimon Even，Oded Goldreich和Abraham Lempel在1985年提出，在这种形式的不经意传输模型中，Alice每次发两条信息（m1、m2）给Bob，<strong>Bob提供一个输入</strong>，并根据输入获得输出信息，在协议结束后，Bob得到了自己想要的那条信息（m1或者m2），而Alice并不知道Bob最终得到的是哪条。</p><blockquote><p>这个输入，我的理解是通知发送者发哪些消息，发送消息的范围</p></blockquote><p>1986年，Brassard等人将2选1不经意传输拓展为n选1。</p><p><img src="不经意传输2.png" alt="不经意传输2"></p><p>不经意传输一种实现方式是<strong>基于RSA公钥算法</strong>，下面就2选1不经意传输的实现做简要介绍。</p><h1 id="基于RSA公钥算法的2选1不经意传输"><a href="#基于RSA公钥算法的2选1不经意传输" class="headerlink" title="基于RSA公钥算法的2选1不经意传输"></a>基于RSA公钥算法的2选1不经意传输</h1><p>先把「基于RSA公钥算法的2选1不经意传输」的流程图列出来：</p><p><img src="不经意传输流程.png" alt="不经意传输流程"></p><h2 id="流程"><a href="#流程" class="headerlink" title="流程"></a>流程</h2><ol><li>发送者Alice生成两对RSA公私钥$(puk0, pri0)$，$(puk1, pri1)$，并将两个公钥$puk0$和$puk1$发送给Bob。</li><li>Bob生成一个随机数$r$，并用收到的两个公钥之一加密随机数，$c=Encrypt(r)$。（用哪个秘钥取决于想获取哪条数据，例如如果想要得到消息$M_0$就用$puk0$加密随机数，如果想要得到$M_1$就用$puk1$加密随机数），并将密文结果发送给Alice。</li><li>Alice用自己的两个私钥分别解密收到随机数密文，得到两个解密结果：$k_0=Decrypt(c, pri_0)$，$k_1=Decrypt(c, pri_1)$。（$k_0$，$k_1$其中一个就是随机数$r$）。并将两个结果分别与两条信息进行异或，生成掩码消息：$e_0=k_0\bigoplus m_0$，$e_1=k_1\bigoplus m_1$，并将两个结果$e_0$，$e_1$发给Bob。</li><li>Bob用之前生成的随机数$r$与收到的$e_0$，$e_1$分别做异或操作，得到的两个结果中只有一条为真实数据，另外一条为随机数：$m^{‘}_0=e_0\bigoplus r$，$m^{‘}_1=e_1\bigoplus r$。</li><li>Bob在步骤2中，如果使用$puk0$加密，得到的$m^{‘}_0=m_0$，反之是$m_1$。</li></ol><h2 id="分析"><a href="#分析" class="headerlink" title="分析"></a>分析</h2><p>在此过程中第3步最为关键，如果Alice无法从用两条私钥解密得到的结果$k_0$、$k_1$中区分出Bob的真实随机数，则能保证Alice无法得知Bob将要获取的是哪条数据。Bob没有私钥也就无法得出真实的私钥解密结果（如果$k_0$为真实随机数，Bob无法得知$k_1$的值），所以也就只能得到自己想要的那条数据而无法得到另外一条，保障协议能执行成功。</p><h1 id="Refs"><a href="#Refs" class="headerlink" title="Refs"></a>Refs</h1><ol><li><a href="https://learnblockchain.cn/article/2022">区块链中的数学 - 不经意传输</a></li><li><a href="https://zhuanlan.zhihu.com/p/208295083">什么是不经意传输</a></li></ol>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;背景&quot;&gt;&lt;a href=&quot;#背景&quot; class=&quot;headerlink&quot; title=&quot;背景&quot;&gt;&lt;/a&gt;背景&lt;/h1&gt;&lt;p&gt;“不经意传输”要解决这类问题：你需要给对方多条信息，但是你又必须确保对方只获得其中一条，但是对方又希望能够确保你不知道他看到哪一条信息。&lt;/</summary>
      
    
    
    
    <category term="密码学" scheme="https://guoyujian.github.io/categories/%E5%AF%86%E7%A0%81%E5%AD%A6/"/>
    
    
    <category term="密码学" scheme="https://guoyujian.github.io/tags/%E5%AF%86%E7%A0%81%E5%AD%A6/"/>
    
  </entry>
  
</feed>
